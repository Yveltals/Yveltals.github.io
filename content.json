{"meta":{"title":"Hexo","subtitle":"","description":"N/A","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2022-06-05T17:23:21.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-06-05T17:24:07.000Z","updated":"2025-03-06T09:01:58.048Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2022-06-05T17:23:39.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"Nothing to say ……"}],"posts":[{"title":"RocksDB","slug":"Storage/RocksDB","date":"2025-02-15T14:20:04.000Z","updated":"2025-03-06T09:01:58.039Z","comments":true,"path":"2025/02/15/Storage/RocksDB/","permalink":"http://example.com/2025/02/15/Storage/RocksDB/","excerpt":"","text":"RocksDB内部数据组织方式介绍及性能压测 Basic OperationsIterator迭代器本身不会占用太多内存，但是迭代器最好保持较短的生存周期，为了确保某些资源能被释放，包括： 迭代器创建时的 memtables 和 SST 文件。即使某些 memtables 和 SST 文件在刷新或压缩后被删除，如果迭代器固定它们，它们仍然保留。 当前迭代位置的数据块。这些块将保存在内存中，要么固定在 Block Cache 中，要么在未设置块缓存时在堆中。 Iterator的创建也存在成本，因此复用iterator是最合适的，调用Iterator::Refresh() 来刷新以表示最近的状态，并且先前固定的资源会被释放。 Prefix Iterator前缀 Iterator 是一种特殊的迭代器，允许高效地遍历具有 特定前缀 的键值对，避免遍历整个数据库，减少不必要的数据扫描，提高读取效率。 read_options.prefix_same_as_start = true，启用前缀迭代器 read_options.total_order_seek，默认 false 只遍历前缀匹配的键，设置 true 会忽略前缀限制，允许迭代整个数据库（按顺序扫描所有键） Prefix Bloom filter前缀 Bloom Filter 是专门为 前缀迭代器 设计的，它通过将前缀与 Bloom Filter 结合，减少不必要的磁盘读取操作，加速前缀匹配的查找。 加速前缀迭代器：在进行前缀迭代时，RocksDB 会使用前缀 Bloom Filter 来判断数据是否存在于某个 SST 文件中，否则不会去读取文件。 1234567891011121314Options options;// Set up bloom filterrocksdb::BlockBasedTableOptions table_options;table_options.filter_policy.reset(rocksdb::NewBloomFilterPolicy(10, false));table_options.whole_key_filtering = false; // If you also need Get() to use whole key filters, leave it to true.options.table_factory.reset( rocksdb::NewBlockBasedTableFactory(table_options)); // For multiple column family setting, set up specific column family&#x27;s ColumnFamilyOptions.table_factory instead.// Define a prefix. In this way, a fixed length prefix extractor. A recommended one to use.options.prefix_extractor.reset(NewCappedPrefixTransform(3));DB* db;Status s = DB::Open(options, &quot;/tmp/rocksdb&quot;, &amp;db); options.prefix_extractor指定前缀，如果这个参数改变需要重启DB，通常，最终结果是现有SST文件中的bloom过滤器在读取时会被忽略。 read_options.total_order_seek = true 将确保查询返回与没有前缀布隆过滤器相同的结果，忽略前缀bloom filter。 read_options.auto_prefix_mode = true; 防止 bloom filter 的 “假阳性” 因 hash 冲突导致的不存在的数据显示存在。 Bloom FilterRocksDB 的每个 SST 文件都包含一个 Bloom filter。Bloom Filter 只对特定的一组 keys 有效，所以只有新的 SST 文件创建的时候才会生成这个 filter。当两个 SST 文件合并的时候，会生成新的 filter 数据。 当 SST 文件加载进内存的时候，filter 也会被加载进内存，当关闭 SST 文件的时候，filter 也会被关闭。如果想让 filter 常驻内存，可以设置BlockBasedTableOptions::cache_index_and_filter_blocks 为 true。 Compaction FilterRocksDB提供了一种基于自定义逻辑在后台删除或修改键&#x2F;值对的方法。它可以方便地实现自定义垃圾收集，比如根据TTL删除过期的键，或者在后台删除一系列键。它还可以更新现有键的值。 要使用压缩过滤器，需要实现 CompactionFilter 接口并将其设置为ColumnFamilyOptions。或者可以实现 CompactionFilterFactory&#96; 接口，灵活地为每个（子）压缩创建不同的压缩过滤器实例。 123options.compaction_filter = new CustomCompactionFilter();// oroptions.compaction_filter_factory.reset(new CustomCompactionFilterFactory()); 每次(子)压缩从其输入中看到一个新键，且该值是正常值时，它就调用压缩筛选器。根据压实过滤器的结果： 如果它决定保留key，什么都不会改变。 如果请求过滤键，则该值将被删除标记替换。注意，如果压缩的输出级别是底层，则不需要输出删除标记。 如果请求更改该值，则该值将被更改后的值替换。 如果它请求通过返回kRemoveAndSkipUntil来删除一段键，则压缩将跳到skip_until(意味着skip_until将是压缩后的下一个可能的键输出)。这个比较棘手，因为在这种情况下，压缩不会为它跳过的键插入删除标记。这意味着旧版本的键可能会重新出现。另一方面，如果应用程序知道没有旧版本的键，或者可以重新出现旧版本，那么简单地删除键会更有效。 如果来自压缩输入的相同键有多个版本，则对最新版本只调用压缩筛选器一次。如果最新版本是删除标记，则不会调用压缩筛选器。但是，如果删除标记没有包含在压缩的输入中，则可能对已删除的键调用压缩筛选器。 当merge被使用，每个合并操作数调用压缩过滤器。 在调用合并运算符之前，将压缩过滤器的结果应用于合并操作数。 Snapshot快照在创建时捕获数据库的时间点视图，快照不会在数据库重新启动后持续存在。 123db.getSnapshot()ReadOptions.setSnapshot()db.releaseSnapshot() 快照由 SnapshotImpl 类的一个小对象表示。它只保存几个基本字段，比如快照所在的seqnum。 快照被存储在DBImpl的一个链表里。一个好处是我们可以在获取 DB 互斥锁之前分配列表节点。然后在持有互斥锁的同时，我们只需要更新列表指针。此外，可以按任意顺序对快照调用 ReleaseSnapshot()。使用链表，可以在不移动的情况下从中间删除一个节点。 在刷新&#x2F;压缩期间，当我们需要找出某个键可见的最早快照时，我们必须扫描快照列表。但是链表不能二分搜索，当有很多快照时会显着降低刷新&#x2F;压缩速度，导致 Write Stall。 Low Priority Write低优先级写能够帮助用户管理写入的优先级。通过writeOptions.setLowPri(true) 设置后台写入，RocksDB将对低优先级写入进行更积极的节流，以确保高优先级写入不会 Write Stall。 如果系统认为存在压缩压力，RocksDB 会让低优先级写操作进行睡眠，降低写速率，确保高优先级写操作的处理优先级，不会因为低优先级写入过多而导致整体性能下降。 在二阶段提交过程中，低优先级写入会在准备阶段完成，而不是在提交阶段。 Column Families RocksDB 中的每个键值对都与一个列族相关联。 如果没有指定列族，键值对与列族 default 相关联。列族提供了一种对数据库进行逻辑分区的方法。 支持跨列族原子写，这个意思是可以原子写入(&#123;cf1, key1, value1&#125;, &#123;cf2, key2, value2&#125;). 跨列族的数据库一致视图。 能够独立配置不同的列族。 即时添加新的列族并删除它们。 这两种操作都相当快。 Column Family 的思想是共享 WAL 日志而不共享 memtables 和sst 文件，即 log 共享而数据分离，可以独立配置列族并快速删除它们。 使用一个 RocksDB 就是使用一个物理存储系统，使用一个 CF 则是使用一个逻辑存储系统，二者主要区别体现在数据备份、原子写以及写性能表现上。DB 是数据备份和复制以及 checkpoint 的基本单位，但是 CF 则利用 BatchWrite，因为这个操作是可以跨 CF 的，而且多个 CF 可以共享同一个 WAL，多个 DB 则无法做到这一点。 每次 Flush 单个 CF 时，都会创建一个新的 WAL，但无法删除旧的 WAL，只有全部的列族被 Flush 且这个 WAL 包含的全部数据已经持久化时才可以删除旧的WAL文件。确保对RocksDB进行调优，以便定期刷新所有列族。另外，查看Options::max_total_wal_size，可以配置为自动刷新过时的列族。 Column Family 使用场景： 不同的 Column Family 可以使用不同的 setting&#x2F;comparators&#x2F;compression types&#x2F;merge operators&#x2F;compaction filters 对数据进行逻辑隔离，方便分别删除 一个 Column Family 存储 metadata，另一个存储 data； LSM-Tree将数据形成Log-Structured：在将数据写入LSM内存结构之前，先记录log。这样LSM就可以将有易失性的内存看做永久性存储器。并且信任内存上的数据，等到内存容量达到threshold再集体写入磁盘。 LSM 将所有数据不组织成一个整体索引结构，而组织成有序的文件集。每次LSM面对磁盘写，将数据写入一个或几个新生成的文件，顺序写入且不能修改其他文件，这样就将随机读写转换成了顺序读写。LSM将一次性集体写入的文件作为一个level，磁盘上划分多level，level与level之间互相隔离。这就形成了，以写入数据时间线形成的逻辑上、而非物理上的层级结构，这也就是为什么LSM被命名为 tree，但不是 tree。 除了将随机写合并之后转化为顺写之外，LSM 的另外一个关键特性就在于其是一种自带数据 Garbage Collect 的有序数据集合，对外只提供了 Add&#x2F;Get 接口，其内部的 Compaction 就是其 GC 的关键，通过 Compaction 实现了对数据的删除、附带了 TTL 的过期数据地淘汰、同一个 Key 的多个版本 Value 地合并。RocksDB 基于 LSM 对外提供了 Add&#x2F;Delete&#x2F;Get 三个接口，用户则基于 RocksDB 提供的 transaction 还可以实现 Update 语义。 ChecksumsRocksdb 对每个 kv 以及整体数据文件都分别计算了 checksum，以进行数据正确性校验。下面有两个选项对 checksum 的行为进行控制。 ReadOptions::verify_checksums 默认 true，强制对每次从磁盘读取的数据进行校验。 Options::paranoid_checks 默认 false，这个选项为 true 的时候，如果检测到内部数据部分错乱，马上抛出一个错误。 如果 RocksDB 的数据错乱，RocksDB 会尽量把它隔离出来，保证大部分数据的可用性和正确性。 Thread PoolRocksDB 会创建一个 thread pool 与 Env 对象进行关联，线程池中线程的数目可以通过 Env::SetBackgroundThreads() 设定。通过这个线程池可以执行 compaction 与 memtable flush 任务。 当 memtable flush 和 compaction 两个任务同时执行的时候，会导致写请求被 hang 住。RocksDB 建议创建两个线程池，分别指定 HIGH 和 LOW 两个优先级。默认情况下 HIGH 线程池执行 memtable flush 任务，LOW 线程池执行 compaction 任务。 12345678910111213#include “rocksdb/env.h”#include “rocksdb/db.h”auto env = rocksdb::Env::Default();env-&gt;SetBackgroundThreads(2, rocksdb::Env::LOW);env-&gt;SetBackgroundThreads(1, rocksdb::Env::HIGH);rocksdb::DB* db;rocksdb::Options options;options.env = env;options.max_background_compactions = 2;options.max_background_flushes = 1;rocksdb::Status status = rocksdb::DB::Open(options, “/tmp/testdb”, &amp;db);assert(status.ok()); Setup Option1. Write Buffer Options::write_buffer_size 是一个全局配置，应用于所有 Column Family 的默认写缓冲区。 cf_options.write_buffer_size 允许为每个 CF 定义不同的写缓冲区大小，从而精细化内存管理。 db_options.db_write_buffer_size 则影响的是数据库整体的写缓冲区大小，特别是在多 CF 的情况下，影响数据库的整体内存配置。 Options::max_write_buffer_number 限制了内存中可以并行存在的最大写缓冲区数量，超过将触发合并操作，默认为 2. Options::min_write_buffer_number_to_merge 至少 n 个写缓冲区都填满时，才会进行合并与 Flush，防止合并操作频繁。影响了 L0 的文件个数，太小导致读放大，太大去重效果差。 Memtable 占用的空间越大，则写放大效应越小，因为数据在内存被整理好，磁盘上就越少的内容会被 compaction。Write Buffer size 并非越大越好，会导致 DB 被重新打开时的数据加载时间变长。 2. Block Cache 建议设置为总内存的 1&#x2F;3 左右，剩余留给 Page Cache。所有 CF 的所有 table_options 都必须使用同一个 cache 对象，或者让所有的 DB 所有的 CF 使用同一个 table_options&#x2F;table_factory。 默认 Block 的大小是 4KB，数据未经压缩。经常 bulk scan 可能需要增大 block size，单 key 读写则可能需要减小，修改方式为 Options::block_size，范围为 1KB ~ a few MB。 12345auto cache = NewLRUCache(128 &lt;&lt; 20); // 128MBBlockBasedTableOptions table_options;table_options.block_cache = cache;auto table_factory = new BlockBasedTableFactory(table_options);cf_options.table_factory.reset(table_factory); 3. Compression cf_options.compression 前 n-1 层压缩格式推荐 kLZ4Compression 或 kSnappyCompression cf_options.bottommost_compression 第 n 层压缩格式推荐 kZSTD 或 kZlibCompression 4. Bloom Filters适用于大量点查如 Get()，不适合范围迭代场景 Iterator()。布隆过滤器为每个键使用一定数量的位，推荐值 10 会产生大约 1% 的假阳率。table_options.filter_policy.reset(NewBloomFilterPolicy(10, false)) 5. RateLimter设置每秒处理 request 速率：dbOptions.setRateLimiter(new RateLimiter(200)) 6. Other Recommendation 12345678cf_options.level_compaction_dynamic_level_bytes = true;opts.max_background_jobs = 6;options.bytes_per_sync = 1048576;options.compaction_pri = kMinOverlappingRatio;table_options.block_size = 16 * 1024;table_options.cache_index_and_filter_blocks = true;table_options.pin_l0_filter_and_index_blocks_in_cache = true;table_options.format_version = &lt;the latest version&gt;; 读流程使用持久化在磁盘上不可变的 SST 文件，读路径要比写路径简单很多。要找寻某个 key，只需自顶而下遍历 LSM—Tree。从 MemTable 开始，下探到 L0，然后继续向更低层级查找，直到找到该 key 或者检查完所有 SST 文件为止。 以下是查找步骤： 检索 MemTable。 检索不可变 MemTables。 搜索最近 flush 过的 L0 层中的所有 SST 文件。 对于 L1 层及以下层级，首先找到可能包含该 key 的单个 SST 文件，然后在文件内进行搜索。 搜索 SST 文件涉及： （可选）探测布隆过滤器。 查找 index 来找到可能包含这个 key 的 block 所在位置。 读取 block 文件并尝试在其中找到 key。 预读取1. 自动预读 自动预读仅适用于基于块的表格格式（Block-based table format）。这意味着它仅在 BlockBasedTableOptions 中启用了块化表格时有效。 当 RocksDB 在迭代过程中发现对同一表文件的多个顺序 I&#x2F;O 请求时，它会启动自动预读机制。预读的大小从 8 KB 开始，随着每个额外的顺序 I&#x2F;O 请求的出现，预读的大小呈指数增长，最大为 BlockBasedTableOptions.max_auto_readahead_size，默认最大 256 KB。 条件与限制： 启用条件：自动预读仅在 ReadOptions.readahead_size = 0（默认值）时启用。如果设置为其他值，则会禁用此功能。 I&#x2F;O 模式：在 Linux 系统中，自动预读在缓冲 I&#x2F;O 模式下使用 readahead 系统调用，而在直接 I&#x2F;O 模式下则使用 AlignedBuffer 来存储预读数据。 版本支持：自动迭代器预读从 RocksDB 版本 5.12 开始在缓冲 I&#x2F;O 模式下支持，从 5.15 开始也支持直接 I&#x2F;O 模式。 2. 手动预读控制 如果主要依赖迭代操作并且使用 Page Cache，可以通过设置 DBOptions.advise_random_on_open = false 来选择手动启用预读功能。 这种设置对硬盘驱动器（HDD）或远程存储尤为有用，尤其在这些存储的延迟较高时。对于直连的 SSD，预读对性能的影响可能不明显。 Mergemerge operator描述了原子性的在rocksdb读取修改写入操作，如果用户操作Rocksdb存在获取、修改并且再写入，那么就需要用户来保证它的原子性，merge operator可以解决这个问题。 将读-修改-写的语义封装到一个简单的抽象接口中。 允许用户避免因重复Get()调用而产生额外成本。 在不改变底层语义的情况下，执行后端优化以决定何时&#x2F;如何组合操作数。 在某些情况下，可以摊销所有增量更新的成本，以提供渐进的效率提高。 MergeOperatorMergeOperator定义了几个方法来告诉RocksDB应该如何在已有的数据上做增量更新。这些方法(PartialMerge、FullMerge)可以组成新的merge操作。 AssociativeMergeOperator 接口封装了partial merge的实现细节，可以满足大部分场景的需要。使用AssociativeMergeOperator的一个前提是：数据类型的关联性，即： 调用Put接口写入RocksDB的数据的格式和Merge接口是相同的 使用用户自定义的merge操作，可以将多个merge操作数合并成一个 Generic MergeOperator 还可以用于非关联型数据类型的更新：例如，在RocksDB中保存json字符串，即Put接口写入data的格式为合法的json字符串。而Merge接口只希望更新json中的某个字段。使用场景为： merge 操作数的格式和Put不同 当多个merge操作数可以合并时，PartialMerge()方法返回true AssociativeMergeOperator Folding 123456789101112131415161718192021222324252627282930313233343536// The simpler, associative merge operator.class AssociativeMergeOperator : public MergeOperator &#123; public: virtual ~AssociativeMergeOperator() &#123;&#125; // Gives the client a way to express the read -&gt; modify -&gt; write semantics // key: (IN) The key that&#x27;s associated with this merge operation. // existing_value:(IN) null indicates the key does not exist before this op // value: (IN) the value to update/merge the existing_value with // new_value: (OUT) Client is responsible for filling the merge result // here. The string that new_value is pointing to will be empty. // logger: (IN) Client could use this to log errors during merge. // // Return true on success. // All values passed in will be client-specific values. So if this method // returns false, it is because client specified bad data or there was // internal corruption. The client should assume that this will be treated // as an error by the library. virtual bool Merge(const Slice&amp; key, const Slice* existing_value, const Slice&amp; value, std::string* new_value, Logger* logger) const = 0; private: // Default implementations of the MergeOperator functions virtual bool FullMergeV2(const MergeOperationInput&amp; merge_in, MergeOperationOutput* merge_out) const override; virtual bool PartialMerge(const Slice&amp; key, const Slice&amp; left_operand, const Slice&amp; right_operand, std::string* new_value, Logger* logger) const override;&#125;; 用户需要定义一个子类，继承AssociativeMergeOperator，重载用到的接口。 RocksDB持有一个MergeOperator类型的成员变量，并提供了Merge接口。用户将自定义的MergeOperator子类赋值给DB对应的成员变量，这样RocksDB可以调用用户定义的Merge方法，达到用户定义merge语义的目的。 Folding 1234567891011121314151617181920212223242526272829// In addition to Get(), Put(), and Delete(), the DB class now also has an additional method: Merge().class DB &#123; ... // Merge the database entry for &quot;key&quot; with &quot;value&quot;. Returns OK on success, // and a non-OK status on error. The semantics of this operation is // determined by the user provided merge_operator when opening DB. // Returns Status::NotSupported if DB does not have a merge_operator. virtual Status Merge( const WriteOptions&amp; options, const Slice&amp; key, const Slice&amp; value) = 0; ... &#125;; Struct Options &#123; ... // REQUIRES: The client must provide a merge operator if Merge operation // needs to be accessed. Calling Merge on a DB without a merge operator // would result in Status::NotSupported. The client must ensure that the // merge operator supplied here has the same name and *exactly* the same // semantics as the merge operator provided to previous open calls on // the same DB. The only exception is reserved for upgrade, where a DB // previously without a merge operator is introduced to Merge operation // for the first time. It&#x27;s necessary to specify a merge operator when // opening the DB in this case. // Default: nullptr const std::shared_ptr&lt;MergeOperator&gt; merge_operator; ... &#125;; Folding 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// A &#x27;model&#x27; merge operator with uint64 addition semanticsclass UInt64AddOperator : public AssociativeMergeOperator &#123; public: virtual bool Merge( const Slice&amp; key, const Slice* existing_value, const Slice&amp; value, std::string* new_value, Logger* logger) const override &#123; // assuming 0 if no existing value uint64_t existing = 0; if (existing_value) &#123; if (!Deserialize(*existing_value, &amp;existing)) &#123; // if existing_value is corrupted, treat it as 0 Log(logger, &quot;existing value corruption&quot;); existing = 0; &#125; &#125; uint64_t oper; if (!Deserialize(value, &amp;oper)) &#123; // if operand is corrupted, treat it as 0 Log(logger, &quot;operand value corruption&quot;); oper = 0; &#125; auto new = existing + oper; *new_value = Serialize(new); return true; // always return true for this, since we treat all errors as &quot;zero&quot;. &#125; virtual const char* Name() const override &#123; return &quot;UInt64AddOperator&quot;; &#125;&#125;;// Implement &#x27;add&#x27; directly with the new Merge operationclass MergeBasedCounters : public RocksCounters &#123; public: MergeBasedCounters(std::shared_ptr&lt;DB&gt; db); // mapped to a leveldb Merge operation virtual void Add(const string&amp; key, uint64_t value) override &#123; string serialized = Serialize(value); db_-&gt;Merge(merge_option_, key, serialized); &#125;&#125;;// How to use itDB* dbp;Options options;options.merge_operator.reset(new UInt64AddOperator);DB::Open(options, &quot;/tmp/db&quot;, &amp;dbp);std::shared_ptr&lt;DB&gt; db(dbp);MergeBasedCounters counters(db);counters.Add(&quot;a&quot;, 1);...uint64_t v;counters.Get(&quot;a&quot;, &amp;v); Generic MergeOperator MergeOperator提供了两个方法, FullMerge和PartialMerge. 第一个方法用于对已有的值做Put或Delete操作. 第二个方法用于在可能的情况下将两个操作数合并. AssociativeMergeOperator继承了MergeOperator, 并提供了这些方法的默认实现, 暴露了简化后的接口. MergeOperator的FullMerge方法的传入exsiting_value和一个操作数序列, 而不是单独的一个操作数. Folding 12345678910111213141516171819202122232425262728293031323334353637383940// The Merge Operator//// Essentially, a MergeOperator specifies the SEMANTICS of a merge, which only// client knows. It could be numeric addition, list append, string// concatenation, edit data structure, ... , anything.// The library, on the other hand, is concerned with the exercise of this// interface, at the right time (during get, iteration, compaction...)class MergeOperator &#123; public: virtual ~MergeOperator() &#123;&#125; // Gives the client a way to express the read -&gt; modify -&gt; write semantics // key: (IN) The key that&#x27;s associated with this merge operation. // existing: (IN) null indicates that the key does not exist before this op // operand_list:(IN) the sequence of merge operations to apply, front() first. // new_value: (OUT) Client is responsible for filling the merge result here // logger: (IN) Client could use this to log errors during merge. // // Return true on success. Return false failure / error / corruption. virtual bool FullMerge(const Slice&amp; key, const Slice* existing_value, const std::deque&lt;std::string&gt;&amp; operand_list, std::string* new_value, Logger* logger) const = 0; // This function performs merge(left_op, right_op) // when both the operands are themselves merge operation types. // Save the result in *new_value and return true. If it is impossible // or infeasible to combine the two operations, return false instead. virtual bool PartialMerge(const Slice&amp; key, const Slice&amp; left_operand, const Slice&amp; right_operand, std::string* new_value, Logger* logger) const = 0; // The name of the MergeOperator. Used to check for MergeOperator // mismatches (i.e., a DB created with one MergeOperator is // accessed using a different MergeOperator) virtual const char* Name() const = 0;&#125;; 当调用DB::Put()和DB:Merge()接口时, 并不需要立刻计算最后的结果. RocksDB将计算的动作延后触发, 例如在下一次用户调用Get, 或者RocksDB决定做Compaction时. 所以, 当merge的动作真正开始做的时候, 可能积压(stack)了多个操作数需要处理. 这种情况就需要MergeOperator::FullMerge来对existing_value和一个操作数序列进行计算, 得到最终的值. PartialMerge和Stacking有时候, 在调用FullMerge之前, 可以先对某些merge操作数进行合并处理, 而不是将它们保存起来, 这就是PartialMerge的作用: 将两个操作数合并为一个, 减少FullMerge的工作量.当遇到两个merge操作数时, RocksDB总是先会尝试调用用户的PartialMerge方法来做合并, 如果PartialMerge返回false才会保存操作数. 当遇到Put&#x2F;Delete操作, 就会调用FullMerge将已存在的值和操作数序列传入, 计算出最终的值. CompactionLeveled Compaction 流程大致为： 找到 score 最高的 level 根据一定策略从 level 中选择一个 sst 文件进行 compact，L0 的各个 sst 文件之间 key 有重叠，所以可能一次选取多个 获取 sst 文件的 minkey 和 maxkey 从 level + 1 中选取出于 (minkey, maxkey) 有重叠的 sst 文件，与 level 中的文件进行 merge - sort 作为目标文件，没有重叠文件则把原始文件作为目标文件 对目标文件进行压缩后放入 level + 1 中 L0 subcompaction 参数 maxbackgroundcompactions 大于 1 时，RocksDB 会进行并行 Compact，但 L0 到 L1 层的 Compaction 任务不能进行并行，这会约束整体 compaction 速度。可以设置 max_subcompactions 参数大于 1，尝试把一个文件拆为多个 sub，启动多个线程执行 sub-compact。 Compaction的选择策略 当多个level都满足触发compaction的条件，rocksdb通过计算得分来选择先做哪一个level的compaction。 对于非0 level，score &#x3D; 该level文件的总长度 / 阈值。已经正在做compaction的文件不计入总长度中。 对于L0，score &#x3D; max&#123;文件数量 / level0_file_num_compaction_trigger， L0文件总长度 / max_bytes_for_level_base&#125; 并且 L0文件数量 &gt; level0_file_num_compaction_trigger。 Compaction触发阈值 每一层的compaction阈值设置策略由 level_compaction_dynamic_level_bytes 来决定。 当 level_compaction_dynamic_level_bytes 为 false： L1 触发阈值：max_bytes_for_level_base 下面的level触发阈值通过公式计算：Target_Size(Ln+1) &#x3D; Target_Size(Ln) * max_bytes_for_level_multiplier * max_bytes_for_level_multiplier_additional[n].max_bytes_for_level_multiplier_additional max_bytes_for_level_base &#x3D; 16384max_bytes_for_level_multiplier &#x3D; 10max_bytes_for_level_multiplier_additional &#x3D; 1那么每个level的触发阈值为 L1, L2, L3 and L4 分别为 16384, 163840, 1638400 和 16384000 当 level_compaction_dynamic_level_bytes 为 true： 最后一个level的文件长度总是固定的。 上面level触发阈值通过公式计算：Target_Size(Ln-1) &#x3D; Target_Size(Ln) &#x2F; max_bytes_for_level_multiplier。如果计算得到的值小于 max_bytes_for_level_base &#x2F; max_bytes_for_level_multiplier， 那么该level将维持为空，L0做compaction时将直接merge到第一个有合法阈值的level上。 max_bytes_for_level_base &#x3D; 1Gnum_levels &#x3D; 6level 6 size &#x3D; 276G那么从L1到L6的触发阈值分别为：0， 0， 0.276G， 2.76G， 27.6G，276G。这样分配保证了稳定的 LSM-tree 结构。并且有 90% 的数据在最后一层，9%的数据在倒数第二层 Blobblob_db参考了WiscKey的思想，设计的kv存储分离，可以有效的减小写放大。LSM树里面只存储key和value的地址，这样后台线程compact的时候可以少读写很多数据。rocksdb里面增加一种类型：kTypeBlobIndex 表示value是否blob_db的地址。 写流程首先判断value大小是否超过配置，超过了就写blob_db，然后在把offset和文件id做为value写入lsm树。 否则就是正常的rocksdb写入。如果设置了db最大size，并且磁盘空间超过限制了，就会淘汰删除最老的blob文件。 blob文件格式：head结构|—-|—-|—-|-|-|——–|———|magic version cf_id flag expiration_start expiration_endfoot结构|—-|——–|——–|———|—-|magic count expiration_start expiration_end crc 和sst文件一样，blob文件写完以后，不会被更改，只能被删除。每个blob文件都有size限制，超过这个限制就会和wal一样，重新打开一个blob文件写入。每个blob文件没有类似rocksdb那样的level层级。 读流程主要的流程还是和普通的db一样，增加GetImplOptions里面is_blob_index选项。BlobDBOptions选项里面min_blob_size控制多大的value存储在blob_db中，小于min_blob_size，还是和原来一样，存储在lsm树。根据返回的value类型判断，如果是kTypeBlobIndex，那么就需要再从blob_db获取真正的value，可以看到比原来多了一次读。先需要解码lsm树里面获取的value,找到对应的blob_db里面的文件和offset,然后再获取真正的数据。 GC流程每个blob文件或者会有几个对应的sst文件，或者对应几个memtable。只有blob文件没有关联的sst文件并且blob文件的seq比flush_seq大，才满足被gc删除条件。后台线程会周期性的删除无用的blob文件。Flush memtable的时候会跟进value类型判断，如果valuekTypeBlobIndex，则会更新文件对应的最早的blob文件。Flush完成以后会调用blob的回调函数，建立新的sst文件和blob文件的对应关系。Compact完成以后也会调用blob的回调函数，老的sst文件和blob文件映射关系解除，增加新的sst文件和blob文件的映射关系。 内存结构RocksDB的内存大致有如下四个区： Block Cache Indexes and bloom filters Memtables Blocked pinned by iterators Block Cache在内存中缓存数据用于读取。一个Cache对象可以在同一个进程中被多个 DB 实例共享，从而允许用户控制整个缓存容量。Block Cache 存储未压缩的块，用户可以选择设置第二个 Block Cache 存储压缩块。先读取未压缩的块，再读取压缩的块。如果使用Direct-IO，压缩块缓存可以替代 Page cache。 RocksDB 中有两种缓存实现，分别是 LRUCache 和 ClockCache。两种类型的缓存都被分片以减轻锁争用。默认每个缓存将被分片为最多 64 个分片，每个分片的容量不低于 512k 字节。 Indexes and bloom filtersIndex 由 key、offset 和 size 三部分构成，通常仅索引每个 Block 中的第一个 key（或者是一个代表性的 key）。当 Block Cache 增大 Block Size 时，block 个数必会减小，index 个数也会随之降低，如果减小 key size，index 占用内存空间的量也会随之降低。 filter是 bloom filter 的实现，如果缩小 bloom 占用的空间，可以设置 options.optimize_filters_for_hits = true，则最后一个 level 的 filter 会被关闭，bloom 占用率只会用到原来的 10% 。 默认情况下 index 和 filter block 与 block cache 是独立的，用户不能设定二者的内存空间使用量，但为了控制 RocksDB 的内存空间使用量，可以设置 cache_index_and_filter_blocks = true，将 index &amp; filter 存入 block cache。 需要注意的是，index 与 filter 一般访问频次比 data 高，所以把他们放到一起会导致内存空间与 cpu 资源竞争，进而导致 cache 性能抖动厉害。有两个优化方式： cache_index_and_filter_blocks_with_high_priority = true 和 high_pri_pool_ratio = 0.8，会把 LRU Cache 划分为高低优先级的两个区域，data 放在 low 区，index 和 filter 放在 high 区，如果高区占用的内存空间超过了 80%，则会侵占 low 区的尾部数据空间。 pin_l0_filter_and_index_blocks_in_cache 设为 true，把 level0 的 index 以及 filter block 放到 Block Cache 中，因为 l0 访问频次最高，一般内存容量不大，占用不了多大内存空间。 如果 cache_index_and_filter_blocks = false（默认值），index&#x2F;filter 个数就会受 max_open_files 影响，官方建议把这个选项设置为 -1，以方便 RocksDB 加载所有的 index 和 filter 文件，最大化程序性能。 Memory pool不管 RocksDB 有多少 column family，一个 DB 只有一个 WriteController，一旦 DB 中一个 column family 发生堵塞，那么就会阻塞其他 column family 的写。RocksDB 写入时间长了以后，可能会不定时出现较大的写毛刺，可能有两个地方导致 RocksDB 会出现较大的写延时： 获取 mutex 时可能出现几十毫秒延迟：因为 flush&#x2F;compact 线程与读写线程竞争导致的，可以通过调整线程数量降低毛刺时间。 数据写入 memtable 时候可能出现几百毫秒延时：解决方法一就是使用大的 page cache，禁用系统 swap 以及配置 min_free_kbytes、dirty_ratio、dirty_background_ratio 等参数来调整系统的内存回收策略，更基础的方法是使用内存池。 采用内存池时，memtable 的内存分配和回收流程图如下： 磁盘结构RocksDB 磁盘上的数据种类： DB 的操作日志 存储实际数据的 SSTable 文件 DB 的元信息 Manifest 文件 记录当前正在使用的 Manifest 文件，它的内容就是当前的 Manifest 文件名 系统的运行日志，记录系统的运行信息或者错误日志 临时数据库文件，repair 时临时生成的 Write Ahead Log 如上图，log 文件的逻辑单位是 Record，物理单位是 block，每个 Record 可以存在于一个 block 中，也可以占用多个 block。Record 的详细结构见上图文字部分，其 type 字段的意义见下图，如果某 KV 过长则可以用多 Record 存储。 Manifest MANIFEST 是指在事务日志中跟踪 RocksDB 状态变化的系统Manifest-&lt;seq no&gt; 是指包含 RocksDB 状态快照&#x2F;编辑的单个日志文件CURRENT 是指当前最新的 mainfest log RocksDB 是文件系统和存储介质无关的。文件系统操作不是原子操作，在系统故障时很容易出现不一致。即使打开了日志记录，文件系统也不能保证不干净重启时的一致性，POSIX 文件系统也不支持原子批处理操作。为了避免进程崩溃或机器宕机导致的数据丢失，RocksDB 需要将元信息数据持久化到磁盘，承担这个任务的就是 Manifest 文件，每当有新的Version产生都需要更新 Manifest。 Manifest 文件记录了 DB 状态变化的事务性日志，即所有改变 DB 状态的操作。任意时间存储引擎的状态都会保存为一个Version（即SST的集合），而每次对 Version 的修改都是一个VersionEdit，而最终这些 VersionEdit 就是组成 Manifest 文件的内容。在 Manifest 中的一次增量内容称作一个Block，Manifest Block 的详细结构如下图所示： RocksDB 进程 Crash 后 Reboot 的过程中，会首先读取 Manifest 文件在内存中重建 LSM 树，然后根据 WAL 日志文件恢复 Memtable 内容。 下图是 leveldb 的 Manifest 文件结构，这个 Manifest 文件有以下文件内容： VersionSetVersionSet 是 RocksDB 用于管理数据库版本和存储布局的核心结构。它包含了关于当前数据库版本的信息，以及该版本所包含的 SST 文件、ColumnFamily、memtable 等的状态信息。 RocksDB 的 Version 表示一个版本的 metadata，其主要内容是 FileMetaData 指针的二维数组，分层记录了所有的SST文件信息。FileMetaData 用来维护一个文件的元信息，包括文件大小、文件编号、最大最小值、引用计数等信息，其中引用计数记录了被不同的 Version 引用的个数，保证被引用中的文件不会被删除。 Version中还记录了触发 Compaction 相关的状态信息，这些信息会在读写请求或 Compaction 过程中被更新。在 CompactMemTable 和 BackgroundCompaction 过程中会导致新文件的产生和旧文件的删除，每当这个时候都会有一个新的对应的 Version 生成，并插入 VersionSet 链表头部，LevelDB 用 VersionEdit 来表示这种相邻 Version 的差值。 VersionSet 结构如上图所示，它是一个 Version 构成的双向链表，这些 Version 按时间顺序先后产生，记录了当时的元信息，链表头指向当前最新的 Version，同时维护了每个 Version 的引用计数，被引用中的 Version 不会被删除，其对应的 SST 文件也因此得以保留，通过这种方式，使得LevelDB 可以在一个稳定的快照视图上访问文件。VersionSet 中除 Version 的双向链表外还会记录一些如 LogNumber、Sequence、下一个SST文件编号的状态信息。 MetaData Restore上图最上面的流程显示了恢复元信息的过程，也就是一次应用 VersionEdit 的过程，这个过程会有大量的临时 Version 产生，但这种方法显然太过于耗费资源，LevelDB 引入 VersionSet::Builder 来避免这种中间变量，方法是先将所有的 VersoinEdit 内容整理到 VersionBuilder 中，然后一次应用产生最终的 Version，如上图下部分所示。 数据恢复的详细流程如下： 依次读取Manifest文件中的每一个Block，将从文件中读出的 Record 反序列化为 VersionEdit； 将每一个的 VersionEdit Apply 到 VersionSet::Builder 中，进而生成Version； 计算compactionlevel、compactionscore； 将新生成的 Version 挂到 VersionSet 中，并初始化 VersionSet 的 manifestfilenumber，nextfilenumber，lastsequence，lognumber，prevlognumber 信息； SST file SSTfile 结构如下，大致分为几个部分： Data Block 直接存储有序键值对，是 SSTfile 的数据实体 Meta Block 存储 Filter 相关信息 Meta Index Block 是 Meta Block 的索引，它只有一条记录 Index Block 是 Key 到 Data Block 的索引，是提高查询效率的关键 Footer 指向各个分区的位置和大小 1234567891011121314&lt;beginning_of_file&gt;[data block 1][data block 2]…[data block N][meta block 1: filter block][meta block 2: stats block][meta block 3: compression dictionary block]…[meta block K: future extended block][metaindex block][index block][Footer]&lt;end_of_file&gt; RocksDB 执行查询或修改时会引用当前 version，对该 version 下的 sst file 设置 reference count，Compact完成后要等 reference count 降为 0 后才能将文件真正的删除。 Block结构如下图： Record 结构如下图： Footer 结构如下图： MemtableMemtable 中存储了一些 metadata 和 data，data 在 skiplist 中存储。metadata 数据如下： 当前日志句柄； 版本管理器、当前的版本信息（对应 compaction）和对应的持久化文件标示； 当前的全部db配置信息比如 comparator 及其对应的 memtable 指针； 当前的状态信息以决定是否需要持久化 memtable 和合并 sstable； sstable 文件集合的信息。 SnapshotRocksDB 每次进行更新操作就会把更新内容写入 Manifest 文件，同时它会更新版本号。 版本号是一个 8 字节的证书，每个 key 更新时，除了新数据被写入数据文件，同时记录下 RocksDB 的版本号。RocksDB 的 Snapshot 数据仅仅是逻辑数据，并没有对应的真实存在的物理数据，仅仅对应一下当前 RocksDB 的全局版本号而已，只要 Snapshot 存在，每个 key 对应版本号的数据在后面的更新、删除、合并时会一并存在，不会被删除，以保证数据一致性。 CheckpointsCheckpoints 是 RocksDB 提供的一种 snapshot，独立的存在一个单独的不同于 RocksDB 自身数据目录的目录中，既可以 ReadOnly 模式打开，也可以 Read-Write 模式打开。Checkpoints 被用于全量或者增量 Backup 机制中。 如果 Checkpoints 目录和 RocksDB 数据目录在同一个文件系统上，则 Checkpoints 目录下的 SST 是一个 hard link（SST 文件是 Read-Only的），而 manifest 和 CURRENT 两个文件则会被拷贝出来。如果 DB 有多个 Column Family，wal 文件也会被复制，其时间范围足以覆盖 Checkpoints 的起始和结束，以保证数据一致性。 如果以 Read-Write 模式打开 Checkpoints 文件，则其中过时的 SST 文件会被删除掉。 BackupRocksDB 提供了 point-of-time 数据备份功能，可以调用 BackupEngine::CreateNewBackup(db, flush_before_backup &#x3D; false) 接口进行数据备份， 其大致流程如下： 禁止删除文件（sst 文件和 log 文件）； 调用 GetLiveFiles() 获取当前的有效文件，如 table files, current, options and manifest file; 将 RocksDB 中的所有的 sst&#x2F;Manifest&#x2F;配置&#x2F;CURRENT 等有效文件备份到指定目录；GetLiveFiles() 接口返回的 SST 文件如果已经被备份过，则这个文件不会被重新复制到目标备份目录，但是 BackupEngine 会对这个文件进行 checksum 校验，如果校验失败则会中止备份过程。 如果 flush_before_backup 为 false，则BackupEngine 会调用 GetSortedWalFiles() 接口把当前有效的 wal 文件也拷贝到备份目录； 重新允许删除文件。 sst 文件只有在 compact 时才会被删除，所以禁止删除就相当于禁止了 compaction。别的 RocksDB 在获取这些备份数据文件后会依据 Manifest 文件重构 LSM 结构的同时，也能恢复出 WAL 文件，进而重构出当时的 memtable 文件。 在进行 Backup 的过程中，写操作是不会被阻塞的，所以 WAL 文件内容会在 backup 过程中发生改变。RocksDB 的 flushbeforebackup 选项用来控制在 backup 时是否也拷贝 WAL，其值为 true 则不拷贝。 Snapshot 仅仅存在于逻辑概念上，其对应的实际物理文件可能正被 compaction 线程执行写任务；Checkpoint 则是实际物理文件的一个镜像，或者说是一个硬链接，而出处于同样的 Env 下（都是 RocksDB 数据文件格式）；Backup 虽然也是物理数据的镜像，但是与原始数据处于不同的 Env 下（如 backup 可能在 HDFS 上）； 调优配置如何保证数据快速写入RocksDb 使用单个写入线程并且有序插入 将数百个键批量写入一批 memtable底层数据结构使用vector 确保options.max_background_flushes至少为4 在插入数据之前，禁用自动压缩，将 options.level0_file_num_compaction_trigger、options.level0_slowdown_writes_trigger 和 options.level0_stop_writes_trigger 设置为非常大的值。插入所有数据后，发出手动压缩。如果调用了Options::PrepareForBulkLoad()，后面三个方法会被自动启用； 可以通过 SstFileWriter 直接创建 SST 文件并添加到 RocksDB 中。但是它的键范围一定不能与数据库重叠。 WriteStall触发场景当RocksDB的flush或compact 速度落后于数据写入速度就会增加空间放大和读放大，可能导致磁盘空间被撑满或严重的读性能下降，为此则需要限制数据写入速度或者完全停止写入，这个限制就是write stall，触发原因有三个： 1. memtable数量过多 当memtable数量达到min-write-buffer-number-to-merge (默认值为1) 参数个时会触发flush，Flush慢主要由于磁盘性能问题引起 当等待flush的memetable数量达到参数max-write-buffer-number时会完全停止写入。当max-write-buffer-number&gt;3且等待flush的memetable数量&gt;&#x3D;参数max-write-buffer-number-1时会降低写入速度。 当由于memtable数量引起write stall时，内存充足的情况下可尝试调大max-write-buffer-number、max_background_jobs 、write_buffer_size 进行缓解。 2. L0数量过多 当L0 sst文件数达到level0_slowdown_writes_trigger后会触发write stall 降低写入速度，当达到level0_stop_writes_trigger则完全停止写入。 当由于memtable数量引起write stall时，内存充足的情况下可尝试调大max_background_jobs 、write_buffer_size、min-write-buffer-number-to-merge进行缓解。 3. 待compact的数据量过多 当需要compact的文件数量达到soft_pending_compaction_byte参数值时会触发write stall，降低写入速度，当达到hard_pending_compaction_byte时会完全停止写入. FAQ 如果机器崩溃后重启，则 RocksDB 能够恢复的数据是同步写【WriteOptions.sync&#x3D;true】调用 DB::SyncWAL() 之前的数据 或者已经被写入 L0 的 memtable 的数据都是安全的； 可以通过 GetIntProperty(cf_handle, “rocksdb.estimate-num-keys”) 获取一个 column family 中大概的 key 的个数； 可以通过 GetAggregatedIntProperty(“rocksdb.estimate-num-keys”, &amp;num_keys) 获取整个 RocksDB 中大概的 key 的总数，之所以只能获取一个大概数值是因为 RocksDB 的磁盘文件有重复 key，而且 compact 的时候会进行 key 的淘汰，所以无法精确获取； 当进程中还有线程在对 RocksDB 进行 读、写或者手工 compaction 的时候，不能强行关闭它； 关闭 RocksDB 对象时，如果是通过 DestroyDB() 去关闭时，这个 RocksDB 还正被另一个进程访问，则会造成不可预料的后果； 当 BackupOptions::backup_log_files 或者 flush_before_backup 的值为 true 的时候，如果程序调用 CreateNewBackup() 则 RocksDB 会创建 point-in-time snapshot，RocksDB进行数据备份的时候不会影响正常的读写逻辑； RocksDB 启动之后不能修改 prefix extractor； SstFileWriter API 可以用来创建 SST 文件，如果这些 SST 文件被添加到别的 RocksDB 数据库发生 key range 重叠，则会导致数据错乱； 使用多磁盘时，RAID 的 stripe size 不能小于 64kb，推荐使用1MB； RocksDB 可以针对每个 SST 文件通过 ColumnFamilyOptions::bottommost_compression 使用不同的压缩的方法； 当多个 Handle 指向同一个 Column Family 时，其中一个线程通过 DropColumnFamily() 删除一个 CF 的时候，其引用计数会减一，直至为 0 时整个 CF 会被删除； RocksDB 接受一个写请求的时候，可能因为 compact 会导致 RocksDB 多次读取数据文件进行数据合并操作； RocksDB 不直接支持数据的复制，但是提供了 API GetUpdatesSince() 供用户调用以获取某个时间点以后更新的 kv； options.prefixextractor 一旦启用，就无法继续使用 Prev() 和 SeekToLast() 两个 API，可以把 ReadOptions.totalorder_seek 设置为 true，以禁用 prefix iterating； 当 BlockBaseTableOptions::cache_index_and_filter_blocks 的值为 true 时，在进行 Get() 调用的时候相应数据的 bloom filter 和 index block 会被放进 LRU cache 中，如果这个参数为 false 则只有 memtable 的 index 和 bloom filter 会被放进内存中； 当调用 Put() 或者 Write() 时参数 WriteOptions.sync 的值为 true，则本次写以前的所有 WriteOptions.disableWAL 为 false 的写的内容都会被固化到磁盘上； 禁用 WAL 时，DB::Flush() 只对单个 Column Family 的数据固化操作是原子的，对多个 Column Family 的数据操作则不是原子的，官方考虑将来会支持这个 feature； 当使用自定义的 comparators 或者 merge operators 时，ldb 工具就无法读取 sst 文件数据； RocksDB 执行前台的 Get() 和 Write() 任务遇到错误时，它会返回 rocksdb::IOError 具体值； RocksDB 执行后台任务遇到错误时 且 options.paranoid_checks 值为 true，则 RocksDB 会自动进入只读模式； RocksDB 一个线程执行 compact 的时候，这个任务是不可取消的，可以在另一个线程调用 CancelAllBackgroundWork(db, true) 以中断正在执行的 compact 任务； 当多个进程打开一个 RocksDB 时，如果指定的 compact 方式不一样，则后面的进程会打开失败； RocksDB 不支持多列； RocksDB 的读并不是无锁的，有如下情况：(1) 访问 sharded block cache (2) 如果 table cache options.maxopenfiles 不等于 -1 (3) 如果 flush 或者 compaction 刚刚完成，RocksDB 此时会使用全局 mutex lock 以获取 LSM 树的最新 metadata (4) RocksDB 使用的内存分配器如 jemalloc 有时也会加锁，这四种情况总体很少发生，总体可以认为读是无锁的； 如果想高效的对所有数据进行 iterate，则可以创建 snapshot 然后再遍历； 如果一个 key space range (minkey, maxkey) 很大，则使用 Column Family 对其进行 sharding，如果这个 range 不大则不要单独使用一个 Column Family； RocksDB 没有进行 compaction 的时候，可以通过 rocksdb.estimate-live-data-size 可以估算 RocksDB 使用的磁盘空间； 即使没有被标记为删除的 key，也没有数据过期，RocksDB 仍然会执行 compaction，以提高读性能； RocksDB 的 key 和 value 是存在一起的，遍历一个 key 的时候，RocksDB 已经把其 value 读入 cache 中； 对于一个离线 DB 可以通过 sstdump –showproperties –command&#x3D;none 命令获取特定 sst 文件的 index &amp; filter 的 size，对于正在运行的 DB 可以通过读取 DB 的属性 kAggregatedTableProperties 或者调用 DB::GetPropertiesOfAllTables() 获取 DB 的 index &amp; filter 的 size。","categories":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/categories/Storage/"}],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/tags/Storage/"}]},{"title":"Linux","slug":"OS/Linux","date":"2025-02-03T23:00:04.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2025/02/03/OS/Linux/","permalink":"http://example.com/2025/02/03/OS/Linux/","excerpt":"","text":"Cgroup进程绑核 12345678910cd /sys/fs/cgroup/cpusetmkdir mygroup &amp;&amp; cd mygroup## 避免报错 write error: No space left on deviceecho 0 &gt; cpuset.mems## 限制进程运行在对应的 processorecho &quot;0-19,40-59&quot; &gt; cpuset.cpus## 进程加入 cgroupecho 4462 &gt; cgroup.proc## 加入上级解除限制（或等进程结束）echo 4462 &gt; ../cgroup.procs Linux Cgroup系列（04）：限制cgroup的内存使用 火焰图生成与解析 环境准备 1234# 安装 Linux 系统的 perf 工具yum -y install perf# 下载生成火焰图的工具git clone https://github.com/brendangregg/FlameGraph.git 数据采样，解析生成火焰图 12perf record -a -g -F99 --call-graph dwarf -p &lt;pid&gt; sleep 30perf script | ./FlameGraph/stackcollapse-perf.pl | ./FlameGraph/flamegraph.pl &gt; process.svg 常用命令 1234567-p &lt;pid&gt;：指定待分析进程的 pid（多个用,分隔列表）-t &lt;tid&gt;：指定待分析线程的 tid（多个用,分隔列表）-a：从所有 CPU 收集系统数据-g：开启 call-graph (stack chain/backtrace) 记录-C &lt;cpu-list&gt;：只统计指定 CPU 列表的数据，如：0,1,3或1-2-F &lt;n&gt;：每秒采样 n 次-o &lt;output.data&gt;：指定输出文件output.data，默认输出到perf.data perf 火焰图大量 unknown 的问题 在实际使用过程中发现，简单的使用 perf record -g 获取到的调用栈是有问题的，存在大量 Unknown 函数，从 perf report 的结果来看这些部分对应地址大部分都是非法地址，且生成的火焰图中存在很多明显与代码矛盾的调用关系。 perf 同时支持 3 种栈回溯方式：fp, dwarf, lbr，可以通过 --call-graph 参数指定，而 -g 就相当于 --call-graph fp 优点 缺点 fp None 默认 fp 被优化掉了根本不可用 lbr 高效准确 较新的 Intel CPU 才有此功能，能记录的调用栈深度有限 dwarf 准确 开销相对较大，需要编译时加 -g Linux命令网络与进程 netstat [选项] 查看网络状态，-i网卡信息，-anp | grep port查看占用端口进程 ipcs 显示共享内存段、消息队列和信号量的信息 ifconfig 显示或设置网络设备，配置IP、MAC地址、启动网卡 lsof 查看文件被哪个进程修改lsof tmp.txt，查看端口占用 lsof -i :8080 fdisk 创建和维护分区表 tcpdump 抓包 route 查看路由 pgrep dummy 查看进程号，-l显示进程名 pkill dummy Kill进程名，-f全匹配command line ps aux | grep -w &#39;hello&#39; | grep -v grep | awk &#39;&#123;print $2&#125;&#39; | xargs kill -9 Kill进程名的另一种方式 文件查找与操作 sed -i &quot;s/查找字段/替换字段/g&quot; src.txt head -n log.txt 查看前 n 行 tail -f log.txt 查看尾行（实时刷新） which 查找某一命令所在的路径,格式为 which 命令 whereis 命令与其类似,但是 whereis 还能展示命令帮助文档所在的路径 find 格式为 find &#123;path&#125; -name &#123;xxx&#125; locate 功能与 find -name 相同,find 是遍历了搜索路径下的每个文件,而 locate 是搜索/var/lib/locatedb 里的一个数据库,相当于散列查找。在使用 locate 命令之前,可先使用 updatedb 命令手动更新数据库。 headlink -f . 查看当前路径 zxvf xxx.tar.gz -C dst_dir/ &gt; /dev/null 2&gt;&amp;1 解压缩 mount挂载 硬盘:mount 设备 挂载点 镜像:mount -o rw -t iso9660 设备 挂载点,rw读写,ro只读 Shell编程中控机命令 12scp /home/web_server/mazhuang/load.sh web_server@$&#123;host&#125;:/home/web_server/mazhuang/ssh -n $&#123;host&#125; &quot;sh /home/web_server/mazhuang/load.sh&quot; Kill进程 1234567pkill -f $directory/dummyuntil [[ -z `ps aux | awk &#x27;&#123;print $11&#125;&#x27; | grep -v grep | grep &quot;$directory/dummy&quot;` ]]; do sleep 1sdoneif [[ -z `ps aux | awk &#x27;&#123;print $11&#125;&#x27; | grep -v grep | grep &quot;dummy&quot;` ]]; then echo -e &quot;\\e[31mWARNING: Failed to kill a process. \\e[0m&quot;fi Vim命令模式 级别 操作符 说明 行级 0 光标移动到当前行首字符 段落级 { 光标移动到段落首字符 段落级 } 光标移动到段落尾字符 屏幕级 H 光标移动到屏幕首行首字符 屏幕级 L 光标移动到屏幕尾行首字符 文档级 G 光标移动到文档尾行首字符 段落级 y{ 从段落首字符开始复制直到当前字符(不包括) 段落级 y} 从当前字符开始复制直到段落尾字符(包括) 文档级 yG 从当前行开始复制直到文档尾行(包括) 底行模式 操作符 说明 :s&#x2F;被替换&#x2F;替换&#x2F; 替换当前行的第一目标 :s&#x2F;被替换&#x2F;替换&#x2F;g 替换当前行的全部目标 :%s&#x2F;被替换&#x2F;替换&#x2F;g 替换整个文档的全部目标 :%s&#x2F;被替换&#x2F;替换&#x2F;gc 替换文档全部目标并询问 设置 说明 set number 设置行号 set smartindent 智能对⻬ set cindent C语言格式对⻬ set showmatch 括号匹配 set tabstop&#x3D;2 Tab为2个空格 set mouse&#x3D;a 鼠标支持 调试 GDB断点的原理： 断点替换：在指定的地址处，GDB 会替换原有的指令为 int 3 中断指令。当程序执行到该位置时，会产生一个中断信号。GDB 捕获信号后，会停止程序进入调试模式。 保存原指令：GDB 会保存被替换的原始指令，以便在断点被移除时能够恢复。 命令 含义 gdb attach 调试附加到进程 gcore 生成core pstack 查看栈帧信息 info registers &#x2F; print $eax 查看寄存器值 C&#x2F;C++编译g++编译参数 -g 编译带调试信息的可执行文件 -o 指定输出文件名 -O2 优化源代码 -Wall 打印警告信息，-w 关闭警告信息 -std=c++11 设置编译标准 -D 定义宏 1g++ -D USERM test.cpp -l 指定库文件 -L指定库文件路径 1234# 库文件在/lib和/usr/lib和/usr/local/lib里直接用-l链接g++ -lpthread test.cpp# 库文件不在上面三个目录里用-L指定库文件目录g++ -L/home/yveltal/mylibfolder -lmytest test.cpp -I 指定头文件搜索目录 12# 头文件不在/usr/include里用I参数指定，相对路径可以用-I.来指定g++ -I/myinclude test.cpp Cmake指定特定版本gcc服务器上有多个版本gcc时，cmake可能会使用老版本的gcc&#x2F;g++通过 which gcc 和 gcc/g++ --version 确定正确版本路径后，在cmake命令时加入对应gcc和g++的位置： 1cmake .. -D CMAKE_C_COMPILER=/path/to/gcc/bin/gcc -D CMAKE_CXX_COMPILER=/path/to/gcc/bin/g++ 重要指令 add_library - 生成库文件 1add_library(libname [SHARED|STATIC] $&#123;SRC&#125;) add_compile_options - 添加编译参数 1add_compile_options(-Wall -std=c++11 -O2) add_executable - 生成可执行文件 1add_executable(main main.cpp test.cpp) add_subdirectory - 向工程添加存放源文件的子目录，其中需有一个CMakeLists.txt 1add_subdirectory(src) include_directories - 引入头文件目录 link_directories - 引入库目录，如工程编译时可能用到第三方库的 lib 文件 link_libraries - 引入库文件到当前工程（全路径） target_link_libraries - 引入库文件到子工程，即分配，故需指定子工程 1target_link_libraries(子工程名 库文件1 库文件2 ...) target_include_directories - 引入头文件目录到子工程，同5 编译工程1234vim CMakeLists.txtmkdir build &amp;&amp; cd buildcmake ..make","categories":[{"name":"OS","slug":"OS","permalink":"http://example.com/categories/OS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"Memo","slug":"Other/Memo","date":"2025-02-02T00:00:22.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2025/02/02/Other/Memo/","permalink":"http://example.com/2025/02/02/Other/Memo/","excerpt":"","text":"Protobuf vs FlatBuffersFlatBuffersFlatBuffers在序列化时计算了各字段在数据体的偏移量，并存储在数据体中。因此，反序列化时，先读取字段的偏移量再读取数据即可。因为反序列化过程没有内存拷贝、数据解码等耗时操作，所以速度非常快，但是数据量比原数据有所增加。此外，生成的代码量较少，CPU占用较低 场景：延迟和性能要求高，特别是在数据不需要全部加载到内存中的场景 Protobuf压缩后的数据包更小，但序列化与反序列化都比较重度，生成的代码量较大，CPU占用较高，内存占用较多。语言支持更广，解决方案更广泛、成熟 场景：适用于需要高效传输大量数据的分布式应用，如网络通信和数据存储 技巧：消息的字段数量不超过15、正数使用uint而非int、尽量控制int32或int64型数据在0~127 RPCGRPCgRPC是一种高性能 RPC 框架。使用Protocol Buffers作为二进制序列化，并使用HTTP&#x2F;2协议进行传输。gRPC基于服务的思想：定义一个服务，描述这个服务的方法以及入参出参，服务器端有这个服务的具体实现，客户端保有一个存根，提供与服务端相同的服务。 基于 ProtoBuf 接口定义语言：它可以定义服务的方法和消息类型，并生成各种语言的代码桩，实现跨平台。 HTTP&#x2F;2作为底层传输协议：支持二进制传输效率高、双向流、消息头压缩、单 TCP 的多路复用、服务端推送等。 支持流式数据：gRPC支持流式传输，即服务可以持续发送数据，而客户端可以持续接收数据。这在传输大量数据时非常有用。 gRPC同时支持同步调用和异步调用，同步RPC调用时会一直阻塞直到服务端处理完成返回结果，异步RPC是客户端调用服务端时不等待服务段处理完成返回，而是服务端处理完成后主动回调客户端告诉客户端处理完成 gRPC与HTTP&#x2F;2的关系：HTTP&#x2F;2为长连接、实时的通信流提供了基础。gRPC建立在这个基础之上，具有连接池、健康语义、高效使用数据帧和多路复用以及KeepAlive，gRPC的通讯基石就是HTTP&#x2F;2 基于http2协议的特性：gRPC允许定义如下四类服务方法 一元RPC：客户端发送一次请求，等待服务端响应结构，会话结束，就像一次普通的函数调用这样简单 服务端流式RPC：客户端发起一起请求，服务端会返回一个流，客户端会从流中读取一系列消息，直到没有结果为止 客户端流式RPC：客户端提供一个数据流并写入消息发给服务端，一旦客户端发送完毕，就等待服务器读取这些消息并返回应答 双向流式RPC：客户端和服务端都一个数据流，都可以通过各自的流进行读写数据，这两个流是相互独立的，客户端和服务端都可以按其希望的任意顺序独写 名称解析器和负载平衡器：解析器将名称转换为地址，然后将这些地址交给负载均衡器。负载均衡器负责从这些地址创建连接，并在连接之间对rpc进行负载均衡。 当连接失败时，负载均衡器将开始使用最后已知的地址列表重新连接。同时，解析器将开始尝试重新解析主机名列表，告知负载均衡器。 对于失效连接： 对方主动关闭、超时计时器情况：TCP的 FIN 语义即可完成 HTTP2&#x2F;GRPC 连接的关闭 端点死亡、挂起而不通知客户端：TCP得长时间重试，gRPC 使用 HTTP2 语义中的 PING 帧绕过流量控制，判断连接是否有效 BRPC特点 性能好，M：N （bthread:pthread）高效轻量的线程模型 自带性能监控和分析功能：bvar，一般的RPC框架没有提供热点分析、延时统计的工具，brpc通过自带的 bvar 能够监控并采集到多种性能相关的数据，便于快速确定热点、定位瓶颈。 Bthread线程模型：1:1，一个内核线程里只有一个用户线程。利于调度到其他核上，多核扩展性好。缺点：线程锁、线程调度到另一个CPU时，data要从L1 cache同步到其他cpu，锁住总线。 协程模型：n:1，n个用户线程跑在一个CPU上。无多线程竞争，数据的locality好，但难以扩展到多核，一个线程阻塞会阻塞整个内核线程。 Bthread 通过实现上层 M：N 线程绑定减小了线程间的来回调度，减小了cache buncing；通过内部的多个队列和 stealing worker 机制，保证了整体的并发度QPS*latency最大； Bthread的机制核心是 work stealing，即 pthread 之间可以偷bthread来执行。每个bthread两种调度方式，既可以只在某一个内核线程里调度（locality不错），也可以在该bthread被卡住时，允许被偷到其他内核线程去运行，只要有空闲的worker(pthread)在，就不会有bthread被阻塞，保证了多核在任意时刻只要有bthread被创建出来就可以去跑任务。 内存管理BRPC通过IOBuf（非连续零拷贝缓存）方式减少数据传递处理过程中的拷贝，提高了数据传输效率。此外，各种ThreadLocal的ResourcePool、Object Pool等优化了定长的短生命周期的申请和释放，减少了内存分配和释放的开销。 执行队列BRPC使用多生产者单消费者无锁队列作为执行队列，实现了多生产者单消费者之间的的高效通信。这种队列设计避免了锁竞争和线程同步的问题，提高了系统的吞吐量和并发性能。在实现单TCP连接复用、高效发送-接收数据等方面发挥了很重要的作用。 StreamLoader1234class CompoundLoader : StreamLoaderBase &#123; map&lt;int32, vector&lt;PerDbData&gt;&gt; table_db_map_ map&lt;string, LoaderProcessor*&gt; loaders; // hive, kafka, btq...&#125; 退出方式： per_db-&gt;stop &#x3D; true，Processor::ThreadWork 循环中检测退出 StreamLoaderBase::ThreadWorkBase 退出，此时所有 ThreadWork 线程已 join StreamLoaderBase 唤醒 CondVar，通过 BeforeUnsubscribe() 停止consumer消费（线程还在写数据，等写完一条通过flag退出了，才唤醒cv，执行后续 unsubscribe） 关于offset： 框架由db传入，若db没记录则从 info_file 获取 框架定期调用 GetSubscribeInfo 将 offset 持久化到文件中 StreamLoaderBase123456789101112131415161718192021void Subscribe() &#123; SetOptions() AfterSubscribe() &#123; loaders-&gt;AfterSubscribe() &#125; work_threads.emplace_back(&amp;StreamLoaderBase::ThreadWorkBase)&#125;void Unsubscribe() &#123; loaders-&gt;BeforeUnsubscribe()&#125;void ThreadWorkBase() &#123; CompoundLoader::ThreadWork() &#123; threads.emplace_back(&amp;LoaderProcessor::ThreadWork) threads.join(); &#125; cv_.SignalAll();&#125;void PauseSubscribe() &#123; per_db.pause = true; &#125;void ResumeSubscribe() &#123;per_db.pause = false; per_db.pause_notifier_.Notify(); &#125;bool LagNearLatest() &#123; return Processor::PerDbLagNearLatest(); &#125; Kafka Processor工具函数 123456789// 调 Kafka client, 根据 timestamp 查找offset (-1 latest, -2 earliset)bool QueryOffset(shared_ptr&lt;RawConsumer&gt; &amp;consumer, string &amp;kafka_cluster_id, string &amp;kafka_topic, int partition, int64_t timestamp, int64_t *kafka_offset);// last_offset 最后消费到的offset (多个取最早)， latest_offset Kafka中最新的 offsetvoid GetOffset(PerDbData *per_db, int64_t *last_offset, int64_t *latest_offset);// 是否丢数据：当前 offset &lt; kafka earliset offsetbool IsOffsetGapExcessive() 功能函数 123456789101112131415161718192021222324252627282930void AfterSubscribe(ExternStateDB *db, PerDbData *per_db) &#123; // 计算 offset, 获取kafka client consumer开始消费 offset = max(earliset_offset, to_consume_offset); consumer = GetRawConsumerByLogicalTopicId(); consumer-&gt;Start(cluster_id, topic_name, partition, offset); // 记录当前db消费offset per_db-&gt;topic_last_offset = offset; // 过于落后则 remove DB&#125;// consumer-&gt;Stop() 释放kafka clientvoid BeforeUnsubscribe(ExternStateDB *db, PerDbData *per_db);// max_latest_offset - last_offset &gt; FLAG ?bool PerDbLagNearLatest(ExternStateDB *db, PerDbData *per_db, int max_lag_offset);// need sync (ckpt)?void PerDbOffsetExpired(ExternStateDB *db, PerDbData *per_db, const std::unordered_map&lt;std::string, std::string&gt; &amp;offset, bool *need_sync);void ThreadWork(ExternStateDB *db, PerDbData *per_db, vector&lt;PerDbData&gt; *table_dbs, int thread_id) &#123; while (true) &#123; if (per_db-&gt;stop) break; if (per_db-&gt;pause) wait(FLAGS_kafka_pause_s); pre_db-&gt;topic_latest_offsets = QueryOffset() // kafka latest offset msg = per_db-&gt;consumer-&gt;Consume() per_db-&gt;topic_last_offset = msg-&gt;offset(); // consume offset per_db-&gt;db-&gt;StreamLoaderPut(msg-&gt;payload(), msg-&gt;len(), topic, msg-&gt;timestamp(), msg-&gt;offset()); &#125;&#125; Hive Processor1234567891011121314151617181920void ThreadWork(ExternStateDB *db, PerDbData *per_db, vector&lt;PerDbData&gt; *table_dbs, int thread_id) &#123; while (true) &#123; for (hdfs_path : paths) &#123; read_paths = GetReadPath(hdfs_path) for (file_path : read_paths) &#123; file = Open(file_path) buffer_file = BufferedFile(file) per_db-&gt;db-&gt;StreamLoaderFileStart() StreamLoaderPutByBlocks() per_db-&gt;db-&gt;StreamLoaderFileEnd() &#125; &#125; &#125;&#125;void StreamLoaderPutByBlocks(BufferedFile &amp;buffer_file,) &#123; while (true) &#123; string block = buffer_file.ReadLine() per_db-&gt;db-&gt;StreamLoaderPut(block.data(), block.size(), ...) &#125;&#125;","categories":[{"name":"Other","slug":"Other","permalink":"http://example.com/categories/Other/"}],"tags":[]},{"title":"Notes","slug":"Other/Notes","date":"2025-02-01T23:46:04.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2025/02/01/Other/Notes/","permalink":"http://example.com/2025/02/01/Other/Notes/","excerpt":"","text":"Centos开发环境 参考链接 Env &amp; Proxy 切换默认shell chsh -s /bin/bash root 配代理 123456export http_proxy=http://xxxexport https_proxy=http://xxxexport HTTP_PROXY=http://xxxexport HTTPS_PROXY=http://xxxexport no_proxy=&quot;localhost,127.0.0.1,localaddress,localdomain.com,xxx”export NO_PROXY=&quot;localhost,127.0.0.1,localaddress,localdomain.com,xxx&quot; 注意：在sudo或切换用户时代理会失效，可以通过 visudo 保留代理环境变量 1234## find Defaults env_resetDefaults env_reset## add following exceptionsDefaults env_keep = &quot;http_proxy ftp_proxy&quot; centos换源 12345cd /etc/yum.repos.d## 备份 &amp; 去掉有问题的源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum clean allyum makecache 环境变量添加第三方库 12345678910#在PATH中找到可执行文件程序的路径。export PATH =$PATH:/MyBin#gcc找到头文件的路径export C_INCLUDE_PATH=$C_INCLUDE_PATH:/usr/include/xxx#g++找到头文件的路径export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/include/xxx#找到动态链接库的路径export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/MyLib#找到静态库的路径export LIBRARY_PATH=$LIBRARY_PATH:/MyLib Vim1. 安装 Vim-plug 插件 下载 plug.vim 文件，放置在 ~/.vim/autoload 目录中： 12mkdir -p ~/.vim/autoload/cp plug.vim ~/.vim/autoload/plug.vim 2. 配置Vim，执行 :PlugInstall 安装主题 Folding 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758call plug#begin(&#x27;~/.vim/plugged&#x27;)Plug &#x27;sainnhe/sonokai&#x27;call plug#end()&quot; 关闭对vi的兼容set nocompatible&quot; 设置backspace键功能set backspace=eol,start,indent&quot; 显示行号set number&quot; 高亮显示当前行set cursorline&quot; 让一行的内容不换行set nowrap&quot; 距窗口边缘还有多少行时滚动窗口set scrolloff=8&quot; tab设为4个空格set tabstop=2set shiftwidth=2set softtabstop=2set expandtabset smarttab&quot; 新一行与上一行的缩进一致set autoindent&quot; 开启语法高亮syntax on&quot; 代码颜色主题set t_Co=256colorscheme sonokai&quot; 显示括号匹配set showmatch&quot; 高亮查找匹配set hlsearch&quot; 增量式搜索set incsearch&quot; 不区分大小写,除非含有大写字母set ignorecaseset smartcase&quot; 检测文件类型filetype on&quot; 文件编码set encoding=utf-8set fileencodings=ucs-bom,utf-8,utf-16,gbk,big5,gb18030,latin1&quot; 没有保存或文件只读时弹出确认set confirm&quot; 记录历史记录的条数set history=1000set undolevels=1000&quot; 禁用自动备份set nobackupset nowritebackupset noswapfile BashBash 的彩色配色主题，将 ~/.bashrc 中的 PS1 替换： 1PS1=&#x27;$&#123;debian_chroot:+($debian_chroot)&#125;\\[\\033[00;33m\\][\\u@\\h]\\[\\033[00m\\]:\\[\\033[00;36m\\]\\w\\[\\033[00m\\]\\$ &#x27; GCCCentOS 7 默认 gcc 版本为 4.8，可通过 devtoolset 工具安装多个不同的高版本 gcc 备用切换 可以通过 yum search devtooset 查看其他版本安装，devtoolset 安装目录为 /opt/rh/devtoolset-x 12345678910111213## 安装 centos-release-sclyum install centos-release-scl## 安装 devtoolsetyum install devtoolset-9-gcc## 切换 gcc 版本 vim /etc/profilesource /opt/rh/devtoolset-9/enablesource /etc/profile## 软连接（备份gcc同理）mv /usr/bin/g++ /usr/bin/g++.bakln -s /opt/rh/devtoolset-11/root/usr/bin/g++ /usr/bin/g++## 检验gcc --version GDB官网 Download GDB 获取最新版 gdb-x.x.tar.gz 下载地址 123456wget https://ftp.gnu.org/gnu/gdb/gdb-11.2.tar.gztar -zxvf gdb-11.2.tar.gzcd gdb-11.2/./configuremake &amp;&amp; make installgdb --version Make官网 Index of &#x2F;gnu&#x2F;make 获取最新版 make-x.x.tar.gz 下载地址 123456789101112wget https://ftp.gnu.org/gnu/make/make-4.3.tar.gztar -zxvf make-4.3.tar.gzcd make-4.3/## 指定 make 的安装路径./configure --prefix=/usr/local/makemake &amp;&amp; make install## 备份原版 makemv /usr/bin/make /usr/bin/make.bak## 创建软连接ln -s /usr/local/make/bin/make /usr/bin/make## 验证make -v CMake1. 二进制方式安装 12345678910## 在系统源代码目录下载二进制分发压缩包cd /usr/local/srccurl -LO https://github.com/Kitware/CMake/releases/download/v3.22.2/cmake-3.22.2-linux-x86_64.tar.gz## 解压 直接安装tar -xvf cmake-3.22.2.tar.gzmv cmake-3.22.2 /usr/local/cmakevim /etc/profileexport PATH=&quot;/usr/local/cmake/bin:$PATH&quot;source /etc/profilecmake --version 2. 源码安装 官网 Download | CMake 获取最新版 cmake-x.xx.x.tar.gz 下载地址 12345678910111213141516wget https://github.com/Kitware/CMake/releases/download/v3.23.0/cmake-3.23.0.tar.gztar -zxvf cmake-3.23.0.tar.gzcd cmake-3.23.0/./configure --prefix=/usr/local/cmakemake &amp;&amp; make install## 卸载原有 CMakeyum -y remove cmake## 创建软连接ln -s /usr/local/cmake/bin/cmake /usr/bin/cmake## 配置环境变量vim /etc/profileexport CMAKE_HOME=/usr/local/cmakeexport PATH=$PATH:$CMAKE_HOME/binsource /etc/profile## 检验cmake --version CMake Error：Could not find OpenSSL 报错，可通过以下命令解决：yum install openssl-devel Gflags1234git clone https://github.com/gflags/gflags.git &amp;&amp; cd gflagsmkdir build &amp;&amp; cd buildcmake .. -DBUILD_SHARED_LIBS=ONmake &amp;&amp; make install Glog1234git clone https://github.com/google/glog.git &amp;&amp; cd glogcmake -S . -B build -G &quot;Unix Makefiles&quot;cmake --build buildcmake --build build --target install # optional Gtest1234git clone https://github.com/google/googletest.git &amp;&amp; cd googletestmkdir build &amp;&amp; cd buildcmake ..make &amp;&amp; make install Mysql1. 命令安装 1sudo apt install mysql-server 通过apt安装的mysql已经默认开启服务，服务名叫做mysql，而非mysqld 2. 登陆Mysql 方法一：sudo mysql 方法二：查看默认用户密码登陆 12sudo cat /etc/mysql/debian.cnfmysql -u debian-sys-maint -p 3. 本地Root用户 修改一个host字段为 localhost 的 root 用户密码（localhost 表示本机登录） 不需授予访问权限，因为默认已有 12ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;;FLUSH PRIVILEGES; 4. 远程Root用户 创建一个 host 字段为 % 的 root 用户（% 表示远程登陆） 授权所有数据库的访问权限 123create user &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;yourpassword&#x27;;GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; WITH GRANT OPTION;FLUSH PRIVILEGES; 开启远程连接，注释bind-address 1234sudo systemctl stop mysqlsudo vim /etc/mysql/mysql.conf.d/mysqld.cnf# bind-address = 127.0.0.1sudo service mysql start 5. 查看用户信息 12use mysqlselect host,user,authentication_string from user; 6. 常用命令 服务状态管理 1234service mysql statusservice mysql startservice mysql restartservice mysql stop 卸载 MySQL 12345678### MySQL 5.7sudo apt-get remove mysql-commonsudo apt-get autoremove --purge mysql-server-5.7### MySQL 8.0sudo apt-get autoremove mysql-serverdpkg -l |grep ^rc|awk &#x27;&#123;print $2&#125;&#x27; |sudo xargs dpkg -Psudo apt-get autoremove --purge mysql-apt-config Redis 使用 C++ SDK Hiredis 访问 redisRedis Stream 1. 下载源码解压wget http://download.redis.io/releases/redis-5.0.5.tar.gztar -xzf redis-5.0.5.tar.gz &amp;&amp; cd redis-5.0.52. 编译yum -y install gcc gcc-c++ kernel-develmake3. 安装make PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis installcp redis.conf &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;4. 更改配置vim &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis.conf 12345678910111213## redis以守护进程的方式运行daemonize yes## 监听ip#bind 127.0.0.1 ## 关闭保护模式protected-mode no## 设置密码授权requirepass &lt;password&gt;## 关闭RDBsave &quot;&quot;#save 900 1#save 300 10#save 60 10000 5. 配置环境变量vim &#x2F;etc&#x2F;profileexport PATH&#x3D;”$PATH:&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin”source &#x2F;etc&#x2F;profile6. 启动脚本 Folding .&#x2F;redis start|stop|restart123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bashREDISPORT=6379PATH=/usr/local/bin:/sbin:/usr/bin:/binEXEC=/usr/local/redis/bin/redis-serverREDIS_CLI=/usr/local/redis/bin/redis-cliPIDFILE=/var/run/redis_$REDISPORT.pidCONF=&quot;/usr/local/redis/bin/redis.conf&quot;case &quot;$1&quot; in start) if [ -f $PIDFILE ]; then echo &quot;$PIDFILE exists, process is already running or crashed&quot; else echo &quot;Starting Redis server...&quot; $EXEC $CONF fi if [ &quot;$?&quot;=&quot;0&quot; ]; then echo &quot;Redis is running...&quot; fi ;; stop) if [ ! -f $PIDFILE ]; then echo &quot;$PIDFILE does not exist, process is not running&quot; else PID=$(cat $PIDFILE) echo &quot;Stopping ...&quot; $REDIS_CLI -p $REDISPORT SHUTDOWN while [ -x $&#123;PIDFILE&#125; ]; do echo &quot;Waiting for Redis to shutdown ...&quot; sleep 1 done echo &quot;Redis stopped&quot; fi ;; restart) $&#123;0&#125; stop $&#123;0&#125; start ;; *) echo &quot;Usage: $0 &#123;start|stop|restart&#125;&quot; &gt;&amp;2 exit 1esac Anaconda1. 环境管理 查看环境 12conda info -epython -V 创建环境 12## 创建一个环境名为py34，指定Python版本是3.4conda create --name py34 python=3.4 激活环境 12345## 在windows环境activate py34## 在Linux &amp; Mac中source activate py34 退出环境 12345## 在windows环境deactivate## 在Linux &amp; Mac中source deactivate 删除环境 1conda remove -n py34 --all 2. 包管理 换镜像 123conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes 进入指定的环境中进行包的安装，以pandas包为例 相关操作命令 12345678#查看已安装conda list#检查包是否可以安装conda search pandas#安装更新卸载conda install pandasconda update pandasconda remove pandas 使用conda来管理conda和python的版本( 都视为包 ) 1234conda update condaconda update anaconda#更新python为本系列最新版本conda update python 软件激活Office365Navicat 指令下载过程中容易失败，手动下载或挂梯子 注意教程中指令的工作目录 下载官方版 激活Ubuntu或Win10平台 Sublime textVscode MonoKai Pro 生成license key 12email=yourMail@mail.comecho -n fd330f6f-3f41-421d-9fe5-de742d0c54c0$email | md5sum | cut -c1-25 | sed &#x27;s/.\\&#123;5\\&#125;/&amp;-/g;s/-$//g&#x27; 打开VS Code的命令面板，ctrl+shift+p 输入 Monokai Pro: enter license 依次输入 email 和 lincese key gpedit.msc123456@echo offpushd &quot;%~dp0&quot;dir /b %systemroot%\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~3*.mum &gt;gp.txtdir /b %systemroot%\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~3*.mum &gt;&gt;gp.txtfor /f %%i in (&#x27;findstr /i . gp.txt 2^&gt;nul&#x27;) do dism /online /norestart /add-package:&quot;%systemroot%\\servicing\\Packages\\%%i&quot;pause Ventoy启动盘 GNOME美化 Windows相关1. 安全模式启动 WIN + R -&gt; msconfig 打开系统配置 引导 -&gt; 安全引导 -&gt; 重启即进入安全模式 常规 -&gt; 正常启动 -&gt; 重启即进入正常系统 2. 卸载 ESET 在安全模式下，打开终端运行 esetuninstaller.exe，按提示操作 3. 环境变量生效 12set PATH=Cecho %PATH% # 重启cmd 4. Edge&#x2F;Chrome切换最近标签页 需求：按ctrl+tab切换最近两个标签页 问题：默认只能每次切换到下一个标签页，且不允许被扩展的切换标签页快捷键所覆盖 解决：安装QuicKey，按页面中 Option 1 的步骤执行（最后用开发者工具设置扩展快捷键） Ubuntu相关1. 无法访问部分网页 问题描述：双系统win可以，但Ubuntu很多网页如CSDN无法访问 解决方案：Ubuntu网卡的MTU设置不当，改为1412（尝试值）即可 123456789## 查看网卡名称，如wlp0s20f3ifconfig## 设置MTU大小sudo ifconfig wlp0s20f3 mtu 1412 ## 若此时问题解决，新建脚本让网卡每次启动时自动设置MTUsudo vim /etc/network/if-up.d/setmtu#!/bin/shifconfig &quot;$IFACE&quot; mtu 1412sudo chmod a+x /etc/network/if-up.d/setmtu 2. 开关机异常缓慢 开机动画 12sudo systemctl mask plymouth-quit-wait.service##关闭mask 开启unmask 关机重启等待 90 秒 1234567sudo vim /etc/systemd/system.conf### 修改为1sDefaultTimeoutStartSec=1sDefaultTimeoutStopSec=1s### 使其生效sudo systemctl daemon-reloadsudo reboot 3. 双系统扩容预留给 Ubuntu 系统的预留空间不足时需要扩容，可 参考流程 与 gparted使用方法 启动盘进入系统，使用自带的gparted分区工具 将多余空间分区并格式化 通过一系列对未分配分区的调换，移到待扩容分区后方相邻合并 4. Linux开机挂载硬盘 123456##修改开机配置sudo vim /etc/fstab##添加如下一行UUID=[1] [2] [3] defaults 0 1##测试是否正确mount -a 通过sudo blkid查看C盘UUID，如C8086A73086A6104 挂载目录如/media/yveltal/LENOVO 文件系统类型，如win为ntfs 5. 通过tar包安装应用 解压下载文件并移动到安装文件夹内/opt/demo 为启动文件建立软Link(注意修改.sh中路径) 12# 注意相对路径问题sudo ln -s /opt/demo/run.sh /usr/bin/demo 添加第三方软件图标 sudo vim /usr/share/applications/demo.desktop 12345678[Desktop Entry]Encoding=UTF-8Name=demoExec=demoIcon=/opt/demo/icon.png Terminal=falseType=ApplicationCategories=Development; IOS相关1. IOS越狱 下载Linux x86_64版本 chmod 777 ，sudo .&#x2F;checkra1n 设置允许越狱未测试的iOS新版本 开机后用4G安装Cydia ​ 2. IOS跳ID锁 通过爱思助手打开SSH通道 打开激活工具，按提示选择数字进行激活 激活完毕后，会发现IOS跳过了验证环节，可以直接进入桌面 ​ Android相关1. 去APK弹窗 MT管理器查看apk，用dex编辑器++打开dex文件(全选) 搜索内容show，搜索类型代码 （或搜弹窗内容等） 找到类似invoke-virtual&#123;v0&#125;,LandroidlapplAlertDialog$Builder;-&gt;show()Landroidl... 点击跳转到相应代码，用#注释该句 2. 去APK浮窗 同理搜索相应浮窗内容，搜索类型字符串 跳转将对应方法注释 OtherRec Mono 字体 123// VSCode 用户配置&quot;editor.fontLigatures&quot;: &quot;&#x27;dlig&#x27;,&#x27;ss01&#x27;&quot;,&quot;editor.fontFamily&quot;: &quot;\\&quot;Rec Mono Linear\\&quot;, monospace&quot;, 图片压缩 1jpegoptim --size=700k xxxx.jpg","categories":[{"name":"Other","slug":"Other","permalink":"http://example.com/categories/Other/"}],"tags":[{"name":"Other","slug":"Other","permalink":"http://example.com/tags/Other/"}]},{"title":"Design pattern","slug":"Software/Design pattern","date":"2024-12-18T12:39:04.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2024/12/18/Software/Design pattern/","permalink":"http://example.com/2024/12/18/Software/Design%20pattern/","excerpt":"","text":"设计原则 单⼀职责原则：⼀个类应该仅有⼀个引起它变化的原因。 开放封闭原则：软件实体可以扩展，但是不可修改。即⾯对需求，对程序的改动可以通过增加代码来完成，但是不能改动现有的代码。 ⾥⽒代换原则：⼀个软件实体如果使⽤的是基类，则⼀定适⽤于其派⽣类。即把基类替换成派⽣类，程序的⾏为没有变化。 依赖倒转原则：抽象不应该依赖细节，细节应该依赖抽象。即针对接⼝编程，不要对实现编程。 迪⽶特原则：不直接通信的两个类不应发⽣直接相互作⽤，可以通过第三个类转发这个调⽤。 接⼝隔离原则：每个接⼝中不存在派⽣类⽤不到却必须实现的⽅法，否则就要将接⼝拆分，使⽤多个隔离的接⼝。 组合模式需求变化，需要组合多个Processor实例功能例如 Processor 表示几种消费数据的接口，需求是需要同时消费 hive 和 kafka 1234567891011121314151617181920212223242526272829303132class Processor &#123; public: virtual void ThreadWork() = 0;&#125;;class HiveProcessor : public Processor &#123; public: void ThreadWork() override &#123; cout &lt;&lt; &quot;ConsumeHive&quot; &lt;&lt; endl; &#125;&#125;;class KafkaProcessor : public Processor &#123; public: void ThreadWork() override &#123; cout &lt;&lt; &quot;ConsumeKafka&quot; &lt;&lt; endl; &#125;&#125;;class CompoundProcessor: public Processor &#123; public: void AddProcessor(unique_ptr&lt;Processor&gt; p) &#123; processors_.emplace_back(std::move(p)); &#125; void ThreadWork() override &#123; for (auto&amp; p : processors_) &#123; p-&gt;ThreadWork(); &#125; &#125; list&lt;unique_ptr&lt;Processor&gt;&gt; processors_;&#125;;int main() &#123; CompoundProcessor cp; cp.AddProcessor(make_unique&lt;HiveProcessor&gt;()); cp.AddProcessor(make_unique&lt;KafkaProcessor&gt;()); Processor *p = &amp;cp; p-&gt;ThreadWork();&#125; 装饰模式需求变化，需要在现有 Bar 的实现上添加特定功能。通过组合方式实现功能扩展更灵活，能够动态地改变对象的行为例如 Bar 表示日志接口，需求是输入日志前，对日志做过滤 123456789101112131415161718192021222324252627282930313233class Bar &#123; public: virtual void UseBar() = 0; virtual ~Bar() = default;&#125;;class BarImpl : public Bar &#123; public: // 现有的实现，在不影响其结构的情况下添加新的功能 void UseBar() override &#123; cout &lt;&lt; &quot;UseBar&quot; &lt;&lt; endl; &#125;&#125;;class BarDecorator : public Bar &#123; public: BarDecorator(unique_ptr&lt;Bar&gt; bar) : bar_(std::move(bar)) &#123;&#125;protected: unique_ptr&lt;Bar&gt; bar_; // 将原始对象嵌套在装饰类中&#125;;class BarDecoratorFilter : public BarDecorator &#123; public: BarDecoratorFilter(unique_ptr&lt;Bar&gt; bar) : BarDecorator(std::move(bar)) &#123;&#125; // 装饰类在运行时“装饰”该对象，添加新的行为 void UseBar() override &#123; Dofilter(); bar_-&gt;UseBar(); &#125; private: void Dofilter() &#123; cout &lt;&lt; &quot;DoFilter&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; auto bar_ptr = make_unique&lt;BarImpl&gt;(); unique_ptr&lt;Bar&gt; bar = make_unique&lt;BarDecoratorFilter&gt;(std::move(bar_ptr)); bar-&gt;UseBar();&#125; 策略模式定义一系列算法，把他们一个个封装起来，并且使他们可以互相替换。该模式使得算法可独立于使用它的客户程序（稳定）而变化（扩展，子类化） 策略模式 + 工厂模式写一个类 Foo，根据不同 type 执行对应 strategy 类的 Execute 函数，type 种类会随着需求不断增加 1.朴素写法：违反开闭原则，不方便添加新 strategy 1234567891011121314151617181920212223242526class StrategyA &#123;public: void Execute() &#123; cout &lt;&lt; &quot;execute type 1&quot; &lt;&lt; endl; &#125;&#125;;class StrategyB &#123;public: void Execute() &#123; cout &lt;&lt; &quot;execute type 2&quot; &lt;&lt; endl; &#125;&#125;;class Foo &#123;public: void ExecuteByType(int type) &#123; if (type == 1) &#123; StrategyA sta; sta.Execute(); &#125; else if (type == 2) &#123; StrategyB stb; stb.Execute(); &#125; // 违反开闭原则 &#125;&#125;;int main() &#123; Foo f; f.ExecuteByType(1); f.ExecuteByType(2);&#125; 2.采用工厂模式优化，动态创建 strategy 对象，但 if-else 仍违反开闭原则 12345678910111213141516171819202122232425262728293031323334class Strategy &#123;public: virtual void Execute() = 0;&#125;;class StrategyA : public Strategy &#123;public: void Execute() override &#123; cout &lt;&lt; &quot;execute type 1&quot; &lt;&lt; endl; &#125;&#125;;class StrategyB : public Strategy &#123;public: void Execute() override &#123; cout &lt;&lt; &quot;execute type 2&quot; &lt;&lt; endl; &#125;&#125;;class StrategyFactory &#123;public: static unique_ptr&lt;Strategy&gt; createStrategy(int type) &#123; if (type == 1) &#123; return make_unique&lt;StrategyA&gt;(); &#125; else if (type == 2) &#123; return make_unique&lt;StrategyB&gt;(); &#125; else &#123; return nullptr; &#125; // 违反开闭原则 &#125;&#125;;class Foo &#123;public: void ExecuteByType(int type) &#123; StrategyFactory::createStrategy(type)-&gt;Execute(); &#125;&#125;;int main() &#123; Foo f; f.ExecuteByType(1); f.ExecuteByType(2);&#125; 3.采用策略模式+工厂模式进一步优化，满足开闭原则 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Strategy;class StrategyFactory &#123;public: static unique_ptr&lt;Strategy&gt; createStrategy(int type) &#123; return strategies[type](); &#125; static void registerStrategy(int type, function&lt;unique_ptr&lt;Strategy&gt;()&gt; create_fn) &#123; strategies[type] = create_fn; &#125;private: static unordered_map&lt;int, function&lt;unique_ptr&lt;Strategy&gt;()&gt;&gt; strategies;&#125;;unordered_map&lt;int, function&lt;unique_ptr&lt;Strategy&gt;()&gt;&gt; StrategyFactory::strategies;class Strategy &#123;public: virtual void Execute() = 0;&#125;;class StrategyA : public Strategy &#123;public: static void registerStrategy() &#123; StrategyFactory::registerStrategy(1, []() -&gt; unique_ptr&lt;Strategy&gt; &#123; return make_unique&lt;StrategyA&gt;(); &#125;); &#125; void Execute() override &#123; cout &lt;&lt; &quot;execute type 1&quot; &lt;&lt; endl; &#125;&#125;;class StrategyB : public Strategy &#123;public: static void registerStrategy() &#123; StrategyFactory::registerStrategy(2, []() -&gt; unique_ptr&lt;Strategy&gt; &#123; return make_unique&lt;StrategyB&gt;(); &#125;); &#125; void Execute() override &#123; cout &lt;&lt; &quot;execute type 2&quot; &lt;&lt; endl; &#125;&#125;;class Foo &#123;public: explicit Foo() &#123; StrategyA::registerStrategy(); StrategyB::registerStrategy(); &#125; void ExecuteByType(int type) &#123; StrategyFactory::createStrategy(type)-&gt;Execute(); &#125;&#125;;int main() &#123; Foo f; f.ExecuteByType(1); f.ExecuteByType(2);&#125; 单例模式系统只需要⼀个实例对象，或客户调⽤类的单个实例只允许使⽤⼀个公共访问点 123456789101112131415161718192021222324252627282930// Lazyclass Single&#123;public: static Single* getInstance()&#123; static Single ins; return &amp;ins; &#125; Single(const Single&amp;) = delete; Single(Single&amp;&amp;) = delete; Single&amp; operator=(const Single&amp;) = delete;private: Single() = default; virtual ~Single() = default;&#125;;// Eagerclass Single&#123;public: static Single* getInstance()&#123; return ins; &#125; Single(const Single&amp;) = delete; Single(Single&amp;&amp;) = delete; Single operator=(const Single&amp;) = delete;private: Single() = default; virtual ~Single() = default; static Single *ins;&#125;;Single* Single::ins = new(nothrow) Single; 观察者模式定义一种订阅机制，可在对象事件发生时通知多个观察者对象。 观察者：内部包含被观察者对象，当被观察者对象的状态发⽣变化时，更新⾃⼰的状态。（接收通知更新状态） 被观察者：内部包含了所有观察者对象，当状态发⽣变化时通知所有的观察者更新⾃⼰的状态。（发送通知） 应⽤场景： 当⼀个对象的改变需要同时改变其他对象，且不知道具体有多少对象有待改变时，应该考虑使⽤观察者模式；⼀个抽象模型有两个⽅⾯，其中⼀⽅⾯依赖于另⼀⽅⾯，这时可以⽤观察者模式将这两者封装在独⽴的对象中使它们各⾃独⽴地改变和复⽤。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081class Subject;//观察者 （内部实例化了被观察者的对象）class Observer &#123;public: Observer(string name, Subject *sub) &#123; this-&gt;name = name; this-&gt;sub = sub; &#125; virtual void update() = 0;protected: string name; Subject *sub;&#125;;class StockObserver : public Observer &#123;public: StockObserver(string name, Subject *sub) : Observer(name, sub)&#123;&#125; void update() &#123; cout &lt;&lt; name &lt;&lt; &quot; 收到消息：&quot; &lt;&lt; sub-&gt;action &lt;&lt; endl; if (sub-&gt;action == &quot;⽼板来了!&quot;) &#123; cout &lt;&lt; &quot;我⻢上关闭股票，装做很认真⼯作的样⼦！&quot; &lt;&lt; endl; &#125; &#125;&#125;;class NBAObserver : public Observer &#123;public: NBAObserver(string name, Subject *sub) : Observer(name, sub)&#123;&#125; void update() &#123; cout &lt;&lt; name &lt;&lt; &quot; 收到消息：&quot; &lt;&lt; sub-&gt;action &lt;&lt; endl; if (sub-&gt;action == &quot;⽼板来了!&quot;) &#123; cout &lt;&lt; &quot;我⻢上关闭 NBA，装做很认真⼯作的样⼦！&quot; &lt;&lt; endl; &#125; &#125;&#125;;// 被观察者 （存放了所有观察者对象，在状态变化时给观察者发通知）class Subject &#123;protected: std::list&lt;Observer*&gt; observers;public: string action; //被观察者对象的状态 virtual void attach(Observer *) = 0; virtual void detach(Observer *) = 0; virtual void notify() = 0;&#125;;class Secretary : public Subject &#123; void attach(Observer *observer) &#123; observers.push_back(observer); &#125; void detach(Observer *observer) &#123; auto iter = observers.begin(); while (iter != observers.end()) &#123; if ((*iter) == observer) &#123; observers.erase(iter); return; &#125; ++iter; &#125; &#125; void notify() &#123; list&lt;Observer *&gt;::iterator iter = observers.begin(); while (iter != observers.end()) &#123; (*iter)-&gt;update(); ++iter; &#125; &#125;&#125;;int main()&#123; Subject *BOSS = new Secretary(); Observer *a = new NBAObserver(&quot;a&quot;, BOSS); Observer *b = new StockObserver(&quot;b&quot;, BOSS); BOSS-&gt;attach(a); BOSS-&gt;attach(b); BOSS-&gt;action = &quot;去吃饭了&quot;; BOSS-&gt;notify(); cout &lt;&lt; endl; BOSS-&gt;action = &quot;⽼板来了&quot;; BOSS-&gt;notify();&#125; ⼯⼚模式工厂方法和抽象工厂的区别 工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个 工厂方法模式的具体工厂类只能创建一个具体产品类的实例，而抽象工厂模式可以创建多个 工厂方法在增加一个具体产品的时候，都要增加对应的工厂，而抽象工厂模式只有在新增一个类型的具体产品时才需要新增工厂 工厂方法模式工厂方法模式是一种创建型设计模式，其在父类中提供一个创建对象的方法，允许子类决定实例化对象的类型。核心的工厂类不再负责所有产品的创建，而是将具体创建工作交给子类去做。这个核心类仅仅负责给出具体工厂必须实现的接口，而不负责产品类被实例化这种细节，这使得工厂方法模式可以允许系统在不修改工厂角色的情况下引进新产品。 优点： 一个调用者想创建一个对象，只要知道其名称就可以了。 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以，符合开闭原则 屏蔽产品的具体实现，调用者只关心产品的接口。 缺点：每加一个产品，需要额外加一个产品工厂的类，增加了额外的开销。 结构 伪代码以下示例演示了如何使用工厂方法开发跨平台 UI （用户界面） 组件， 并同时避免客户代码与具体 UI 类之间的耦合。 基础对话框类使用不同的 UI 组件渲染窗口。 在不同的操作系统下， 这些组件外观或许略有不同， 但其功能保持一致。 Windows 系统中的按钮在 Linux 系统中仍然是按钮。 如果使用工厂方法， 就不需要为每种操作系统重写对话框逻辑。 如果我们声明了一个在基本对话框类中生成按钮的工厂方法， 那么我们就可以创建一个对话框子类， 并使其通过工厂方法返回 Windows 样式按钮。 子类将继承对话框基础类的大部分代码， 同时在屏幕上根据 Windows 样式渲染按钮。 如需该模式正常工作， 基础对话框类必须使用抽象按钮 （例如基类或接口）， 以便将其扩展为具体按钮。 这样一来， 无论对话框中使用何种类型的按钮， 其代码都可以正常工作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 创建者类声明的工厂方法必须返回一个产品类的对象。创建者的子类通常会提供// 该方法的实现。class Dialog is // 创建者还可提供一些工厂方法的默认实现。 abstract method createButton():Button // 请注意，创建者的主要职责并非是创建产品。其中通常会包含一些核心业务 // 逻辑，这些逻辑依赖于由工厂方法返回的产品对象。子类可通过重写工厂方 // 法并使其返回不同类型的产品来间接修改业务逻辑。 method render() is // 调用工厂方法创建一个产品对象。 Button okButton = createButton() // 现在使用产品。 okButton.onClick(closeDialog) okButton.render()// 具体创建者将重写工厂方法以改变其所返回的产品类型。class WindowsDialog extends Dialog is method createButton():Button is return new WindowsButton()class WebDialog extends Dialog is method createButton():Button is return new HTMLButton()// 产品接口中将声明所有具体产品都必须实现的操作。interface Button is method render() method onClick(f)// 具体产品需提供产品接口的各种实现。class WindowsButton implements Button is method render(a, b) is // 根据 Windows 样式渲染按钮。 method onClick(f) is // 绑定本地操作系统点击事件。class HTMLButton implements Button is method render(a, b) is // 返回一个按钮的 HTML 表述。 method onClick(f) is // 绑定网络浏览器的点击事件。class Application is field dialog: Dialog // 程序根据当前配置或环境设定选择创建者的类型。 method initialize() is config = readApplicationConfigFile() if (config.OS == &quot;Windows&quot;) then dialog = new WindowsDialog() else if (config.OS == &quot;Web&quot;) then dialog = new WebDialog() else throw new Exception(&quot;错误！未知的操作系统。&quot;) // 当前客户端代码会与具体创建者的实例进行交互，但是必须通过其基本接口 // 进行。只要客户端通过基本接口与创建者进行交互，你就可将任何创建者子 // 类传递给客户端。 method main() is this.initialize() dialog.render() 抽象工厂由于工厂方法模式中的每个工厂只生产一类产品，可能会导致系统中存在大量的工厂类。 因此可以将相关的产品组成一个产品族（如button、checkbox），由同一个工厂来统一生产（该工厂能同时创建button和checkbox），不同工厂生产不同系列（mac、win），这就是抽象工厂模式的基本思想。 好处： 易于交换产品系列，只需要应用中根据环境初始化一次，就能切换成一种对应的具体工厂（mac or win），从而可以使用不同的产品配置。 让客户端不关心具体创建过程，只需要通过抽象接口操纵实例，产品的具体类名也被具体工厂的实现分离，不会出现在客户代码中。 缺点：如果要添加一个产品类，就得增加很多代码 结构 伪代码下面例子通过应用抽象工厂模式， 使得客户端代码无需与具体 UI 类耦合， 就能创建跨平台的 UI 元素， 同时确保所创建的元素与指定的操作系统匹配。 跨平台应用中的相同 UI 元素功能类似， 但是在不同操作系统下的外观有一定差异。 此外， 你需要确保 UI 元素与当前操作系统风格一致。 你一定不希望在 Windows 系统下运行的应用程序中显示 macOS 的控件。 抽象工厂接口声明一系列构建方法， 客户端代码可调用它们生成不同风格的 UI 元素。 每个具体工厂对应特定操作系统， 并负责生成符合该操作系统风格的 UI 元素。 其运作方式如下： 应用程序启动后检测当前操作系统。 根据该信息， 应用程序通过与该操作系统对应的类创建工厂对象。 其余代码使用该工厂对象创建 UI 元素。 这样可以避免生成错误类型的元素。 使用这种方法， 客户端代码只需调用抽象接口， 而无需了解具体工厂类和 UI 元素。 此外， 客户端代码还支持未来添加新的工厂或 UI 元素。 这样一来， 每次在应用程序中添加新的 UI 元素变体时， 你都无需修改客户端代码。 你只需创建一个能够生成这些 UI 元素的工厂类， 然后稍微修改应用程序的初始代码， 使其能够选择合适的工厂类即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// 抽象工厂接口声明了一组能返回不同抽象产品的方法。这些产品属于同一个系列// 且在高层主题或概念上具有相关性。同系列的产品通常能相互搭配使用。系列产// 品可有多个变体，但不同变体的产品不能搭配使用。interface GUIFactory is method createButton():Button method createCheckbox():Checkbox// 具体工厂可生成属于同一变体的系列产品。工厂会确保其创建的产品能相互搭配// 使用。具体工厂方法签名会返回一个抽象产品，但在方法内部则会对具体产品进// 行实例化。class WinFactory implements GUIFactory is method createButton():Button is return new WinButton() method createCheckbox():Checkbox is return new WinCheckbox()// 每个具体工厂中都会包含一个相应的产品变体。class MacFactory implements GUIFactory is method createButton():Button is return new MacButton() method createCheckbox():Checkbox is return new MacCheckbox()// 系列产品中的特定产品必须有一个基础接口。所有产品变体都必须实现这个接口。interface Button is method paint()// 具体产品由相应的具体工厂创建。class WinButton implements Button is method paint() is // 根据 Windows 样式渲染按钮。class MacButton implements Button is method paint() is // 根据 macOS 样式渲染按钮// 这是另一个产品的基础接口。所有产品都可以互动，但是只有相同具体变体的产// 品之间才能够正确地进行交互。interface Checkbox is method paint()class WinCheckbox implements Checkbox is method paint() is // 根据 Windows 样式渲染复选框。class MacCheckbox implements Checkbox is method paint() is // 根据 macOS 样式渲染复选框。// 客户端代码仅通过抽象类型（GUIFactory、Button 和 Checkbox）使用工厂// 和产品。这让你无需修改任何工厂或产品子类就能将其传递给客户端代码。class Application is private field factory: GUIFactory private field button: Button constructor Application(factory: GUIFactory) is this.factory = factory method createUI() is this.button = factory.createButton() method paint() is button.paint()// 程序会根据当前配置或环境设定选择工厂类型，并在运行时创建工厂（通常在初// 始化阶段）。class ApplicationConfigurator is method main() is config = readApplicationConfigFile() if (config.OS == &quot;Windows&quot;) then factory = new WinFactory() else if (config.OS == &quot;Mac&quot;) then factory = new MacFactory() else throw new Exception(&quot;错误！未知的操作系统。&quot;) Application app = new Application(factory) 参考 大话设计模式、UML、设计模式Java版完全总结Refactoringguru","categories":[{"name":"Software","slug":"Software","permalink":"http://example.com/categories/Software/"}],"tags":[]},{"title":"Example","slug":"CPP/Example","date":"2024-12-13T18:20:04.000Z","updated":"2025-03-06T09:01:58.037Z","comments":true,"path":"2024/12/13/CPP/Example/","permalink":"http://example.com/2024/12/13/CPP/Example/","excerpt":"","text":"AsyncQuery1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#define BOOST_THREAD_VERSION 4#include &lt;bits/stdc++.h&gt;#include &lt;boost/thread/future.hpp&gt;using namespace std;enum class StatusCode : int &#123; Ok = 0, NotFound = 1&#125;;class Status &#123;public: StatusCode code_; string message_; Status(StatusCode code, const string &amp;message): code_(code), message_(message) &#123;&#125;&#125;;Status AsyncRead(const string &amp;req, function&lt;void(const string &amp;suffix)&gt; cb) &#123; boost::future&lt;string&gt; f = boost::async([&amp;req]()&#123; this_thread::sleep_for(chrono::seconds(3)); return string&#123;&quot;value&quot;&#125;; // mock rpc request &#125;); f.then([cb](boost::future&lt;string&gt; future) &#123; auto result = future.get(); cb(result); &#125;); return &#123;StatusCode::Ok, &quot;async read&quot;&#125;;&#125;Status Read(const string &amp;req, string &amp;resp) &#123; auto pms = make_shared&lt;boost::promise&lt;Status&gt;&gt;(); boost::future&lt;Status&gt; fut(pms-&gt;get_future()); function&lt;void(const string &amp;value)&gt; cb = [&amp;resp, &amp;pms] (const string &amp;value) &#123; resp = value; // exec something after async finished pms-&gt;set_value(&#123;StatusCode::Ok, &quot;pms set value&quot;&#125;); &#125;; auto st = AsyncRead(req, cb); // non-blocking cout &lt;&lt; st.message_ &lt;&lt; endl; st = fut.get(); // blocking cout &lt;&lt; st.message_ &lt;&lt; endl; return &#123;StatusCode::Ok, &quot;read&quot;&#125;;&#125;int main() &#123; string resp; auto st = Read(&quot;key&quot;, resp); if (st.code_ == StatusCode::Ok) &#123; cout &lt;&lt; resp &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; st.message_ &lt;&lt; endl; &#125;&#125; RecordBuffer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;bits/stdc++.h&gt;using namespace std;class RecordBuffer &#123; public: explicit RecordBuffer(int size, string file): file_(file), buffer_size_(size), buffer_(new char[size]) &#123;&#125; ~RecordBuffer() &#123; FlushBuffer(); cout &lt;&lt; &quot;Destructed after flushing&quot; &lt;&lt; endl; &#125; void WriteRecord(const char *data, int size) &#123; if (!IsAvailable(size)) &#123; FlushBuffer(); &#125; WriteToBuffer(data, size); &#125; void WriteToBuffer(const char *data, int size) &#123; assert(IsAvailable(size)); memcpy(buffer_.get() + buffer_used_, data, size); buffer_used_ += size; &#125; void FlushBuffer() &#123; if (buffer_used_ == 0) return; ofstream f(file_, ios::app); f &lt;&lt; string(buffer_.get(), buffer_used_) &lt;&lt; endl; this_thread::sleep_for(chrono::seconds(3)); f.close(); buffer_used_ = 0; &#125; bool IsAvailable(int size) &#123; return buffer_size_ - buffer_used_ &gt;= size; &#125; unique_ptr&lt;char[]&gt; buffer_; int buffer_size_; int buffer_used_&#123;0&#125;; string file_;&#125;;int main() &#123; RecordBuffer rb(16, &quot;output.txt&quot;); string s&#123;&quot;zxcvbnm&quot;&#125;; for (int i = 0; i &lt; 20; ++i) &#123; rb.WriteRecord(s.data(), s.size()); &#125;&#125; ThreadPool12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;bits/stdc++.h&gt;using namespace std;class ThreadPool &#123;public: ThreadPool(int size = thread::hardware_concurrency()); ~ThreadPool(); template&lt;class F, class... Args&gt; auto submit(F&amp;&amp; f, Args&amp;&amp;... args) -&gt; future&lt;typename result_of&lt;F(Args...)&gt;::type&gt;;private: queue&lt;function&lt;void()&gt;&gt; tasks; vector&lt;thread&gt; workers; mutex mtx_; condition_variable cv_; bool stop;&#125;;ThreadPool::ThreadPool(int size) : stop(false) &#123; for (int i = 0; i &lt; size; i++) &#123; workers.emplace_back([this] &#123; while (!stop) &#123; unique_lock&lt;mutex&gt; lock(mtx_); cv_.wait(lock, [this] &#123; return !tasks.empty() || stop; &#125;); if (stop) return; function&lt;void()&gt; task = move(tasks.front()); tasks.pop(); lock.unlock(); task(); &#125; &#125;); &#125;&#125;ThreadPool::~ThreadPool() &#123; &#123; unique_lock&lt;mutex&gt; lock(mtx_); stop = true; &#125; cv_.notify_all(); for (auto&amp; worker : workers) &#123; worker.join(); &#125;&#125;template&lt;class F, class... Args&gt;auto ThreadPool::submit(F&amp;&amp; f, Args&amp;&amp;... args) -&gt; future&lt;typename result_of&lt;F(Args...)&gt;::type&gt; &#123; using return_type = typename result_of&lt;F(Args...)&gt;::type; auto task = make_shared&lt;packaged_task&lt;return_type()&gt;&gt;( bind(forward&lt;F&gt;(f), forward&lt;Args&gt;(args)...) ); future&lt;return_type&gt; result = task-&gt;get_future(); &#123; unique_lock&lt;mutex&gt; lock(mtx_); if (stop) &#123; throw runtime_error(&quot;submit on stopped ThreadPool&quot;); &#125; tasks.emplace([task] &#123; (*task)(); &#125;); &#125; cv_.notify_one(); return result;&#125;int main() &#123; unique_ptr&lt;ThreadPool&gt; pool = make_unique&lt;ThreadPool&gt;(); auto result = pool-&gt;submit([] &#123; this_thread::sleep_for(chrono::seconds(3)); return 100; &#125;); cout &lt;&lt; result.get() &lt;&lt; endl;&#125;","categories":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/categories/CPP/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/tags/CPP/"}]},{"title":"Cpp编译链接","slug":"CPP/CPP编译","date":"2024-11-11T11:45:04.000Z","updated":"2025-03-06T09:01:58.036Z","comments":true,"path":"2024/11/11/CPP/CPP编译/","permalink":"http://example.com/2024/11/11/CPP/CPP%E7%BC%96%E8%AF%91/","excerpt":"","text":"ELF格式和动态链接可执行文件和共享库通常采用ELF格式。ELF格式不仅定义了文件的结构，还包含了一系列的头部信息，这些信息对于动态链接和程序的执行至关重要。 ELF文件结构一个典型的ELF文件由以下几个部分组成： 文件头（ELF Header）：包含了关于整个文件的一般信息，如文件类型（可执行文件、共享库等）、机器类型、入口点地址等。 程序头表（Program Header Table）：指定了程序执行所需的各种段（segment）的位置和属性。对于动态链接来说，其中最重要的是动态段（Dynamic Segment），它包含了动态链接所需的信息，如RPATH。 节头表（Section Header Table）：描述了文件中的各个节（section）的信息。节是文件的逻辑分割，用于存储程序的代码、数据、符号表等。 节内容（Section Contents）：包含了实际的代码、数据等。 动态链接器的角色动态链接器在Linux系统中扮演着至关重要的角色。它负责在程序启动时加载和链接其依赖的共享库，确保程序能够正确执行。 加载共享库当一个程序启动时，动态链接器会根据程序的ELF文件中的信息来加载所需的共享库。这个过程包括： 解析依赖：动态链接器首先解析程序的动态段，获取它依赖的共享库列表。 搜索共享库：接着，动态链接器按照一定的顺序搜索这些共享库。这个顺序通常是：RPATH → LD_LIBRARY_PATH → 系统默认路径 加载共享库：一旦找到共享库，动态链接器会将它们加载到内存中，并进行必要的符号解析和重定位。 符号解析和重定位加载共享库后，动态链接器需要解析程序和库之间的符号引用，并进行重定位。这包括： 符号解析：动态链接器会查找程序中引用的符号（如函数和变量）在共享库中的地址。 重定位：根据找到的地址，动态链接器会调整程序中的符号引用，确保它们指向正确的位置。 设置库寻找路径查看so依赖信息查看动态库依赖：ldd myso，查看详细依赖search过程：LD_DEBUG=libs ldd myso查看二进制&#x2F;动态库详细信息：readelf -d myso | head -n 20 设置LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/home/user/mylibs:$LD_LIBRARY_PATH 设置RPATH 编译参数-Wl,-rpath=&#39;$$ORIGIN/&#39;，$ORIGIN是表示so所在执行路径在bash中添加单引号防止 $ 被转义，在string中（如BUILD配置）额外添加一个 $ 防止 $O 丢失，是否设置成功可以通过 chrpath 查看 chrpath修改so查看rpath：chrpath -l myso设置rpath：chrpath -r /home/user/mylibs myso，限制：新RPATH长度不能超过原始长度 patchelf修改sopatchelf --set-rpath /home/user/mylibs myso CXXABI_1.3.8 not found 查询当前 libstdc++.so 支持的CXXABI版本strings /lib64/libstdc++.so.6 | grep CXXABI 查询系统上的 libstdc++.so，从中找到符合 CXXABI 版本的find / -name &quot;libstdc++.so*&quot; 把这个动态库（如libstdc++.so.6.0.25）复制到 &#x2F;usr&#x2F;lib64，建立软链接。这里的 xx.so.6 和 xx.so 都是 xx.so.6.0.25 的软链接sudo ln -s libstdc++.so.6.0.25 libstdc++.so.6","categories":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/categories/CPP/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/tags/CPP/"}]},{"title":"Linux内存与存储","slug":"Storage/Linux内存与存储","date":"2024-09-25T01:00:00.000Z","updated":"2025-03-06T09:01:58.039Z","comments":true,"path":"2024/09/25/Storage/Linux内存与存储/","permalink":"http://example.com/2024/09/25/Storage/Linux%E5%86%85%E5%AD%98%E4%B8%8E%E5%AD%98%E5%82%A8/","excerpt":"","text":"文件系统读写 从内核文件系统看文件读写过程 address_space 指示文件在页缓存中已经缓存了的物理页，是页缓存和外部设备中文件系统的桥梁 读文件 read()函数根据传入的文件路径，在目录项中检索，找到该文件的inode 在inode中，通过文件内容偏移量计算出要读取的页 通过inode找到文件对应的address_space，在address_space中访问该文件的页缓存树，查找对应的页缓存结点： 如果页缓存命中，那么直接返回文件内容 如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页；重新进行第6步查找页缓存 写文件 找到inode，进一步找到文件对应的address_space 在address_space中查询对应页的页缓存是否存在： 如果页缓存命中，直接修改完页缓存的页中就写结束了，并没有写回到磁盘文件中去 如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第6步。 页缓存被修改后会被标记成脏页。脏页需要写回到磁盘中的文件块：调用sync()/fsync()，或等pdflush进程定时把脏页写回到磁盘。脏页写回过程中会上锁，其他写请求被阻塞 内存资源管理Buffers／Cached在内存管理中的buffer指Linux内存的：Buffer cache，cache指Linux内存中的：Page cache。 如果有内存是以page进行分配管理的，都可以使用page cache来缓存。以 block 进行管理的内存可以通过buffer cache来缓存。 Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。 块的长度主要是根据所使用的块设备决定的，而页长度都是4k。 什么是page cache Page cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read／write操作的时候。仔细想想的话，作为可以映射文件到内存的系统调用：mmap是不是很自然的也应该用到page cache？malloc会不会用到page cache？ 在当前的实现里，page cache也被作为其它文件类型的缓存设备来用，所以事实上page cache也负责了大部分的块设备文件的缓存工作。 什么是buffer cache Buffer cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。但是由于page cache也负责块设备文件读写的缓存工作，于是，当前的buffer cache实际上要负责的工作比较少。这意味着某些对块的操作会使用buffer cache进行缓存，比如我们在格式化文件系统的时候。 一般情况下两个缓存系统是一起配合使用的，比如对一个文件进行写操作的时候，page cache的内容会被改变，而buffer cache则可以用来将page标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续 writeback 时，就不用将整个page写回，而只需要写回修改的部分即可。 buffer&#x2F;cache 不等同于空闲内存。内核需要维持内存缓存的一致性，在脏数据产生较快或数据量较大的时候，缓存系统整体的效率一样会下降，因为毕竟脏数据写回也是要消耗IO的。进程申请内存时，内核可以将buffer／cache占用的内存当成空闲的内存分给进程，但是其成本是内核会进行脏数据写回，保证数据一致后才会清空并分给进程使用。如果进程突然申请大量内存，而且业务是一直在产生很多脏数据（比如日志），并且系统没有及时写回的时候，此时系统给进程分配内存的效率会很慢，系统IO也会很高。 进程使用的用户空间内存映射包括文件影射（file）和匿名影射（anon）。 匿名影射主要是诸如进程使用malloc和mmap的MAP_ANONYMOUS的方式申请的内存 文件影射就是使用mmap影射的文件系统上的文件，这种文件系统上的文件既包括普通的文件，也包括临时文件&gt; 系统（tmpfs）。这意味着，Sys V的IPC和POSIX的IPC（共享内存，信号量数组和消息队列）都是通过文件影&gt; 射方式体现在用户空间内存中的。这两种影射的内存都会被算成进程的RSS，但是也一样会被显示在cache的内存计数中。 进程申请内存会发生什么申请内存不会真正的让内核去给进程分配一个实际的物理内存空间。真正会触发分配物理内存的行为是缺页异常。 缺页异常的处理过程大概可以整理为以下几个路径： 首先检查要访问的虚拟地址是否合法，如果合法则继续查找和分配一个物理页，步骤如下： 如果该虚拟地址在物理页表中不存在 如果是匿名影射，则申请置0的匿名影射内存，此时也有可能是影射了某种虚拟文件系统，比如共享内存，那么就去影射相关的内存区，或者发生COW写时复制申请新内存。 如果是文件影射，则有两种可能，一种是这个影射区是一个page cache，直接将相关page cache区影射过来即可，或者COW新内存存放需要影射的文件内容。如果page cache中不存在，则说明这个区域已经被交换到swap空间上，应该去处理swap。 如果页表中已经存在需要影射的内存 则检查是否要对内存进行写操作，如果不写，那就直接复用，如果要写，就发生COW写时复制。 分配内存过程先会检查空闲页表中有没有页可以申请，实现方法是：get_page_from_freelist。如果空闲中没有，则处理过程的主逻辑大概这样： 唤醒kswapd进程，把能换出的内存换出，让系统有内存可用。 继续检查看看空闲中是否有内存。有了就ok，没有继续下一步： 尝试清理page cache，清理的时候会将进程置为D状态。如果还申请不到内存则： 启动oom killer干掉一些进程释放内存，如果这样还不行则： 回到步骤1再来一次！ 以上逻辑中，不仅仅只有清理cache的时候会使进程进入D状态，还有其它逻辑也会这样做。这就是为什么在内存不够用的情况下，oom killer有时也不生效，因为可能要干掉的进程正好陷入这个逻辑中的D状态了。 Cgroup - Linux内存资源管理 | Zorro’s Linux Book IO缓存 库缓冲为啥要有库缓冲（如clib buffer）因为从应用层到内核层需要系统调用、内核态切换，开销比较大，为了减少调用次数 绕过库缓冲的方案用mmap(内存映射文件)，把内核空间的page cache映射到用户空间。 内核缓冲为啥要有内核缓冲内核用pdflush线程循环检测脏页，判断是否写回磁盘。由于磁盘是单向旋转，重新排布写操作顺序可以减少旋转次数。(合并写入) O_SYNC参数: 访问内核缓冲时是异步还是同步。O_SYNC表示同步。 绕过内核缓冲的方案用O_Direct参数，直接怼Disk cache。 磁盘缓冲为啥要有磁盘缓冲驱动通过DMA，将数据写入磁盘cache。磁盘缓冲主要是保护磁盘不被cpu写坏。是与外部总线交换数据的场所。（断电丢数据） 绕过磁盘缓冲的方案用RAW设备写，直接写扇区: fdisk，dd，cpio工具。 共享内存共享内存共享内存就是多个进程间共同使用同一段物理内存空间，它是通过将同一段物理内存映射到不同进程的虚空间中来实现的。由于映射到不同进程的虚拟地址空间中，不同进程可以直接使用，不需要进行内存的复制，所以共享内存的效率很高。 优点：共享内存（shared memory）是最简单的最大自由度的Linux进程间通信方式之一。使用共享内存，不同进程可以对同一块内存进行读写。由于所有进程对共享内存的访问就和访问自己的内存空间一样，而不需要进行额外系统调用或内核操作，同时还避免了多余的内存拷贝，这种方式是效率最高、速度最快的进程间通信方式。 缺点：内核并不提供任何对共享内存访问的同步机制，比如同时对共享内存的相同地址进行写操作，则后写的数据会覆盖之前的数据。所以，使用共享内存一般还需要使用其他IPC机制（如信号量）进行读写同步与互斥。 原理：内核对内存的管理是以页为单位的（4k）。而程序本身的虚拟地址空间是线性的，创建共享内存空间后，内核将不同进程虚拟地址的映射到同一个页面。所以在不同进程中，对共享内存所在的内存地址的访问最终都被映射到同一页面。 Linux的实现机制 System V共享内存：持久化的，除非被进程明确的删除，否则关机前始终存在于内存中 POSIX mmap文件映射实现共享内存：非持久化的，随着进程关闭，映射会随即失效 虽然 System V 与 POSIX 共享内存都是通过 tmpfs 实现，但由于内核在mount tmpfs时，指定了MS_NOUSER，所以该tmpfs没有大小限制。因此&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;shmmax只会限制 System V 共享内存，&#x2F;dev&#x2F;shm只限制Posix共享内存,默认是物理内存的一半。 tmpfs 一种基于内存的临时文件系统，tmpfs可以使用RAM，但它也可以使用swap分区来存储。传统的ramdisk是个块设备，要用mkfs来格式化它，才能真正地使用它；tmpfs是一个文件系统，并不是块设备，安装即可以使用。tmpfs是最好的基于RAM的文件系统，动态文件系统大小 &amp; 存取速度快 &#x2F;dev&#x2F;shm是利用内存虚拟出来的磁盘空间。通常是内存空间大小的一半，该目录下创建的文件存取速度优于普通硬盘挂载的目录下的文件，该目录下的文件在机器重启时会丢失。 System V共享内存基本介绍System V 是Unix操作系统众多版本中的一支，一共发行了4个 System V 的主要版本：版本1、2、3和4。 System V 共享内存机制为了在多个进程之间交换数据，内核专门留出了一块内存区域用于共享，共享这个内存区域的进程就只需要将该区域映射到本进程的地址空间中即可。内核直接实现了shmget &#x2F; shmat系统调用，最终也是靠tmpfs来实现的。 System V 的IPC对象有共享内存、消息队列、信号量。注意：在IPC的通信模式下，不管是共享内存、消息队列还是信号灯，每个IPC的对象都有唯一的名字，称为”键(key)”。通过”键”，进程能够识别所用的对象。”键”与IPC对象的关系就如同文件名称于文件，通过文件名，进程能够读写文件内的数据，甚至多个进程能够公用一个文件。而在IPC的通信模式下，通过”键”的使用也能使得一个IPC对象能为多个进程所共用。 使用步骤共享内存的使用过程可分为 创建-&gt;连接-&gt;使用-&gt;分离-&gt;销毁 这几步。 创建&#x2F;打开共享内存 映射共享内存，即把指定的共享内存映射到进程的地址空间用于访问 撤销共享内存的映射 删除共享内存对象 执行过程先调用shmget，获得或者创建一个IPC共享内存区域，并返回获得区域标识符。类似于mmap中先open一个磁盘文件返回文件标识符一样。再调用shmat，完成获得的共享区域映射到本进程的地址空间中，并返回进程映射地址。类似与mmap函数原理。使用完成后，调用shmdt解除共享内存区域和进程地址的映射关系。每个共享的内存区，内核维护一个struct shmid_ds信息结构，定义在sys&#x2F;shm.h头文件中 相关APIhttps://bbs.huaweicloud.com/blogs/316187 示例代码 1234567891011121314151617181920/***** writer.c *******/int main() &#123; key_t key = ftok(&quot;.&quot;,1); //1. 写入端先用ftok函数获得key int shmid = shmget(key,4096,IPC_CREAT); //2. 写入端用shmget函数创建共享内存段 printf(&quot;key = %d shmid = %d\\n&quot;, key, shmid); char *p = (char *)shmat(shmid, NULL, 0); //3. 获得共享内存段的首地址 memset(p, 0, 4096); memcpy(p, &quot;hello world&quot;, 4096); //4. 往共享内存段中写入内容 shmdt(p); //5. 关闭共享内存段&#125;/***** reader.c *******/int main() &#123; key_t key = ftok(&quot;.&quot;,1); int shmid = shmget(key,4096,IPC_CREAT); printf(&quot;key = %d shmid = %d\\n&quot;, key, shmid); char *p = (char *)shmat(shmid, NULL, 0); printf(&quot;receive the data:%s\\n&quot;,p); //4. 读取共享内存段中的内容 shmctl(shmid, IPC_RMID, 0); //5. 删除共享内存段, 否则数据会一直存在的 return 0;&#125; POSIX mmap实现共享内存基本介绍POSIX 表示可移植操作系统接口（Portable Operating System Interface），POSIX 标准定义了操作系统应该为应用程序提供的接口标准，是IEEE为要在各种UNIX操作系统上运行的软件而定义的一系列API标准的总称，其正式称呼为 IEEE 1003，而国际标准名称为 ISO&#x2F;IEC 9945。 POSIX 提供了两种在无亲缘关系进程间共享内存区的方法： 内存映射文件，由open函数打开，由mmap函数把所得到的描述符映射到当前进程空间地址中的一个文件。 共享内存区对象(shared-memory object)，由shm_open函数打开一个POSIX IPC名字，所返回的描述符由mmap函数映射到当前进程的地址空间。 这两种共享内存区的区别在于共享的数据的载体(底层支撑对象)不一样：内存映射文件的数据载体是物理文件；共享内存区对象，也就是共享的数据载体是物理内存。共享内存，一般是指共享内存区对象，也就是共享物理内存。 Posix的共享内存机制实际上在库过程中以及用户空间的其他部分被展示为完全的文件系统的调用过程，在调用完shm_open之后，需要调用mmap来将tmpfs的文件映射到地址空间，接着就可以操作这个文件了，需要注意的是，别的进程也可以操作这个文件，因此这个文件其实就是共享内存。 相关APIhttps://bbs.kanxue.com/thread-275275.htm 示例代码 12345678910111213141516171819202122232425262728293031323334// gcc writer.c -lrt -o writer/***** writer.c *******/int main() &#123; /* 创建共享对象，可以查看/dev/shm目录 */ int fd = shm_open(&quot;shm.test&quot;， O_CREAT | O_TRUNC | O_RDWR， 0777); /* 调整大小 */ ftruncate(fd， 1024*4) == -1); /* 获取属性 */ struct stat buf; fstat(fd， &amp;buf) == -1); printf(&quot;the shm object size is %ld\\n&quot;， buf.st_size); /* 建立映射关系 */ char *ptr = (char*)mmap(NULL， MAXSIZE， PROT_READ | PROT_WRITE， MAP_SHARED， fd， 0); printf(&quot;mmap %s success\\n&quot;， FILENAME); close(fd); /* 写入数据 */ char *content = &quot;hello world&quot;; strncpy(ptr， content， strlen(content));&#125;/***** reader.c *******/int main() &#123; /* 创建共享对象，可以查看/dev/shm目录 */ int fd = shm_open(&quot;shm.test&quot;， O_RDONLY， 0); /* 获取属性 */ struct stat buf; fstat(fd， &amp;buf); printf(&quot;the shm object size is %ld\\n&quot;， buf.st_size); /* 建立映射关系 */ char *ptr = (char*)mmap(NULL， buf.st_size， PROT_READ， MAP_SHARED， fd， 0); printf(&quot;mmap %s success\\n&quot;， FILENAME); close(fd); /* 关闭套接字 */ printf(&quot;the read msg is: %s\\n&quot;， ptr);&#125; 写放大原因读写单元较大文件系统的写放大：如果write的数据小于4K，则要先把整块读入，再修改，再把新的4K整体写入（O_DIRECT情况除外），这个过程可以称为 RMW (Read-Modify-Write)。 再如，在DBMS等应用层存储系统中，同样存在自己管理的读写单元，如MySQL的默认读写单元称为页，默认是16KB，所以一次读写只能以页的单位进行，造成了“写放大”。 RAID中的RMWRAID中更新一个块，需要额外读原始块、校验块，额外写校验块，所以多了两个读，一个写，也称为Read-Modify-Write。这是由于校验块必须更新，且根据异或运算的可逆性，新校验块&#x3D;新数据块^旧校验块^旧数据块。 SSD中闪存特性在SSD中，一个block可以分为多个page，在读的时候，可以以page为单位，但是写的时候，只能以block为单位，因此写的单元比较大。同样是读写1个page的大小，读的话直接读就行，写的话却需要先把与要写page同一个block的数据全复制一遍，加上修改的page后，再一起写入block。 存储系统一致性机制在存储系统的很多层次中，都有保证系统crash consistency（一致性）的设计。因此，不管是应用层的存储系统（如DBMS、KV-store）、虚拟化层中的镜像管理、系统层的文件系统，都要通过强制同步各种元数据的写入顺序，或者利用 redo log 的思想，用journaling、log-structured或copy-on-write等策略保证元数据写入目的位置生效前先完整地生成日志，来保证系统崩溃或断电时，元数据之间是一致。但是，如果多层存储系统重叠，由于一致性机制导致同步次数增加就会层层放大。 比如，运行在x86虚拟机中的levelDB，其一次更新操作就会 最终导致levelDB写log文件和写数据两次同步写，这两次写就又会 导致2次的Guest文件系统log写和2次Guest文件系统数据写，一共4次同步写，这4次写又会导致 虚拟化镜像管理层的4 x N次写（N取决于镜像为保证元数据crash consistency的同步次数，若是qcow2格式，N可能有5次之多），最后导致: Host文件系统的4 x N x 2 &#x3D; 8 x N次同步写。当然这是一种比较极端的情况，但实际应用中也应该存在。 LSM树KV系统的Merge操作levelDB等KV存储广泛采用了LSM树等结构进行存储组织，其特点就是靠上的level的数据会最终被merge sort到下层，由于多数level在磁盘文件中，这也就导致了同一KV数据的总写放大，放大的倍数就是大约是level的数目。","categories":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/categories/Storage/"}],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/tags/Storage/"}]},{"title":"分布式理论","slug":"Distribution/Distribution","date":"2024-09-17T20:53:00.000Z","updated":"2025-03-06T09:01:58.037Z","comments":true,"path":"2024/09/17/Distribution/Distribution/","permalink":"http://example.com/2024/09/17/Distribution/Distribution/","excerpt":"","text":"CAP一致性：在同一时刻副本一致，所有节点读到修改后的最新数据 - 强一致性、单调一致性、最终一致性可用性：每次请求都能获取非错的响应，尽量低延迟，不保证节点数据最新分区容忍性：出现网络分区时（节点间通信中断），系统仍能对外提供服务 BASEBasically Available（基本可用）：分布式系统在出现不可预知故障的时候，允许损失部分可用性Soft state（软状态）：软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。Eventually consistent（最终一致性）：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性 BASE是对CAP中一致性和可用性权衡的结果，其基本思路就是：通过业务，牺牲强一致性而获得可用性，并允许数据在一段时间内是不一致的，但是最终达到一致性状态。 一致性协议线性一致性一句话概括：在分布式系统上实现寄存器语义。寄存器中的变量可以被原子地被修改，且后续对该变量的读取会返回当次修改的值，直到其被再此修改，简单来说是保证读到最近更新的值。 如何判断一个分布式系统是具备线性一致性？首先我们约定好线性一致性条件下请求之间的相互关系： 对于调用时间有交叠的并发请求，生效的顺序可以任意确定。比如并发读写请求时，读请求无论返回新值、旧值都可以。 对于调用时间有偏序的请求，比如请求B开始在A结束之后，那么B的结果不能违背A已确定的结果。 按照上述给定的请求关系，结合实际调用结果来判断有否出现结果与约定相违背的情况，没有的话整个系统就符合线性一致性。如上图所示，我们可以认为线性一致性系统仿佛有一条隐藏的全局时间轴，每个请求调用的过程中都有一个生效瞬间（如“|”竖线所示）、在全局时间轴上有具体的时间戳，如果将调用生效瞬间按顺序连接起来，所有连线都会呈现从左到右、顺序发生的关系。看图中最后3个请求，cas(x,2,4)与两个read(x)分别都是并发关系，然而两个read(x)是有偏序的，说明后一个read(x)应该能读到前一个read(x)的结果。cas(x,2,4)虽然是与最后的read(x)是并发关系，但由于它的修改结果是成功的，说明其必须发生在前一个read(x)之前，所以到最后我们没法从最后3个请求中发现合理的调用顺序，所以系统不是线性一致性的。 顺序一致性不要求操作的时序与真实物理时间一致。两个不相关的操作，如序列 读A 写A 读B 写B，要求读A、B能读到最新值，但不要求读B到最新值时，读A也一定是最新值。 一致性解决方案两阶段提交 提交事务请求（投票阶段） 协调者向参与者发送事务内容，询问是否可以执行事务提交操作，等待响应 参与者执行事务操作，将undo和redo日志记录，并回复协调者执行成功Yes&#x2F;No 执行事务提交（执行阶段）. 如果都是参与者都回复Yes，则协调者向参与者发送提交请求，否则发送回滚请求 参与者根据协调者的请求执行事务提交或回滚，并向协调者发送Ack消息 协调者收到所有的Ack消息过后判断事务的完成或者中断 它是一个强一致性协议，但可用性太差，存在问题： 阻塞与单点故障：所有参与者必须收到协调者发起的指令才会提交，否则资源会被锁定，但当网络问题或协调者宕机时会阻塞 一致性问题：网络原因，参与者可能没收到协调者发送的指令(commit)，导致集群数据不一致 优化： 超时判断：长时间未收到回复可以多播取消事务 互询机制：参与者回复yes后，如果迟迟收不到协调者最终的commit&#x2F;abort，可以询问其他参与者来决定自身下一步操作，避免一直阻塞 2PC广泛应用于关系数据库的分布式事务处理，如mysql的内部与外部XA都是基于2PC的，一般想要把多个操作打包未原子操作也可以用2PC 三阶段提交把2PC的第一阶段拆成两阶段： 事务询问（canCommit） 协调者向参与者发送一个包含事务内容的询问请求，询问是否可以执行事务并等待 执行事务预提交（preCommit） 若协调者收到全是yes，就发送preCommit请求，否则发布abort请求 参与者若收到preCommit则执行事务操作并记录undo和redo然后发送Ack 执行事务提交（doCommit） 协调者收到所有的Ack则发送doCommit请求，若收到了No或者超时则发送abort请求 参与者收到doCommit就执行提交并发送Ack，否则执行回滚并发送Ack 协调者收到Ack判断是完成事务还是中断事务 2PC 和 3PC 是分布式事务中两种常见的协议，3PC 可以看作是 2PC 协议的改进版本，相比于 2PC 它有两点改进： 引入了超时机制，同时在协调者和参与者中都引入超时机制（2PC 只有协调者有超时机制），所以发生阻塞的几率变小了3PC 相比于 2PC 增加了 CanCommit 阶段，可以尽早的发现问题，从而避免了后续的阻塞和无效操作。 分布式一致性算法一致性算法的目的是保证在分布式系统中，多数据副本节点数据一致性。主要包含一致性Hash算法，Paxos算法，Raft算法，ZAB算法等。 RaftPaxosZABZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 崩溃恢复 和 原子广播 协议。基于该协议，Zookeeper 实现了一种 主备模式 的系统架构来保持集群中各个副本之间数据一致性。 当 Leader 服务可以正常使用，就进入消息广播模式，当 Leader 不可用时，则进入崩溃恢复模式。 消息广播： 使用的是一个原子广播协议，类似一个2PC过程。对于客户端发送的写请求，全部由 Leader 接收，Leader 将请求封装成一个事务，将其发送给所有 Follwer ，如果超过半数成功响应，则执行 commit 操作。减小了同步阻塞，也提高了可用性 在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，避免同步，实现异步解耦 崩溃恢复：ZAB定义两个原则： Leader 事务只要commit了，最终就会被所有服务器提交。 Leader 提出&#x2F;复制了事务但没提交，则丢弃事务。 Leader 崩溃后选举时，要保证新选举出来的 Leader 拥有集群总所有机器编号（即 ZXID 最大）的事务，即这个 Leader 一定具有所有已经提交的提案。当 Follower 链接上 Leader 之后，Leader 服务器会根据自己服务器上最后被提交的 ZXID (LeaderId + 事务ID) 和 Follower 上的 ZXID 进行比对，比对结果要么回滚，要么和 Leader 同步。 zookeeper是弱一致性模型，但是也可以支持强一致性模型，用sync()方法强制读取从leader同步数据。 分布式同步机制 kafka 削峰填谷、副本数量灵活、写入kafka后存储侧无需WAL带宽资源 业务方直接写则还得kafka中转、成本、Kafka partition数有限导致单个partition数据量大 主从(异步) 写入延迟低、便于batch优化、副本数量灵活 业务方是kafka的话，需要额外consumer资源、宕机丢数据 raft 读主时强一致性 难以双副本、性能得优化、跨AZ部署时的写入延迟","categories":[{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/categories/Distribution/"}],"tags":[{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/tags/Distribution/"}]},{"title":"MIT 6.824","slug":"Archive/ShardKV","date":"2024-07-27T19:30:00.000Z","updated":"2025-03-06T09:01:58.041Z","comments":true,"path":"2024/07/27/Archive/ShardKV/","permalink":"http://example.com/2024/07/27/Archive/ShardKV/","excerpt":"","text":"Raft QA Folding Raft 只在非拜占庭的条件下才能正常工作非拜占庭条件 是指所有的服务器都是 宕机-停止 模型：即每个服务器要么严格遵循 Raft 协议，要么停止服务。例如，服务器断电就是一个非拜占庭条件，此时服务器会停止执行指令，则 Raft 也会停止运行，且不会发送错误结果给客户端。拜占庭故障是指有些服务器不好好干活了——可能是代码因为有 bug，也可能是混入了恶意节点。如果出现这种类型节点，Raft 可能会发送错误的结果给客户端。发生网络分区后 Raft 会出现两个 Leader（脑裂）吗不会，被分到少数派分区的 Leader 会发现日志不能同步到大多数节点，从而不能提交任何日志。一种优化是，如果一个 Leader 持续不能联系到多数节点，就自动变为 Follower。Raft 对网络有什么假设网络是不可靠的：可能会丢失 RPC 请求和回复，也可能会经历任意延迟后请求才到达。但网络是有界的（bounded）：在一段时间内请求总会到达，如果还不到达，我们就认为该 RPC 丢失了。即使服务器不宕机，Leader 也可能会下台吗是的，比如说 Leader 所在服务器可能 CPU 负载太高、响应速度过慢，或者网络出现故障，或者丢包太严重，都有可能造成其他 Peer 不能及时收到其 AppendEntries，从而造成超时，发起选举。Raft 中的选举流程所有的 Peer 都会初始化为 Follower，且每个 Peer 都会有一个内置的选举超时的 Timer。当一段时间没有收到领导者的心跳或者没有投给其他 Candidate 票时，选举时钟就会超时。该 Peer 就会由 Follower 变为 Candidate，Term++，然后向其他 Peer 要票（带上自己的 Term 和最后一条日志信息）其他 Peer 收到请求后，如果发现 Term 不大于该 Candidate、日志也没有该 Candidate 新、本 Term 中也没有投过票，就投给该 Term 票。如果该 Peer 能收集到多数票，则为成为 Leader。读旧数据&#x2F;不知道被新leader取代的情况集群发生网络隔离，原 Leader 被隔离到少数节点的区域，多数节点区域已选出新 Leader，但原 Leader 由于无法通信并不知道，继续响应客户端请求，返回了旧数据。 Raft 主要在什么场景中使用 元信息服务，也称为配置服务、分布式协调服务等。用以追踪集群中元信息（如哪些机器、副本位置）、多副本选主等。 数据复制（系统中存储的数据），使用 Raft 作为数据复制和冗余的一种手段。与之相对，GFS 使用简单的主从复制的方法来冗余数据，可用性和一致性都比 Raft 要差。 Raft 为了简洁性做了哪些牺牲（性能问题） 每个操作都要落盘。如果想提高性能可能需要将多个操作 batch 起来。主从同步数据较慢。在每个 Leader 和 Follower 之间只允许有一个已经发出 AppendEntries；只有收到确认了，Leader 才能发下一个。类似 TCP 中的“停等协议”。如果写入速度较大，可能将所有的 AppendEntries Pipeline 起来性能会好一些（即 Leader 不等收到上一个 AppendEntries 的 RPC Reply，就开始发下一个） 只支持全量快照。如果状态机比较小这种方式还可以接受，如果数据量较大，就得支持增量快照。 全量快照同步代价大。如果快照数据量很大，每次全量发送代价会过高。尤其是如果 Follower 本地有一些较老的快照时，我们只需要发增量部分即可。 难以利用多核。因为 log 只有一个写入点，所有操作都得抢这一个写入点。 Raft prevote机制 节点 A 和其他节点发生网络隔离后，会不断发起选举但一直无法当选，推高 Term。等网络恢复通信后，由于 A 的 Term 最高，会强迫当前的 Leader 下台，重新选主。但由于在隔离期间日志被落下很多，A 通常也无法成为 Leader，最终大概率是原来的 Leader 的 Term 被拉上来之后，重新当选为 Leader。这个过程形象的称之为“惊群效应”。 PrevVote机制：每次发起选举时，不再推高 Term，但是会拿着 Term+1 去跟其他 Peer 要票，如果能要到合法的票数，再去推高 Term。 如果能要到多数票就保证了没发生网络隔离、日志是最新的 如果要不到多数票，就不能推高 Term，防止网络隔离的节点一直推高 Term。 新任期leader为什么同步no-op日志 因为leader选举的一个依据是日志的新旧程度(lastLogIndex)，但是受限于从节点的日志复制进度，commitIndex &lt;=lastLogIndex。所以如果在一个新任期的开始，客户端的读(commitIndex, lastLogIndex]之间的日志，可能读取的是未提交的数据。 因此规定在任期开始时，leader会在处理所有读请求之前写入一个”no-op”日志，主节点的lastLogIndex自增，然后将(nextIndex[i], lastLogIndex]区间的日志发送给响应的从节点，这样当多数从节点接收到后，leader节点可以提交这个日志项，commitIndex更新为lastLogIndex，确保读到最新数据。 “no-op”日志即只有 index 和 term 信息，command 信息为空，也是要写到磁盘存储的。 本质原因：新Leader当选后，旧任期的日志只能通过commit自己任期的日志来捎带提交，如图 Raft-figure8 所示： (c)中S5刚写完一条日志就挂了，S1重新当选Leader，Term&#x3D;4。此时还没有新的请求写入，如果S1将此前的index=2 &amp;&amp; term=2 的日志append到多数节点并提交了（埋下了隐患）(d)中S1又挂了，S5重新当选，并将 index=2 &amp;&amp; term=3 的日志复制到其他节点并提交，此时 index&#x3D;2 的日志提交了两次，已提交过的日志被覆盖了！！！ 虽然加了这个约束不会重复提交了，但如果一直没新的请求进来，旧term的日志迟迟无法提交，Leader 查到日志有记录但又不能回复，线性一致性要求不能返回陈旧的数据，Leader 迫切地需要知道这条日志到底能不能提交。 因此需要在 Leader 刚选举成功的时候立刻追加一条”no-op”日志，”no-op”日志一经提交，隐式地提交了之前任期未提交的日志，确认当前 commitIndex。 Raft 和 Paxos 有什么区别 Raft 和 Paxos 都是共识协议，而所有的共识协议在原理上都可以等价为 Paxos，共识协议本质上都是 Paxos。 Raft 是为了解决 Paxos 理解和实现都相对复杂的问题。将共识协议拆成两个相对独立的过程：领导者选举和日志复制，以降低理解和实现的复杂度。 Raft 其实是和 Multi-Paxos 等价，因为 Paxos 只解决单个值的共识问题。 Paxos 只要某个日志在多数节点存在后就可以安全提交；但在 Raft 中如果不是当前任期的日志，即使超过半数也不能直接提交，只能通过提交当前任期的日志来间接提交。 在Paxos 在选举时，Leader 可能需要借机补足日志，但 Raft 中选举过程完全不涉及日志复制，因为只有具有最新日志的 Candidate 才能成为 Leader，而 Paxos 不限制这一点。 Paxos 允许乱序 commit 日志，而 Raft 只允许顺序提交。 Paxos 每个节点的 term 是不一致的，全局自增；在 Raft 中 term 每个节点独立自增，但需要对齐。 Raft 在工程中有哪些常见的优化 由于领导者选举是个低频操作，主要 IO 路径优化还是集中在日志同步流程上。 batch：Leader 每次攒一批再刷盘和对 Follower 进行同步。降低刷盘和 RPC 开销。 pipeline：每次发送日志时类似 TCP 的“停-等”协议，收到 Follower 确认后才更新 nextIndex，发送后面日志。其实可以改成流水线式的，不等前面日志确认就更新 nextIndex 继续发后面的。当然，如果后面发现之前日志同步出错，就要回退 nextIndex 重发之前日志——而原始版本 nextIndex 在同步阶段是单调递增的。 并行 append：Leader 在 append 日志到本地前，就先发送日志给所有 Follower。 简述基于 raft 的分布式 KV 系统的架构 一个基于 raft 的分布式 KV 系统，实际上是由一组使用 raft 算法进行状态复制的节点组成。客户端会选择将请求发送到 Leader 节点，然后由 Leader 节点进行状态复制，即发送日志，当收到多数的节点成功提交日志的响应之后，Leader 会更新自己的 commitIndex，表示这条日志提交成功，并且 apply 到状态机中，然后返回结果给客户端。 以上是单个 raft 集群的分布式 KV 系统架构。如果系统中数据量较大，一个 raft 集群可能无法承受大量的数据，性能也会受到影响。因此还基于此设计了可分片的分布式 shardkv 系统。shardkv 由多个 raft 集群组成，每个集群负责一部分 shard 数据。Shard 到 raft 集群的映射关系，保存在独立的配置服务中。 如何处理客户端的重复请求 如果客户端的请求已经提交，但是 server 返回的过程中结果丢失，那么客户端会发起重试，导致这个请求在状态机中被执行了两次，会违背线性一致性。 因此需要保证客户端的请求只能被状态机应用一次，可以维护一个去重哈希表(duplicateTable)，客户端 ID + 命令 ID 组成一个唯一的标识符，每次请求的时候，判断 map 中是否存在这个命令，有就则直接返回结果，而不用再发送到 raft 模块进行同步。 还需注意的一个细节：一个客户端只会重试当前最新的这个命令，对于已经成功执行的命令就没必要重试了，因此去重 map 只需要为每一个客户端存储一个当前最新的命令即可。 这样做有一个前提：客户端默认在同一个时刻只会有一个命令，即一个 Clerk 内部是不会有并发的请求的 Shard 数据如何迁移 启动一个后台定时任务，定期从配置服务中获取最新的配置，如果检测到配置发生变更，则变更对应 shard 的状态，标记为需要进行迁移。 同时启动另一个后台定时任务，定期扫描 shard 的状态，如果检测到需要进行迁移的 shard，则发送消息，通过 raft 模块进行同步。然后在 Leader 节点中处理 shard 迁移的请求，将 shard 数据从原所属的 raft 集群中迁移到新的集群中。 如何处理 Shard 迁移与客户端请求的关系 如果客户端请求的 key 所属的 shard 并没有在迁移中，那么可以正常提供服务。否则则返回错误，让客户端进行重试。 此外，客户端请求和 shard 迁移请求存在并发情况，需要保证线性一致性。因此将 shard 迁移的请求也传入到 raft 模块进行同步，这样和客户端的请求是一致的，利用 raft 的一致性来保证两种不同请求的先后顺序，前面的执行结果一定对后续的请求可见。 线性一致读什么是线性一致读所谓线性一致读，一个简单的例子是在 t1 的时刻我们写入了一个值，那么在 t1 之后，我们一定能读到这个值，不可能读到 t1 之前的旧值。即当 Client 向集群发起写操作的请求并且获得成功响应之后，该写操作的结果要对所有后来的读请求可见。 Folding 左图展示了 Client A 的一个请求从发起到结束的过程。变量 x 的初始值是 1，x R() A 是一个事件 Invocation 意思是 A 发起了读请求，相应的 x OK(1) A 就是事件 Response A 读到了 x 且值为 1，Server 执行读操作。右图 Client A、B、C、D 均符合线性一致读。C 在 B 之后正确读到了 2。而 D 看起来是 Stale Read，但因为 D 请求横跨 3 个阶段，Read 可能发生在任意时刻，所以读到 1 或 2 都行。 为什么有线性一致的问题实现共识算法并不意味着能线性一致。共识算法只能保证不同节点对 Raft Log 能达成一致，但 Log 后面的状态机的一致性没有做详细规定，用户可以自由实现。例如 TiKV 在将 commit 的 Log 应用状态机（RocksDB）上时，可推出各个 TiKV 状态机的状态能达成一致，但不能保证同时将某个 Log 应用到 RocksDB 上，即各个节点不能实时一致，加之 Leader 会在不同节点之间切换，所以 Leader 的状态机也不总有最新的状态。Leader 处理请求时稍有不慎，没有在最新的状态上进行，这会导致整个系统违反线性一致性。 Raft LogRead每个 read 都有一个对应的 Op log，和 write 一样都走一遍一致性协议的流程。这个方法依据 commit index 对所有请求都做了排序，Log 是严格全序的，将这些 R&#x2F;W 操作一个一个应用到状态机，所得的结果必定符合线性一致性。 缺点：RPC 和 Log 开销、性能差（所有请求被序列化了，无法并发的操作状态机） ReadIndex由于只读请求并没有需要写入的数据，因此并不需要将其写入Raft日志，而只需要关注收到请求时leader的commit index。只要在该commit index被应用到状态机后执行读操作，就能保证其线性一致性。因此使用了ReadIndex的leader在收到只读请求时，会按如下方式处理： 确认 read 返回的数据的哪个点？记录当前的commit index，作为read index; 如果新 Leader 不知道最新的 committ index，则提交一个 No-op log entry 来提交之前的 log entry 确认当前的 Leader 是不是还是 Leader？避免网络分区时 Leader 被孤立的情况。向集群中的所有节点广播一次心跳，是否收到了过半数量的心跳响应 等到 leader 本地的apply index &gt;&#x3D; read index，此时可以保证只读操作的线性一致性，让状态机执行读操作并返回结果 缺点：每次 read 发送心跳开销太大 Lease read为了减少了 ReadIndex 每次 read 发送 heartheat 的开销，每次 leader 发送RPC的时候，会首先记录一个时间点 start，当系统大部分节点都回复时，就可以认为 leader 的 lease 有效期可以到 start + election timeout + clock drift bound（正负未知） 这个时间点。因为 follower 至少在 election timeout的时间之后才会重新发生选举，所以在Election Timeout内只需要确认一次即可 缺点：对分布式系统的时钟准确性要求很高，否则可能会出现不一致 Follower readTiKV的特性：当客户端对一个 Follower 发起读请求的时候，Follower 会请求此时 Leader 的 Commit Index，然后等本地 Apply 到 Leader 最新的 Commit Index 后，自己将这条数据返回给客户端。从而显著减轻 Leader 的负载，并提高读取性能。 缺点： 需要额外的通信延迟，因为每个读请求都需要先去询问领导者最新的commitIndex，所以减低延迟不明显，但好在优化读吞吐。 破坏线性一致性：由于Apply是异步的，Follower 可能比 Leader 先 Apply 这条记录，这样在 Follower 读到这条记录时，Leader 过一会才能读取到。但是好在是永远返回最新的数据。 ShardKV分布式 KV 服务将是一个复制状态机，由几个使用 raft 进行状态复制的 kv 服务节点组成。分布式 KV 服务需要保证在集群大多数节点正常的情况下依然能够正常提供服务，即使有一些其他的错误或者网络分区。 架构图 主要流程 客户端客户端 Clerk 会向 KV 服务发送三种类型的请求：Get/Put/Append。 保证线性一致性：要求客户端的修改对后续的请求都是生效的，即其他客户端能够立即看到修改后的结果，而不会因为我们的多副本机制而看到不一样的结果，最终的目的是要 kv 服务对客户端来说看起来“像是只有一个副本”。 服务端服务端的 KVServer 描述了一个 kv server 节点所维护的状态。里面维护了一个 raft 库中的 Raft 结构体，表示其是一个 raft 集群中的节点，它会通过 raft 提供的功能向其他的 KVServer 同步状态，让整个 raft 集群中的数据保持一致。 服务端收到请求后，先存储到 raft 日志中，然后等待 raft 模块同步完成，等待 notifyCh 中的状态机操作结果 raft 集群中的 Leader 节点处理了 Start 请求之后，会将日志同步到其他的 Follower 节点。 当多数的节点都正常处理之后，Leader 会更新自己的 commitIndex，然后将日志通过 applyCh 这个通道发送过去。 服务端启动 applyTask 后台线程，从 applyCh 中接收来自 raft 的日志消息。取出的日志消息对应的 Operation 已在节点间中同步完成，因此将 Operation 应用到本地状态机中，把返回结果（读到的值&#x2F;写是否成功）存储到 notifyCh 中。 这时 Get&#x2F;Put&#x2F;Append 方法就能从这个 notifyCh 中获取到结果，并返回给客户端。 参考链接 6.824 Schedule: Spring 2022Students’ Guide to RaftMIT 6.824 distributed systems 2022简介与课程翻译|6.824MIT 6.824涉及的部分论文翻译GeminiCx&#x2F;6.824-2022MIT6.824-lab3AB-2022（万字推导思路及代码构建）2021 MIT 6.824 札记2022-6.824-Lab2:RaftRaft 算法、分布式 KV 面试汇总","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"Cpp","slug":"CPP/Cpp","date":"2024-07-04T23:46:04.000Z","updated":"2025-03-06T09:01:58.037Z","comments":true,"path":"2024/07/04/CPP/Cpp/","permalink":"http://example.com/2024/07/04/CPP/Cpp/","excerpt":"","text":"Volatile,Atomic与Memory barrier 参考链接 三者的关联C++ 中的 volatile 关键字，std::atomic 变量及手动插入内存屏障指令（Memory Barrier）均是为了避免内存访问过程中出现一些不符合预期的行为。这三者的适用场景与区别如下： 如果需要原子性的访问支持，只能选择 atomic； 如果仅需保证内存访问不会被编译器优化掉，优先考虑 volatile； 如果需要保证 Memory Order，也优先考虑 atomic，只有当不需要保证原子性，而且很明确要在哪插入内存屏障时才考虑手动插入 Memory Barrier volatile Memory Barrier atomic 抑制编译器重排 Yes Yes Yes 抑制编译器优化 Yes No Yes 抑制 CPU 乱序 No Yes Yes 保证访问原子性 No No Yes 编译器重排编译器重排是指编译器在生成目标代码的过程中交换没有依赖关系的内存访问顺序的行为。 比如以下代码，编译器不保证在最终生成的汇编代码中对 p_a 内存的写入在对 p_b 内存的读取之前。 12*p_a = a;b = *p_b; 为了保证编译器不会进行错误的优化，可以通过以下三种方式来实现： 把对应的变量声明为 volatile 的，C++ 标准保证对 volatile 变量间的访问编译器不会进行重排，不过仅仅是 volatile 变量之间， volatile 变量和其他变量间还是有可能会重排的； 在需要的地方手动添加合适的 Memory Barrier 指令，Memory Barrier 指令的语义保证了编译器不会进行错误的重排操作； 把对应变量声明为 atomic 的， 与 volatile 类似，C++ 标准也保证 atomic 变量间的访问编译器不会进行重排。不过 C++ 中不存在所谓的 “atomic pointer” 这种东西，如果需要对某个确定的地址进行 atomic 操作，需要靠一些技巧性的手段来实现，比如在那个地址上进行 placement new 操作强制生成一个 atomic 等； 编译器优化此处的编译器优化特指编译器不生成其认为无意义的内存访问代码，如下代码对变量 a 的内存访问基本都会被优化掉。 123456void f() &#123; int a = 0; for (int i = 0; i &lt; 1000; ++i) &#123; a += i; &#125;&#125; 为了抑制编译器优化，可以把变量声明为 volatile 或 atomic，C++ 标准保证对 volatile 或 atomic 内存的访问肯定会发生。 不过需要注意的是，这时候手动添加内存屏障指令是没有意义的，在上述代码的 for 循环中加入 mfence 指令后，仅仅是让循环没有被优化掉，然而每次循环中对变量 a 的赋值依然会被优化掉，结果就是连续执行了 1000 次 mfence。 CPU 乱序由于CPU Store Buffer&#x2F;Invalidate queue 的存在，CPU 对一个变量的赋值操作可能无法被另一个核心及时观察到，即cache一致性问题。另外，CPU还有流水线、分支预测、乱序等特性，他们能提高CPU利用率，但也带来了CPU重排的现象，造成内存一致性（memory consistency）问题，这些是MESI协议解决不了的。 这些问题从根本上只能通过插入 Memory Barrier 内存屏障来解决，这些指令会使得 CPU 保证特定的内存访问序及内存写入操作在多核间的可见性。然而由于不同处理器架构间的内存模型和具体 Memory Barrier 指令均不相同，需要在什么位置添加哪条指令并不具有通用性，因此 C++ 11 在此基础上做了一层抽象，引入了 atomic 类型及 Memory Order 的概念，有助于写出更通用的代码。从本质上看就是靠编译器来根据代码中指定的高层次 Memory Order 来自动选择是否需要插入特定处理器架构上低层次的内存屏障指令。 写屏障会等待 Store Buffer 中的数据同步刷到cache后再执行屏障后面的写入操作。读屏障会将 Invalid Queue 中的数据处理完成后再执行屏障后面的读取操作。 访问原子性访问原子性就是 Read，Write 操作是否存在中间状态，具体如何实现原子性的访问与处理器指令集有很大关系，如果处理器本身就支持某些原子操作指令，如 Atomic Store， Atomic Load，Atomic Fetch Add，Atomic Compare And Swap（CAS）等，那只需要在代码生成时选择合适的指令即可，否则需要依赖锁来实现。C++ 中提供的可移植通用方法就是 std::atomic，volatile 及 Memory Barrier 均与此完全无关。 Memory order在atomic变量的store和load中提供以下选项，现在解释它们的含义： 含义解释memory_order_seq_cst要求底层提供顺序一致性模型，这个是默认提供的最强的一致性模型，在这种模型下不存在任何重排，可以解决一切问题 在底层实现上：程序的运行底层架构如果是非内存强一致模型，会使用cpu提供的内存屏障等操作保证强一致，在软件上，要求代码进行编译的时候不能够做任何指令重排。 memory_order_release&#x2F;acquire&#x2F;consume允许 cpu 或者编译器做一定的指令乱序重排，但是由于 tso, pso 的存在，可能产生 store-load 乱序、store-store 乱序导致问题。涉及到多核交互的时候，需要手动使用release 和 acquire去避免这样的这个问题了，与memory_order_seq_cst最大的不同的是，其是对具体代码可能出现的乱序做具体解决而不是要求全部都不能重排。 memory_order_relaxed提供松散一致性模型保障，不提供 operation order 保证。 使用例写顺序保证std::memory_order_release的含义是：在本行代码之前任何写内存的操作，都不能放到本行语句之后。尽管要求{1,2,3}代码的执行不能放到4的后面，但是{1,2,3}本身是可以被乱序的。release可以认为是发布一个版本，也就是说应该在发布之前做的，不能放到release之后。 12345678910std::atomic&lt;bool&gt; has_release;// thread_2 void release_software(int *data) &#123; int a = 100; // line 1 int c = 200; // line 2 if (!data) &#123; data = new int[100]; // line 3 &#125; has_release.store(true, std::memory_order_release); // line 4&#125; 读顺序的保证std::memory_order_acquire 的含义是：后续的读操作都不能放到这条指令之前。 例如 thread_1 按照 {line 1, line2} 的顺序呈现给 thread_2，thread_2 检查是否已经发布再读取，符合预期。 但如果采用 memory_order_relaxed，int x = *data 就可能会被重排到循环之前。 123456789101112131415161718std::atomic&lt;bool&gt; has_release;int *data = nullptr;// thread_1void releae_software() &#123; if (!data) &#123; data = new int[100]; // line 1 &#125; has_release.store(true, std::memory_order_release); // line 2 //.... do something other.&#125;// thread_2void use_software() &#123; // while (!has_release.load(std::memory_order_relaxed)); while (!has_release.load(std::memory_order_acquire)); int x = *data;&#125; 读顺序的消弱std::memory_order_consume 的含义是：所有后续对本原子类型的操作，都不能放到这条指令之前。 std::memory_order_acquire 与 std::memory_order_consume 的区别在于： memory_order_acquire 要求后面所有的读都不得提前： memory_order_consume 要求后面依赖于本次形成读则不能乱序。 例如，由于 global_addr, addr, x 形成了读依赖，所以这几个变量不能乱序。但是 d, f 可以放到 global_addr.load(std::memory_order_consume) 前面。而 std::memory_order_acquire 则要求都不能放到前面。 12345678void func(int *data) &#123; int *addr = global_addr.load(std::memory_order_consume); int d = *data; int f = *(data+1); if (addr) &#123; int x = *addr; &#125;&#125; 最强约束std::memory_order_seq_cst 表示最强约束。所有关于 std::atomic 的使用，如果不带函数（x.store or x.load），而是直接 std::atomic a; a = 1 ，那么就是强一制性的。所有这条指令前面的语句不能放到后面，所有这条语句后面的语句不能放到前面来执行。 CASCAS（Compare-and-Swap）是用于多线程以实现同步的原子指令。CAS 使用了乐观锁的概念执行原子操作，其内部的执行原理为： 获取内存中的当前值，然后传入期待值(expect)和新的值(desire)，比较当前值和期待值(Compare) 若相等，则将内存中的当前值更新为新的值(Swap) 若不相等，则重复该操作(原子操作失败，完全不执行，回滚至初始状态后重新操作)。 这种操作是CPU的一条原子指令，需要CPU支持，现在绝大部分CPU指令都支持CAS的原子操作。 C++提供了 atomic 模板支持一系列原子操作的类，提供的方法能保证操作具有原子性，不会获得修改过程之中的值，以确保不会在并发操作时产生不明确的行为。 该类提供了如下几种接口： store 原子写 load 原子读 exchange 修改当前值，并保证过程具有原子性 compare_exchange_weak compare_exchange_strong compare_exchange_weak 和 compare_exchange_strong 即为CAS操作，参数传入期待值 expected 和设定值 val： 若当前值（原子对象包含）与期待值相等，则将当前值修改为设定值，返回true 若当前值与期待值不等，则将期待值修改为当前值，返回false 1234bool compare_exchange_weak (T&amp; expected, T val, memory_order sync = memory_order_seq_cst) volatile noexcept;bool compare_exchange_weak (T&amp; expected, T val, memory_order sync = memory_order_seq_cst) noexcept;bool compare_exchange_weak (T&amp; expected, T val, memory_order success, memory_order failure) volatile noexcept;bool compare_exchange_weak (T&amp; expected, T val, memory_order success, memory_order failure) noexcept; compare_exchange_weak 和 compare_exchange_strong 的区别：weak允许偶然出乎意料的返回，比如当前值和期待值相等时候返回false，但在多数循环算法中是可以接受的，通常比strong具有更高的性能。 根据上述概念，可以使用C++实现一个简单的CAS无锁栈: Folding 123456789101112131415161718192021222324252627282930/* CAS无锁栈 */template&lt;typename T&gt;class ConcurrentStack &#123;public: void push(const T&amp; val) &#123; Node* new_node = new Node(val); new_node-&gt;m_next = m_head; while (!m_head.compare_exchange_weak(new_node-&gt;m_next, new_node)); &#125; T pop() &#123; Node* _now = m_head.load(); Node* _next = nullptr; do &#123; if (_now == nullptr) return NULL; _next = _now-&gt;m_next; &#125; while (!m_head.compare_exchange_weak(_now, _next)); T _tmp = _now-&gt;m_data; delete _now; return _tmp; &#125;private: struct Node &#123; Node(const T&amp; data) : m_data(data), m_next(nullptr) &#123;&#125; T m_data; Node* m_next; &#125;; std::atomic&lt;Node*&gt; m_head = nullptr;&#125;; Copy elisionCopy elision是指编译器为了优化，将不需要的copy&#x2F;move 操作（含析构函数，为了行文简洁，本文忽略析构函数的省略）直接去掉了。 RVO 是返回值优化，就是将返回值的创建省略了。 NRVO 是函数内具有名字的局部变量充当返回值的时候，它的创建也被省略了。 它们的省略结果都是在最终的变量里创建对象。C++17以后，RVO是保证会发生的，因为标准这么定义了。而NRVO并没有保证会发生，但是大部分编译器都会实现。 RVO123456Obj fun() &#123; return Obj();&#125;int main() &#123; Obj obj = fun();&#125; 在编译器不进行优化的情况下，这段代码一共会调用： 1 次构造函数：对应代码 Obj() 2 次拷贝构造函数： 函数返回使用到的临时对象的拷贝构造 对象 obj 的拷贝构造 3 次析构函数：将上述构造出的对象析构 当一个未具名且未绑定到任何引用的临时变量被移动或复制到一个相同的对象时，拷贝和移动构造可以被省略。当这个临时对象在被构造的时候，它会直接被构造在将要拷贝&#x2F;移动到的对象。编译器明确知道函数会返回哪一个局部对象，那么编译器会把存储这个局部对象的地址和存储返回临时对象的地址进行复用，也就是说避免了从局部对象到临时对象的拷贝操作。 在这个例子中，代码会被优化成这样： 1234567void fun(Obj &amp;_obj) &#123; _obj.Obj::Obj(); // 构造函数&#125;int main() &#123; Obj obj; // 仅定义不构造 fun(obj);&#125; 另外，这种针对未具名临时对象的拷贝构造优化同样也发生在容器操作中，在使用 vector::push_back 操作时，根据 push_back 的内容，会执行不同的步骤： 编译器优化：如果 push_back 的参数是 T 的一个对象，那么会直接调用拷贝构造函数在 vector 中构造对象，这时行为和 emplace_back 一致 正常行为：如果 push_back 的参数和 T 的某一个 implicit 构造函数一致，那么就会先调用该构造函数构造一个临时对象，然后调用移动构造函数将该临时对象移动到 vector 中 NRVO在RVO的基础上，NRVO 优化以下代码中的一次多余的拷贝构造 1234567Obj fun() &#123; Obj obj; return obj;&#125;int main() &#123; Obj obj = fun();&#125; 优化失效1.返回对象不为局部对象当返回的对象不是局部对象而是全局变量、函数参数或者成员变量时，会禁用 (N)RVO。2.返回对象类型和函数返回类型不同这时会触发隐式类型转换，会禁用 (N)RVO。3.运行时依赖当编译器无法单纯通过函数来决定返回哪个实例对象时，会禁用 (N)RVO。 1234567891011Obj fun(bool flag) &#123; Obj o1; Obj o2; if (flag) &#123; return o1; &#125; return o2;&#125;int main() &#123; Obj obj = fun(true);&#125; 如果逻辑上允许，最好优化成这样： 123456789101112Obj fun(bool flag) &#123; Obj obj; if (flag) &#123; return obj; &#125; obj.n = 10; return obj;&#125;int main() &#123; Obj obj = fun(true);&#125; 4.存在赋值行为(N)RVO 只能在从返回值创建对象时发送，在现有对象上使用 operator= 而不是拷贝&#x2F;移动构造函数，这样是不会进行优化的。 1234567Obj fun() &#123; return Obj();&#125;int main() &#123; Obj obj; obj = fun();&#125; 5.使用std::move()返回在返回值上调用 std::move() 进行返回是一种错误的方式。它会尝试强制调用移动构造函数，但这样会导致 (N)RVO 失效。因为即使没有显示调用 std::move()，编译器优化中也会执行 move 操作。 Auto &amp;&amp; 模板类型推导 参考链接 变量类型的占位符，编译器确定。用于定义 STL 迭代器、泛型编程中不知道变量具体类型或不想指定类型时 推导规则： 数组名或者函数名实参会退化为指针（除非被用于初始化引用） 有引用的实参会被视为无引用，在int &amp;a_ref = a; auto b = a_ref中 auto 推导为 int 而非 int&amp; 对于传值类型推导，const 和 volatile 属性会被忽略，在const int a = 1; auto b = a 中 auto 推导为 int 而非 const int 在万能引用中，T&amp;&amp;接收左值实参会被推导为T&amp;，发生了引用折叠 注意事项： 用auto声明的变量必须初始化，根据后面的值来推测这个变量的类型 函数和模板参数不能被声明为auto 不能用于类型转换等操作，如sizeof、typeid 初始化auto用 = ，圆括号会得到函数声明，返回值自动推断；大括号会推断成 initializer_list&lt;SomeType&gt; Lambda利用lambda表达式可以编写内嵌的匿名函数，用以替换独立函数或者函数对象； 定义一个lambda表达式后，编译器会自动生成一个匿名类（重载了()运算符），称为闭包类型，并把 capture 的变量作为该类的属性。闭包的一个强大之处是可以捕捉其作用域内的变量，比如在方括号中通过传值或引用方式捕获 Tip1：lambda必须使用尾置返回来指定返回类型，可以忽略参数列表和返回值，但必须永远包含捕获列表和函数体 Tip2：[=] 按值捕获的变量默认是不可修改的，类似const形参传递。想修改这些变量要添加 mutable，此时仍然不会影响外部的变量。类似的，按值捕获的对象也只能调用常方法 1234int a = 10;[=]() &#123; cout &lt;&lt; a &lt;&lt; endl; &#125;(); // 10[=]() mutable&#123; a = 20; cout &lt;&lt; a &lt;&lt; endl; &#125;(); // 20cout &lt;&lt; a &lt;&lt; endl; // 10 Tip3：用显式的按引用捕获，默认捕获可能会导致悬空引用，如局部变量生命周期结束 Tip4：用显式的按值捕获，默认的按值捕获对于悬空指针很敏感（尤其是this指针），并且它会误导人产生lambda是独立的想法。注意，通过[=] [&amp;] [this] 显式捕获 this 都是 by-reference 的，只有 [*this] 是 by-copy 的 1234567891011121314151617class Widget &#123;public: function&lt;void()&gt; CreateCB() &#123; auto cb = [=] &#123; cout &lt;&lt; id_ &lt;&lt; endl; &#125;; // 实际捕获了 this 指针，并非值拷贝 // cb = [curObjPtr] &#123; cout &lt;&lt; curObjPtr-&gt;id_ &lt;&lt; endl; &#125; return cb; &#125; int id_&#123;1&#125;;&#125;;int main() &#123; Widget w; function&lt;void()&gt; cb = w.CreateCB(); cb(); // 1 w.id_ = 2; cb(); // 2&#125; 左值与右值C++11通过引入右值引用来优化性能，配合移动语义来避免拷贝。通过std::move()语义来将临时生成的左值中的资源无代价的转移到另外一个对象中去。std::move() 的实现原理就是的强转右值引用类型并返还之，由于函数返还值类型是临时值，且返还的还是右值引用类型，因此该返还值会被判断为右值。 左值右值分类lvalue：左值，有标识符、可以取地址的表达式 变量、函数 返回左值引用的表达式，++x、x&#x3D;1 字符串字面量 “hello world” 函数调用时，左值可以绑定到T&amp;，常量只能绑定到const T&amp; rvalue：右值，如常量值、函数返回值、lambda表达式 prvalue：纯右值，传统意义上的右值，不具名的临时对象，无名无地址 返回非引用类型表达式，x++、x+1、make_shared(32) 非字符串字面量，42、true 特点：不能作为赋值操作的左值 xvalue：将亡值表示即将被销毁的对象，通常是通过右值引用操作产生的，表示一个可以被移动的对象，通常用于移动语义避免拷贝 如通过 std::move 产生 左值右值引用右值引用和左值引用都是属于引用类型，都必须立即进行初始化，因为引用类型只是一个别名，并不拥有绑定对象的内存。 左值引用：具名变量的别名。左值引用通常不能绑定到右值，但常量左值引用可以接受非常量左值、常量左值、右值，不过常量左值所引用的右值在它的“余生”中只能是只读的。右值引用：用于绑定右值或即将销毁的变量，允许移动而非复制操作，减少深拷贝，提高程序效率。 用途： 移动语义：通过移动构造函数和移动赋值运算符，可以将资源从一个对象“移动”到另一个对象，而不是复制资源 完美转发：右值引用与模板结合使用，可以实现完美转发，即将参数原封不动地传递给另一个函数。这在编写泛型代码时非常有用。 注意事项： 右值引用变量是左值：尽管右值引用可以绑定到右值，但右值引用本身是一个左值。需要使用 move 或 forward 来显式地将其转换为右值 避免使用已移动的对象：移动操作后，源对象进入一种有效但未指定的状态，应该避免使用 临时对象在对应表达式估值完成后、按生成顺序逆序销毁。若纯右值被绑定到引用上，其生命周期会延长至与引用变量相同 特殊成员函数生成机制 C++特殊成员函数及其生成机制 Item 17: Understand special member function generation 1. 默认构造函数 编译器默认生成条件： 没有显式声明的构造函数 所有的数据成员和基类都拥有自己的默认构造函数 2. 析构函数 编译器默认生成条件：没有显式声明析构函数 3. 拷贝操作 编译器默认生成条件： 不存在显式声明的拷贝操作 不存在显式声明的移动操作（理论上也不能声明析构，但不严格要求） 所有的成员变量都能够被拷贝构造或拷贝赋值 拷贝构造和拷贝赋值运算符的生成是独立的：只声明其中一个，编译器能自动生成另一个 注意：拷贝操作的生成规则不是很严格，并不严格符合 The Rule of Three，这是为了不破坏历史遗留代码。C++11标准只规定：在已经存在拷贝操作或析构函数的条件下，把自动生成拷贝操作列为废弃行为 The Rule of Three：如果我们声明了析构&#x2F;拷贝构造&#x2F;拷贝赋值中的一个，就要同时声明另外的两个。换句话说，如果声明了析构函数，那么拷贝操作就不应该被生成，因为它们的行为可能不正确。 4. 移动操作 编译器默认生成条件： 不存在显式声明的移动操作 不存在显式声明的析构函数和拷贝操作 所有的数据成员都是可以被拷贝或移动 移动构造和移动赋值运算符的生成并不独立：声明了其中一个，编译器就不会生成另一个 [TODO] 一个令人困扰的点以下代码显式声明了析构函数，但使用了移动构造函数时仍然编译运行通过。有一种解释是：确实不会隐式生成移动构造函数，在需要移动构造函数时，会用复制构造函数代替。真是如此吗，还是生成了移动构造？暂时没法验证… 123456789class Widget &#123;public: Widget() &#123; cout &lt;&lt; &quot;construct&quot; &lt;&lt; endl; &#125; virtual ~Widget() &#123; cout &lt;&lt; &quot;destruct&quot; &lt;&lt; endl; &#125;&#125;;int main() &#123; Widget w; Widget y = std::move(w);&#125; 完美转发在模板函数内给另一个函数传递参数时，无论对象是左值&#x2F;右值引用类型，都会被视为左值。因为，完美转发用于保证不丢失其左值&#x2F;右值属性：如果形参推导出是右值引用则作为右值传入，如果是左值引用则作为左值传入 完美转发依赖于三个概念： 1. 万能引用：发生类型推导（模板、auto）的时候，使用 T&amp;&amp; 类型表示为万能引用。它可以绑定到（接收）左值和右值，从而使得模板函数能处理不同类型参数。T&amp;&amp; 推导后的类型： 如果传入左值，T 会被推导为左值引用类型。 如果传入右值，T 会被推导为普通类型。 2. 引用折叠：当万能引用作为参数时，有可能被一个左值引用或右值引用的参数初始化，这时经过类型推导出来T&amp;&amp;类型，相比右值引用会发生类型的变化，这种变化就称为引用折叠 所有右值引用折叠到右值引用上仍然是一个右值引用 所有的其他引用类型之间的折叠都将变成左值引用 3. std::forward()：原理为 return static_cast(形参)，利用了折叠规则。从而接受右值引用类型时，返还值为右值；接受左值引用类型时，返还值为左值 虚函数Vptr与Vtable虚函数表：为了实现虚函数，C++ 通过虚表解决了后期绑定时查找调用函数的问题。每个含有虚函数的类都有虚表，它是编译时期初始化的静态数组，数组中每个条目是一个函数指针。虚表全局共享，存储在常量区。 虚指针：编译器还会添加一个隐藏的 vptr 指向虚表。vptr在构造函数中初始化，先在父类构造函数中指向父类的虚表，之后在子类构造函数中改为指向子类虚表。与this指针不同，this指针实际上是编译器用来解析自引用的函数参数，vptr 是一个真正的指针，占用4B&#x2F;8B大小，也会被派生类继承。 调用过程： 对于：ptr -&gt; z() 不知道ptr所指类型，但可以读取该对象virtual table 不知道哪个z()被调用，但知道每个z()地址都放在slot k 转化为：(*ptr -&gt; vptr[k])(ptr) 如何构造Vtable单继承(A-&gt;B) 继承A的虚函数实体：将其地址拷贝到B的virtual table对应slot中 重写A的虚函数实体：将自己的函数实体地址放到virtual table对应slot中 加入新的虚函数：virtual table尺寸增大一个slot，并放入函数地址 多继承(A1,A2-&gt;B)多重继承下，有几个基类就对应几个虚函数表，虚函数表的顺序和继承时相同。 派生类和第一个基类共用虚函数表，派生类自己的虚函数放在第一个虚函数表的后面，派生类如果要覆盖基类中的虚函数，那么会在虚函数表中代替其位置 多继承下影响到虚函数的调用的实质上为this的调整： 如果 A1 类型引用 B 对象时就不用调整，因为起始地址一致 如果 A2 类型引用 B 对象并且调用 B 重写的虚函数时，由于 A2 引用的起始地址和 B 不同，它的 this 指针地址比 B 对象多了 n 字节的偏移量，所以直接调用虚函数会导致错误，需要调用前调整 this 指针指向 B Thunk技术解决了这个问题，它允许虚函数表中slot包括两个类型的地址: 不需要调整地址，指向虚函数实体地址 需要调整地址，指向一个相关的Thunk偏移量，从而将 this 指针调整到正确的位置，即减少若干字节的偏移量，然后再去调用虚函数 Folding 指向成员函数的指针“指向Nonstatic Member Functions”的指针定义并初始化: double (Point::*coord)() = &amp;Point::x;调用: (origin.*coord)() 或 (ptr-&gt;*coord)()被编译器转化为: (coord)(&amp;origin);和(coord)(ptr);“指向Virtual Member Functions”的指针1234class Point &#123; float x(); virtual float y();&#125;;对nonstatic函数取地址:取x()的地址: &amp;Point::x() 得到的是函数在内存中的地址对virtual函数取地址:取y()的地址:&amp;Point::y(); 得到的结果是2(索引值.)1float (Point::*pmf)() = &amp;Point::y;对指向虚函数的指针调用:通过pmf来调用y()仍能实现虚函数机制，会被编译转化为 (*ptr-&gt;vptr[(int)pmf])(ptr);对一个”指向member function的指针”求值，由于该值有两种意义，其调用也将有别于常规操作pmf的内部定义为 float (Point::*pmf)()，可以指向 nonvirtual x()和 virtual z()。前者代表内存地址，后者代表 virtual table中的索引值。因此编译器必须定义pmf，使它含有这两种值并区分代表哪种 能否使用虚函数 模板类中可以使用虚函数吗？模板成员函数可以是虚函数吗？ 前者可以，后者不行：编译阶段不知道程序中对虚成员模板函数的调用，就无法确定virtual table大小 构造函数能用虚函数吗：不能 从使用上，构造函数是在创建对象时自己主动调用的，不可能通过父类的指针去调用，用虚函数没意义。 从实现上，此时虚指针还没建立，找不到vtable，违反了先实例化后调用的准则 析构函数能用虚函数吗：推荐用，基类指针自动调用派生类析构方法，防止内存泄漏 构造函数和析构函数能调用虚函数吗：不提倡，并不会使用动态联编 构造函数中，子类对象还没初始化，调用子类不安全 析构函数中，子类对象已经销毁，同样调用虚函数没有意义 虚函数能声明inline吗： 当指向派生类的指针调用虚函数时，不会内联展开，因为编译器无法确定展开哪个函数 当是对象本身调用虚函数时，会内联展开，但前提需要函数并不复杂 析构函数能抛异常吗：不能 异常点后无法执行，内存泄漏 出现异常时，在栈展开过程中会调用在栈中构造好的对象的析构函数，此时如果上个异常还没解决，析构函数中又有新异常，会崩溃 多线程简例1. 线程池 Folding 123456789101112131415161718192021222324252627282930313233343536373839404142434445class ThreadPool &#123; public: ThreadPool(int num = 4): isclosed(false) &#123; for (int i = 0; i &lt; num; ++i) &#123; thread([this]&#123; unique_lock&lt;mutex&gt; lck(m); while (true) &#123; if (!tasks.empty()) &#123; auto task = move(tasks.front()); tasks.pop(); lck.unlock(); task(); lck.lock(); &#125; else if (isclosed) &#123; break; &#125; else &#123; cv.wait(lck); &#125; &#125; &#125;).detach(); &#125; &#125; ~ThreadPool() &#123; isclosed = true; cv.notify_all(); &#125; void AddTask(const function&lt;void()&gt;&amp; task) &#123; &#123; unique_lock&lt;mutex&gt; lck(m); tasks.push(task); &#125; cv.notify_one(); &#125; private: mutex m; condition_variable cv; atomic&lt;bool&gt; isclosed; queue&lt;function&lt;void()&gt;&gt; tasks;&#125;;int main() &#123; ThreadPool pool; pool.AddTask([] &#123; cout &lt;&lt; 12 &lt;&lt; endl; &#125;); pool.AddTask([] &#123; cout &lt;&lt; 34 &lt;&lt; endl; &#125;); this_thread::sleep_for(chrono::seconds(1));&#125; 2. 同步交替打印 Folding 12345678910111213141516171819202122232425262728#include &lt;bits/stdc++.h&gt;using namespace std;mutex m;condition_variable cv;int flag = 0;void print(int i)&#123; for(int k = 0; k &lt; 5; ++k) &#123; &#123; unique_lock&lt;mutex&gt; lck(m); while(flag != i) &#123; cv.wait(lck); &#125; cout &lt;&lt; i + 1 &lt;&lt; endl; flag = (flag + 1) % 3; &#125; // 先释放互斥锁，防止唤醒后抢锁失败 cv.notify_all(); &#125;&#125;int main()&#123; vector&lt;thread&gt; pool; for(int i = 0; i &lt; 3; ++i) pool.push_back(thread(print, i)); for(auto&amp; t:pool) t.join();&#125; 3. 生产者消费者 Folding 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;bits/stdc++.h&gt;#include &lt;unistd.h&gt;using namespace std;#define MAX_SIZE 10mutex m;condition_variable cv;queue&lt;char&gt; que;void consumer()&#123; while(true)&#123; unique_lock&lt;mutex&gt; lck(m); while(que.empty())&#123; cv.wait(lck); &#125; cout &lt;&lt; &quot;消费了 &quot; &lt;&lt; que.front() &lt;&lt; endl; que.pop(); cv.notify_all(); &#125;&#125;void productor()&#123; while(true)&#123; sleep(1); unique_lock&lt;mutex&gt; lck(m); while(que.size() &gt;= MAX_SIZE)&#123; cv.wait(lck); &#125; char c = &#x27;A&#x27; + random() % 10; cout &lt;&lt; &quot;生产了 &quot; &lt;&lt; c &lt;&lt; endl; que.push(c); cv.notify_all(); &#125;&#125;int main()&#123; vector&lt;thread&gt; pool; for(int i = 0; i &lt; 4; ++i) pool.push_back(thread(productor)); for(int i = 0; i &lt; 4; ++i) pool.push_back(thread(consumer)); for(auto &amp;t : pool) t.join();&#125; 4. 哲学家就餐 Folding 123456789101112131415161718192021222324252627282930313233#include &lt;bits/stdc++.h&gt;using namespace std;constexpr int N = 5;class DiningPhilosophers &#123;public: void wantsToEat(int philosopher, function&lt;void()&gt; pickLeftFork, function&lt;void()&gt; pickRightFork, function&lt;void()&gt; eat, function&lt;void()&gt; putLeftFork, function&lt;void()&gt; putRightFork) &#123; int l = philosopher; int r = (philosopher + 1) % N; if(philosopher &amp; 1) &#123; lock[r].lock(); lock[l].lock(); pickRightFork(); pickLeftFork(); &#125; else &#123; lock[l].lock(); lock[r].lock(); pickLeftFork(); pickRightFork(); &#125; eat(); putLeftFork(); putRightFork(); lock[l].unlock(); lock[r].unlock(); &#125;private: mutex lock[N];&#125;; 异步编程 https://zhuanlan.zhihu.com/p/553377822 std::future\\promise future表示一个可能还没有实际完成的异步任务的结果，针对这个结果可以添加回调函数以便在任务执行成功或失败后做出对应的操作；C++11 future内定义了一个原子对象，主线程通过自旋锁不断轮询，此外会进行 sys_futex 系统调用 promise交由任务执行者，任务执行者通过promise可以标记任务完成或者失败 所以 future\\promise 编程模型本质上还是message pass（任务线程与主线程消息传递）。在future模型中阻塞和非阻塞都有：拉起一个新线程（非阻塞），在主线程 .get() （阻塞）。整个流程见下图： 其实future&#x2F;promise最强大的功能是能够： 获得结果返回值 处理异常（如果任务线程发生异常） 链式回调（目前c++标准库不支持，但folly支持） std::future 不支持拷贝，支持移动构造。c++提供的另一个类std::shared_future 支持拷贝。 1234567891011void compute(std::promise&lt;int&gt;&amp; pms) &#123; std::this_thread::sleep_for(std::chrono::seconds(1)); pms.set_value(100); // set_value后，future变为就绪&#125;int main() &#123; std::promise&lt;int&gt; pms; std::future&lt;int&gt; fut = pms.get_future(); std::thread t(&amp;compute, std::ref(pms)); std::cout &lt;&lt; fut.get() &lt;&lt; std::endl; // 会阻塞 t.join();&#125; std::asyncstd::async 的默认启动策略是异步和同步执行兼有的。这个灵活性导致访问 thread_local 的不确定性，隐含了任务可能不会被执行的意思，会影响调用基于超时的wait的程序逻辑 如果异步执行任务非常关键，则指定 std::launch::async 12345678910111213// std::launch::deferred 在调用 f1.wait() 时执行std::future&lt;void&gt; f1 = std::async(std::launch::deferred, []&#123; std::this_thread::sleep_for(std::chrono::seconds(3)); std::cout &lt;&lt; &quot;hello world&quot; &lt;&lt; std::endl;&#125;);f1.wait();// std::launch::async 创建新线程立刻执行std::future&lt;std::string&gt; f2 = std::async(std::launch::async, []&#123; std::this_thread::sleep_for(std::chrono::seconds(3)); return std::string(&quot;hello world&quot;);&#125;);std::cout &lt;&lt; f2.get() &lt;&lt; std::endl; std::packaged_taskstd::packaged_task 将任何可调用对象（函数、lambda表达式等）封装成 task，可以异步执行，结果用 std::future 获取 12345678910111213141516171819202122232425262728int f(int x, int y) &#123; return std::pow(x, y); &#125;void task_lambda() &#123; std::packaged_task&lt;int(int, int)&gt; task( [](int a, int b) &#123; return std::pow(a, b); &#125; ); std::future&lt;int&gt; res = task.get_future(); task(2, 9); std::cout &lt;&lt; res.get() &lt;&lt; std::endl;&#125;void task_bind() &#123; std::packaged_task&lt;int()&gt; task(std::bind(f, 2, 10)); std::future&lt;int&gt; res = task.get_future(); task(); std::cout &lt;&lt; res.get() &lt;&lt; std::endl;&#125;void task_thread() &#123; std::packaged_task&lt;int(int, int)&gt; task(f); std::future&lt;int&gt; res = task.get_future(); std::thread task_td(std::move(task), 2, 11); task_td.join(); std::cout &lt;&lt; res.get() &lt;&lt; std::endl;&#125;","categories":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/categories/CPP/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/tags/CPP/"}]},{"title":"CPU Cache","slug":"OS/CPU Cache","date":"2024-05-15T01:14:36.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2024/05/15/OS/CPU Cache/","permalink":"http://example.com/2024/05/15/OS/CPU%20Cache/","excerpt":"","text":"CPU缓存架构 寄存器：在每个核心上，有160个用于整数和144个用于浮点的寄存器单元。访问这些寄存器只需1个时钟周期这构成了对执行核心来说最快的内存。编译器会将本地变量和函数参数分配到这些寄存器上。当使用超线程技术（ hyperthreading ）时，这些寄存器可以在超线程协同下共享。 内存排序缓冲：MOB由一个64长度的load缓冲和36长度的store缓冲组成。这些缓冲用于记录等待缓存子系统时正在执行的操作。store缓冲是一个完全的相关性队列，可以用于搜索已经存在store操作，这些store操作在等待L1缓存的时候被队列化。在数据与缓存子系统传输时， 缓冲可以让处理器异步运转。当处理器异步读或者异步写的时候，结果可以乱序返回。为了使之与已发布的内存模型一致，MOB用于消除load和store的顺序。 L1 Cache：本地核心内的缓存，被分成独立的32K数据缓存和32K指令缓存。访问需要3个时钟周期，并且当指令被核心流水化时， 如果数据已经在L1缓存中的话，访问时间可以忽略。 L2 Cache：本地核心内的缓存，被设计为L1缓存与共享的L3缓存之间的缓冲。L2缓存大小为256K，主要作用是作为L1和L3之间的高效内存访问队列。L2缓存同时包含数据和指令。L2缓存的延迟为12个时钟周期。 L3 Cache：在同插槽的所有核心都共享L3缓存。L3缓存被分为数个2MB的段，每一个段都连接到槽上的环形网络。每一个核心也连接到这个环形网络上。地址通过hash的方式映射到段上以达到更大的吞吐量。根据缓存大小，延迟有可能高达38个时钟周期。在环上每增加一个节点将消耗一个额外的时钟周期。缓存大小根据段的数量最大可以达到20MB。L3缓存包括了在同一个槽上的所有L1和L2缓存中的数据。这种设计消耗了空间，但是使L3缓存可以拦截对L1和L2缓存的请求，减轻了各核心私有的L1和L2缓存的负担。 主内存：在缓存完全没命中的情况下，DRAM通道到每个槽的延迟平均为65ns。具体延迟多少取决于很多因素，比如，下一次对同一缓存行中数据的访问将极大降低延迟，而当队列化效果和内存刷新周期冲突时将显著增加延迟。每个槽使用4个内存通道聚合起来增加吞吐量，并通过在独立内存通道上流水线化（ pipelining ）将隐藏这种延迟。 NUMA：在一个多插槽的服务器上，会使用非一致性内存访问（Non-Uniform Memory Access）。所谓的非一致性是指，需要访问的内存可能在另一个插槽上。只有当CPU访问自身直接attach内存时，才会有较短的响应时间（Local Access）。而如果需要访问其他CPU attach的内存的数据时，就需要通过inter-connect通道访问，响应时间就相比之前变慢了（Remote Access）。 CPU Cache 是由很多个 Cache Line 组成，每个Cache Line大小为64KB。Cache Line 是 CPU从内存读写数据的基本单位，每次从内存中读取完整的一个Cache Line到Cache进行读写操作。 Cache Line从Cache写回内存由两种方案： 写直达 Writer Through，把数据同时写入内存和Cache中；性能较差 写回 Writer Back，新的数据仅仅被写⼊Cache⾥，只有当修改过的Cache Line被换出时才需要写到内存中，减少数据写回内存的频率；性能较好 Cache Coherence现在 CPU 都是多核的，由于 L1&#x2F;L2 Cache 是多个核心各自独有的，那么会带来多核心的缓存一致性（Cache Coherence）的问题，如果不能保证缓存一致性的问题，就可能造成结果错误。假设 A 和 B 号核心同时运行两个线程，且都操作共同的变量 i（采用写回策略），将导致不一致。 要想实现缓存一致性，关键是要满足 2 点： 写传播：当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心； 事物的串行化：保障数据是真正一致的，程序在各个不同的核心上运行的结果也是一致的； MESI 协议MESI 协议用四个状态来标记 Cache Line 四个不同的状态： Modified，已修改 Exclusive，独占 Shared，共享 Invalidated，已失效 已修改代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。已失效表示 Cache Block 里的数据已经失效了，不可以读取该状态的数据。 独占和共享状态都代表 Cache Block 里的数据是干净的，即这时候 Cache Block 里的数据和内存是一致的。 独占：数据只存储在一个 CPU 核心的 Cache 里，可以直接自由地写入，而不需要通知其他 CPU 核心。如果有其他核心从内存读取了相同的数据到各自的 Cache ，独占状态下的数据就会变成共享状态。 共享：相同的数据在多个 CPU 核心的 Cache 里都有，所以更新 Cache 时不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为无效状态，然后再更新当前 Cache 里面的数据。 对于不同状态触发的事件操作，可能是来自本地 CPU 核心发出的广播事件，也可以是来自其他 CPU 核心通过总线发出的广播事件。下图是 MESI 协议的状态图： MESI协议解决了多核环境cache多层级带来的一致性问题，CPU核心对本地cache的修改可以被其它核心观测到，使得cache层对于CPU来说是透明的。单一地址变量的写入，可以以线性的逻辑进行理解。 MESI 带来的问题False Sharing由于 CPU 以 64KB 的 Cache Line 为最小单位从内存中加载数据，可能会出现这样的问题： 假设变量 a 和 b 位于同一个 Cache Line 中，当前 CPU0 和 CPU1 都将这个 Cache Line 加载到 Cache，CPU0 只修改变量 a，CPU1 只读取变量 b。 当 CPU0 修改 a 时，CPU1 的 Cache Line 会变为 Invalid 状态，即使 CPU1 并没有修改 b，这会导致 CPU1 从内存或其它核心重新加载 Cache Line 中的所有变量，影响性能。 解决 False Sharing 的方法是字节填充，在 a 和 b 之间填充无意义的变量，使一个变量单独占用一个 Cache Line。 RMW操作不安全MESI协议无法保证并发场景下RMW操作（Read-Modify-Write操作，先读取再计算最后写回）的安全性。 例如两个线程都执行 i++，i的初值为 0。 两个核心执行 Read 操作的时候，CPU0 和 CPU1 的 cache 都是 Shared 状态 两个核心各自修改自己的寄存器，然后准备将寄存器值需要写入到 cache 假设，CPU1 先完成写入 cache 的操作，状态变为 Modified，导致 CPU0 Cache 状态已经变成了 Invalid CPU0 需要重新发出 Read 请求读取 Cache Line 后继续写入，这时 CPU1 会响应自己修改后的最新 Cache Line，同时写回主存 CPU0 获得 CPU1 修改后的 Cache Line，将i值1写入，导致覆盖掉了CPU1 的自增结果 最终两个i++操作之后，i的值还是 1 使用LOCK前缀指令可以解决这个问题，下文会详细介绍。 性能问题CPU修改Cache Line中的变量时，要通过总线发送Invalidate信息给远程CPU，等到远程CPU返回ACK，才能进行继续修改。如果远程的CPU比较繁忙，会带来更大的延迟。 为了解决这个问题，引入了Store buffer。 Store buffer和Invalidate queueStore buffer在CPU和L1Cache之间引入Store buffer来对cache line的写操作进行优化。 写操作写入Store Buffer后就返回，同时向其它核心发出Invalidate消息。 等CPU的Invalidate ACK消息返回后再异步写进Cache Line 核心从Cache中读取前都要先扫描自己的Store buffers来确认是否存在目标行。有可能当前核心在这次操作之前曾经写入cache，但该数据还没有被刷入cache(之前的写操作还在 store buffer 中等待)。 Store buffer对写操作有明显的优化，但也带来CPU内存一致性的问题（出现内存重排）。 注意，虽然CPU可以读取其之前写入到本地Store buffer中的值，但其它核心并不能在该核心将Store buffer中的内容Flush到Cache之前看到这些值。即 Store buffer是不能跨核心访问的，CPU看不到其它核心的 Store buffer。 Store buffer刷入cache前，其它核心最多只知道cache line已失效（收到Invalidate消息） Invalidate queueStore Buffer 容量是有限的，当Store Buffer满了之后CPU核心还是要卡住等待Invalidate ACK。 接收方响应Invalidate ACK耗时的主要原因是核心需要先将自己cache line状态修改后才响应ACK 如果一个核心很繁忙或者处于S状态的副本特别多，可能所有CPU都在等它的ACK。 CPU优化这个问题的方式是引入Invalid queue，CPU核心先将Invalidate消息放到这个队列并立刻响应Invalidate ACK，但不马上处理，消息只是会被推invalidation队列，并在之后尽快处理。 因此核心可能并不知道在它Cache里的某个Cache Line是Invalid状态的，因为Invalidation队列包含有收到但还没有处理的Invalidation消息。 CPU在读取数据的时候，并不像Store buffer那样读取Invalidate queue。 引入Store buffer和Invalidate queue之后，不同核心上运行的线程对cache line的并发读写可以会出现问题，即修改不会同步被其它核心处理。 Memory Consistency下面两个goroutine执行时，会出现几种可能的结果： 123456789var x, y intgo func() &#123; x = 1 // A1 fmt.Print(&quot;y:&quot;, y, &quot; &quot;) // A2&#125;()go func() &#123; y = 1 // B1 fmt.Print(&quot;x:&quot;, x, &quot; &quot;) // B2&#125;() 很显然的几种结果： 1234y:0 x:1x:0 y:1x:1 y:1y:1 x:1 令人意外的结果： 12x:0 y:0y:0 x:0 出现这两种意外结果的原因就是内存重排 Memory Reordering。 内存重排是指内存读写指令的重排，原因分为软件层面的编译器重排和硬件层面的CPU重排。 编译器重排编译器（compiler）的工作之一是优化我们的代码以提高性能。这包括在不改变程序行为的情况下重新排列指令。因为compiler不知道什么样的代码需要线程安全（thread-safe），所以compiler假设我们的代码都是单线程执行（single-threaded），并且进行指令重排优化并保证是单线程安全的。因此，在不需要compiler重新排序指令的时候，需要显式告诉编译器，这里不需要重排。 对于这段C语言代码 12345int a, b;void foo(void)&#123; a = b + 1; b = 0;&#125; 编译优化后的逻辑可以看作如下形式： 123456int a, b;void foo(void)&#123; register int reg = b; b = 0; a = reg + 1;&#125; 这种 compiler reordering 在某些情况下可能会引入问题，例如用一个全局变量flag标记共享数据data是否就绪。2个线程，一个用来更新data的值。使用flag标志data数据已经准备就绪，其他线程可以读取。另一个线程一直调用read_data()，等待flag被置位，然后返回读取的数据data。 如果compiler产生的汇编代码是flag比data先写入内存，即使是单核系统上也会有问题，如： 在flag置1之后，data写入之前，系统发生抢占 另一个线程发现flag已经置1，认为data的数据已经就绪 但实际上读取data的值并不是合法值 123456789101112int flag, data;void write_data(int value) &#123; data = value; flag = 1; // data is ready.&#125;void read_data(void) &#123; int res; while (flag == 0); // wait for data to be ready. res = data; // read data. flag = 0; return res;&#125; 为什么compiler还会这么操作呢？因为，compiler不知道data和flag之间有严格的依赖关系，这种逻辑关系是我们人为引入的。如下面代码的情况，如果当前只有这一个线程读写X变量，程序的运行结果是符合预期的。但在多线程环境下，假如另一个CPU核心执行了 X &#x3D; 0，输出就不一样了。 123456789// 原代码X = 0for i in range(100): X = 1 print X// 编译器优化后X = 1for i in range(100): print X 为了防止 编译器重排 导致多线程程序逻辑错误的情况，需要在编码时手动插入 内存屏障，禁止编译器调整屏障两边的读写操作。即，内存屏障也具有 编译器屏障 的效果。 1234567#define barrier() __asm__ __volatile__(&quot;&quot;: : :&quot;memory&quot;)int a, b;void foo(void)&#123; a = b + 1; barrier(); b = 0;&#125; barrier()就像是代码中的一道不可逾越的屏障，barrier前的 load&#x2F;store 操作不能跑到barrier后面；同样，barrier后面的 load&#x2F;store 操作不能跑到barrier之前。 CPU重排CPU重排是一种运行时的内存重排序。 由于CPU Store Buffer&#x2F;Invalidate queue的存在，CPU对一个变量的赋值操作可能无法被另一个核心及时观察到，造成出现开头内存重排的另外两种令人意外的结果。这是CPU重排现象的一种原因。 另外，CPU还有流水线、分支预测、乱序等特性，他们的目的都是最大化提高CPU利用率，但也带来了CPU重排的现象，造成 内存一致性memory consistency 问题，这些是MESI协议解决不了的。 写屏障12345678910111213a = 0flag = falsefunc runInCpu0() &#123; a = 1 flag = true&#125;func runInCpu1() &#123; while (!flag) &#123; continue &#125; print(a)&#125; 假设有如下执行步骤： 假定当前a存在于cpu1的cache中，flag存在于cpu0的cache中，状态均为E。 cpu1先执行while(!flag)，由于flag不存在于它的cache中，所以它发出Read flag消息 cpu0执行a&#x3D;1，它的cache中没有a，因此它将a&#x3D;1写入Store Buffer，并发出Invalidate a消息 cpu0执行flag&#x3D;true，由于flag存在于它的cache中并且状态为E，所以将flag&#x3D;true直接写入到cache，状态修改为M cpu0接收到Read flag消息，将cache中的flag&#x3D;true发回给cpu1，状态修改为S cpu1收到cpu0的Read Response：flat&#x3D;true，结束while(!flag)循环 cpu1打印a，由于此时a存在于它的cache中a&#x3D;0（且认为是合法状态），所以打印出来了0 cpu1此时收到Invalidate a消息，将cacheline状态修改为I，但为时已晚 cpu0收到Invalidate ACK，将Store Buffer中的数据a&#x3D;1刷到cache中 从结果看，两个写入操作发生了重排序，代码好像变成了： 1234func runInCpu0() &#123; flag = true a = 1&#125; CPU从软件层面提供了 写屏障write memory barrier 指令来解决上面的问题，Linux将CPU写屏障封装为smp_wmb()函数。 写屏障解决上面问题的方法是等待当前Store Buffer中的数据同步刷到cache后再执行屏障后面的写入操作。 加入写屏障后，当cpu0执行flag&#x3D;true时，由于Store Buffer中有a&#x3D;1还没有刷到cache上，所以会先等待a&#x3D;1刷到cache之后再执行flag&#x3D;true，当cpu1读到flag&#x3D;true时，a也就&#x3D;1了。 12345678910111213a = 0flag = falsefunc runInCpu0() &#123; a = 1 smp_wmb() flag = true&#125;func runInCpu1() &#123; while (!flag) &#123; continue &#125; print(a)&#125; 读屏障现在考虑Invalidate queue带来的问题，还是以上面的代码为例。 我们假设a在CPU0和CPU1中，且状态均为S，flag由CPU0独占 CPU0执行a&#x3D;1，因为a状态为S，所以它将a&#x3D;1写入Store Buffer，并发出Invalidate a消息 CPU1执行while(!flag)，由于其cache中没有flag，所以它发出Read flag消息 CPU1收到CPU0的Invalidate a消息，并将此消息写入了Invalid Queue，接着就响应了Invlidate ACK CPU0收到CPU1的Invalidate ACK后将a&#x3D;1刷到cache中，并将其状态修改为了M CPU0执行到smp_wmb()，由于Store Buffer此时为空所以就往下执行了 CPU0执行flag&#x3D;true，因为flag状态为E，所以它直接将flag&#x3D;true写入到cache，状态被修改为了M CPU0收到了Read flag消息，因为它cache中有flag，因此它响应了Read Response，并将状态修改为S CPU1收到Read flag Response，此时flag&#x3D;true，所以结束了while循环 CPU1打印a，由于a存在于它的cache中且状态为S，所以直接将cache中的a打印出来了，此时a&#x3D;0，这显然发生了错误。 CPU1这时才处理Invalid Queue中的消息将a状态修改为I，但为时已晚 为了解决上面的问题，CPU提供了 读屏障指令，Linux将其封装为了smp_rwm()函数。 1234567func runInCpu1() &#123; while (!flag) &#123; continue &#125; smp_rwm() print(a)&#125; CPU执行到smp_rwm()时，会将Invalid Queue中的数据处理完成后再执行屏障后面的读取操作，这就解决了上面的问题了。 除了上面提到的 读屏障 和 写屏障 外，还有一种 全屏障Full barrier，它其实是读屏障和写屏障的综合体，兼具两种屏障的作用，在Linux中它是smp_mb()函数。 前面提到的 LOCK前缀指令 其实兼具了内存屏障的作用。 CPU重排问题靠是MESI协议解决不了的，还是需要使用内存屏障技术，在需要时同步Flush Store buffer和Invalidate queue。 CPU内存一致性模型cache一致性和内存一致性有什么区别呢？ 可以简单地认为，cache一致性关注的是多个CPU看到一个地址的数据是否一致，而内存一致性更多关注的是多个CPU看到多个地址数据读写的次序是否一致。 针对内存一致性问题，提出内存一致性模型的概念，方便软件工程师在不理解硬件的情况下，基于硬件的内存一致性模型编写正确的并行代码。 内存一致性模型讨论的是，在引入Store buffer等CPU乱序机制后，指令流的定义顺序与CPU实际执行顺序的一致性问题。 目前有多种内存一致性模型。不同的处理器平台，本身的内存模型也有强Strong弱Weak之分。 顺序存储模型 Sequential Consistency 最强一致性，没有乱序存在，严重限制硬件对CPU的优化 完全存储定序 Total Store Order Strong Memory Model，强内存模型，如X86&#x2F;64，保证每条指令的acquire&#x2F;release语义 部分存储定序 Part Store Order 宽松存储模型 Relax Memory Order Weak Memory Model，弱内存模型，如ARM&#x2F;PowerPC 分类顺序存储模型SC多核心会完全按照指令流的顺序执行代码。 C1与C2的指令虽然在不同的CORE上运行，但是C1发出来的访问指令是顺序的，同时C2的指令也是顺序 虽然这两个线程跑在不同的CPU上，但是在顺序存储模型上，其访问行为与UP（单核）上是一致的 所以在顺序存储模型上是不会出现内存访问乱序的情况。 完全存储定序TSOTSO会利用Store buffer提高CPU利用率，并且严格按照FIFO的顺序将Store buffer中的Cache Line写入主存。 123S1：store flag = setS2：load r1 = dataS3：store b = set 在顺序存储模型中，S1肯定会比S2先执行。 但是加入了Store buffer之后，S1将指令放到了Store buffer后会立刻返回，这个时候会立刻执行S2。S2是read指令，CPU必须等到数据读取到r1后才会继续执行。这样很可能S1的store flag&#x3D;set指令还在Store Buffer上，而S2的load指令可能已经执行完（特别是data在Cache上存在，而flag没在Cache中的时候。这个时候CPU往往会先执行S2减少等待时间）。 加入了store buffer之后，内存一致性模型就发生了改变。 完全存储定序TSO要求，严格按照FIFO的次序将数据发送到主存（先进入Store Buffer的指令数据必须先于后面的指令数据写到存储器中），这样S3必须要在S1之后执行。 CPU只保证Store指令的存储顺序，即完全存储定序（TSO）。而对于Store指令后面有Load指令的情况，CPU可能会将Load指令提前执行完成。这就是所谓的 Store-Load 乱序，x86 唯一的乱序就是这种。 关于x86架构的强内存序： x86架构不存在invalidate queue，因此不存在 Load-Load&#x2F;Load-Store乱序 store buffer严格按照FIFO，因此不存在Store-Store乱序 由于store buffer，存在Store-Load乱序 部分存储定序PSO芯片设计人员并不满足TSO带来的性能提升，于是他们在TSO模型的基础上继续放宽内存访问限制，允许CPU以非FIFO来处理Store buffer缓冲区中的指令。CPU只保证 地址相关指令 在Store buffer中才会以FIFO的形式进行处理，而其他的则可以乱序处理，所以这被称为部分存储定序（PSO）。 这里的地址相关指令，指多个指令操作的地址相同或者有前后关联。例子中L1和L2就是地址无关指令。 这时可能出现这样的执行顺序 S2 L1 L2 S1 ，即 Store-Store乱序。由于S2可能会比S1先执行，从而会导致C2的r2寄存器获取到的data值为0。 宽松存储模型RMO在PSO的模型的基础上，更进一步的放宽了内存一致性模型，不仅允许Store-Load，Store-Store乱序。还进一步允许Load-Load，Load-Store乱序。只要是地址无关的指令，在读写访问时都可以打乱所有Load&#x2F;Store的顺序，这就是宽松内存模型（RMO）。 RMO内存模型里乱序出现的可能性会非常大，这是一种乱序随处可见的内存一致性模型。 Acquire&#x2F;Release 语义Acquire语义是指从共享内存中读取数据，无论是读-修改-写还是直接load。这些操作都被归类为read acquire。 Acquire语义保证了read-acquire操作不会被程序后续的任何read或write操作打乱顺序。 Release语义是指向共享内存中写入数据，无论是读-修改-写还是直接store。这些操作都被归类为write-release。 Relase语义保证了write-release操作不会被程序前面的任何read或write操作打乱顺序。 x86只有Store-Load乱序，因此x86上每条指令都符合acquire和release语义。 内存模型的重要性内存一致模型，或称内存模型，是一份语言用户与语言自身、语言自身与所在的操作系统平台、 所在操作系统平台与硬件平台之间的契约。它定义了并行状态下拥有确定读取和写入的时序的条件， 并回答了一个共享变量是否具有足够的同步机制来保障一个线程的写入能否发生在另一个线程的读取之前这个问题。 在一份程序被写成后，将经过编译器的转换与优化、所运行操作系统或虚拟机等动态优化器的优化，以及 CPU 硬件平台对指令流的优化才最终得以被执行。这个过程意味着，对于某一个变量的读取与写入操作，可能 被这个过程中任何一个中间步骤进行调整，从而偏离程序员在程序中所指定的原有顺序。 没有内存模型的保障，就无法正确的推演程序在最终被执行时的正确性。 内存模型的策略同样有着长期影响，并且直接决定了程序的可移植性和可维护性。 例如，过强的内存模型将约束硬件和编译器优化的空间，从而严重降低程序性能上限； 已经选择了强内存模型的硬件体系结构，无法在不破坏兼容性的情况下向更弱的内存模型进行迁移， 这种兼容性破坏所带来的代价就是要求其平台上的程序重新实现其源码。 这种横跨用户、软件与硬件三大领域的主题使得内存模型的设计愿景变得异常的困难，至今仍是一个开放的研究问题。 如今主流的编程语言的内存模型都是顺序一致性(SC)模型，它为开发人员提供了一种理想的SC机器(虽然实际中的机器并非SC的)，程序是建构在这一模型之上的。开发人员要想实现出正确的并发程序，还必须了解编程语言封装后的同步原语以及他们的语义。只要程序员遵循并发程序的同步要求合理使用这些同步原语，那么编写出来的并发程序就能在非SC机器上跑出顺序一致性的效果。 内存屏障芯片设计人员为了尽可能的榨取CPU的性能，引入了乱序的内存一致性模型，这些内存模型在多线程的情况下很可能引起软件逻辑问题。 为了解决在有些一致性模型上可能出现的内存访问乱序问题，芯片设计人员提供给了内存屏障指令。 内存屏障的最根本的作用就是提供一个机制，要求CPU在这个时候必须以顺序存储一致性模型的方式来处理Load与Store指令，这样才不会出现内存不一致的情况。 对于TSO和PSO模型，内存屏障只需要在Store-Load&#x2F;Store-Store时需要（写内存屏障），最简单的一种方式就是内存屏障指令必须保证Store buffer数据全部被清空的时候才继续往后面执行，这样就能保证其与SC模型的执行顺序一致。 而对于RMO，在PSO的基础上又引入了Load-Load与Load-Store乱序。RMO的读内存屏障就要保证前面的Load指令必须先于后面的Load&#x2F;Store指令先执行，不允许将其访问提前执行。 memory barrier 是必须的。一个 Store barrier 会把 Store Buffer flush 掉，确保所有的写操作都被应用到 CPU 的 Cache。一个 Read barrier 会把 Invalidation Queue flush 掉，也就确保了其它 CPU 的写入对执行 flush 操作的当前这个 CPU 可见。 Intel为此提供四种内存屏障指令： sfence ，实现Store Barrier。将Store Buffer中缓存的修改刷入L1 cache中，使得其他cpu核可以观察到这些修改，而且之后的写操作不会被调度到之前，即sfence之前的写操作一定在sfence完成且全局可见； lfence ，实现Load Barrier。 Flush Invalidate Queue，强制读取L1 cache，而且lfence之后的读操作不会被调度到之前，即lfence之前的读操作一定在lfence完成（并未规定全局可见性）； mfence ，实现Full Barrier。 同时刷新Store Buffer和Invalidate Queue，保证了mfence前后的读写操作的顺序，同时要求mfence之后的写操作结果全局可见之前，mfence之前的写操作结果全局可见； lock 用来修饰当前指令操作的内存只能由当前CPU使用，若指令不操作内存仍然有用，因为这个修饰会让指令操作本身原子化，而且自带Full Barrior效果；还有指令比如IO操作的指令、CHG等原子交换的指令，任何带有LOCK前缀的指令以及CPUID等指令都有内存屏障的作用。 X86-64下仅支持一种指令重排：Store-Load ，即读操作可能会重排到写操作前面，同时不同线程的写操作不保证全局可见，这个问题只能用mfence解决，不能靠组合sfence和lfence解决。 解决 cache coherence 的协议(MESI)并不能解决 CAS 类的问题。同时也解决不了 memory consistency，即不同内存地址读写的可见性问题，要解决 memory consistency 的问题，需要使用 memory barrier 之类的工具。 并发编程如果我们的缓存总是保证一致性，那么为什么我们在写并发程序时要担心可见性？这是因为核心为了得到更好的性能，对于其它线程来说，可能会出现数据修改的乱序。这么做主要有两个理由： 编译器在生成程序代码时，为了性能，可能让变量在寄存器中存在很长的时间，例如，变量在一个循环中重复使用。如果我们需要这些变量在核心之间可见，那么变量就不能在寄存器分配。可以添加 volatile 关键字达到这个目标。但是 volatile 并不能保证让编译器不重排我们的指令，因此需要使用内存屏障。 一个线程写了一个变量，然后很快读取，有可能从读缓冲中获得比缓存子系统中最新值要旧的值。这对于遵循单写入者原则（Single Writer Principle）的程序来说没有任何问题，但是对于 Dekker 和Peterson锁算法就是个很大问题。为了克服这一点，并且确保最新值可见，线程不能从本地读缓冲中读取值。可以使用屏障指令，防止下一个读操作在另一线程的写操作之前发生。 误区回到作为并发算法中的一部分的“刷新缓存”误区上，我想，可以说我们永远不会在用户空间的程序上“刷新”CPU缓存。我相信这个误区的来源是由于在某些并发算法需要刷新、标记或者清空store缓冲以使下一个读操作可以看到最新值。为了达到这点，我们需要内存屏障而非刷新缓存。 这个误解的另一个可能来源是，L1缓存，或者 TLB，在上下文切换的时候可能需要根据地址索引策略进行刷新。ARM，在ARMv6之前，没有在TLB条目上使用地址空间标签，因此在上下文切换的时候需要刷新整个L1缓存。许多处理器因为类似的理由需要L1指令缓存刷新，在许多场景下，仅仅是因为指令缓存没有必要保持一致。上下文切换消耗很大，除了污染L2缓存之外，上下文切换还会导致TLB和&#x2F;或者L1缓存刷新。Intel x86处理器在上下文切换时仅仅需要TLB刷新。 参考链接https://zhuanlan.zhihu.com/p/43526907","categories":[{"name":"OS","slug":"OS","permalink":"http://example.com/categories/OS/"}],"tags":[{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"}]},{"title":"MapReduce","slug":"Distribution/MapReduce","date":"2024-04-15T23:54:04.000Z","updated":"2025-03-06T09:01:58.037Z","comments":true,"path":"2024/04/15/Distribution/MapReduce/","permalink":"http://example.com/2024/04/15/Distribution/MapReduce/","excerpt":"","text":"摘要MapReduce既是一种编程模型，也是一种与之关联的、用于处理和产生大数据集的实现。用户要特化一个map程序去处理key&#x2F;value对，并产生中间key&#x2F;value对的集合，以及一个reduce程序去合并有着相同key的所有中间key&#x2F;value对。许多实际的任务都可以用这种模型来表示 用这种函数式风格写出的程序自动就拥有了在一个大的PC机集群上并行执行的能力。运行时系统会负责细节：切分输入数据，在一组机器上调度执行程序，处理机器错误，以及管理所需的机器间通信。这允许不具备任何并行和分布式系统经验的程序员也能轻松地利用一个大型分布式系统的资源 编程模型计算过程就是输入一组key&#x2F;value对，再生成输出一组key&#x2F;value对MapReduce库的使用者用两个函数来表示这个过程：map和reduce map由使用者编写，使用一个输入key&#x2F;value对，生成一组中间key&#x2F;value对。MapReduce库将有着相同中间key I的中间value都组合在一起，再传给reduce函数 reduce也由使用者编写，它接受一个中间key和一组对应的value。它将这些value合并为一个可能更小的value集合。通常每个reduce调用只产生0或1个输出value。中间value是通过一个迭代器提供给reduce函数的。这允许我们操作那些因为大到找不到连续存放的内存而使用链表的value集合 实现执行过程 图1展示了MapReduce操作的整体流程。当用户程序调用MapReduce函数时，会发生下面一系列动作（图1中的标号与下面列表顺序相同）： 用户程序中的MapReduce库首先将输入文件切分为M块，每块的大小从16MB到64MB（用户可通过一个可选参数控制此大小）。然后MapReduce库会在一个集群的若干台机器上启动程序的多个副本 程序的各个副本中有一个是特殊的——主节点，其它的则是工作节点。主节点将M个map任务和R个reduce任务分配给空闲的工作节点，每个节点一项任务 被分配map任务的工作节点读取对应的输入区块内容。它从输入数据中解析出key&#x2F;value对，然后将每个对传递给用户定义的map函数。由map函数产生的中间key&#x2F;value对都缓存在内存中 缓存的数据对会被周期性的由划分函数分成R块，并写入本地磁盘中。这些缓存对在本地磁盘中的位置会被传回给主节点，主节点负责将这些位置再传给reduce工作节点 当一个reduce工作节点得到了主节点的这些位置通知后，它使用RPC调用去读map工作节点的本地磁盘中的缓存数据。当reduce工作节点读取完了所有的中间数据，它会将这些数据按中间key排序，这样相同key的数据就被排列在一起了。同一个reduce任务经常会分到有着不同key的数据，因此这个排序很有必要。如果中间数据数量过多，不能全部载入内存，则会使用外部排序 reduce工作节点遍历排序好的中间数据，并将遇到的每个中间key和与它关联的一组中间value传递给用户的reduce函数。reduce函数的输出会写到由reduce划分过程划分出来的最终输出文件的末尾 当所有的map和reduce任务都完成后，主节点唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码中 成功完成后，MapReduce执行的输出都在R个输出文件中（每个reduce任务产生一个，文件名由用户指定）。通常用户不需要合并这R个输出文件——他们经常会把这些文件当作另一个MapReduce调用的输入，或是用于另一个可以处理分成多个文件输入的分布式应用 主节点数据结构主节点维持多种数据结构。它会存储每个map和reduce任务的状态（空闲、处理中、完成），和每台工作机器的ID（对应非空闲的任务） 主节点是将map任务产生的中间文件的位置传递给reduce任务的通道。因此，主节点要存储每个已完成的map任务产生的R个中间文件的位置和大小。位置和大小信息的更新情况会在map任务完成时接收到。这些信息会被逐步发送到正在处理中的reduce任务节点处。 容错性1.工作节点错误主节点周期性的ping每个工作节点。如果工作节点在一定时间内没有回应，主节点就将它标记为已失败。这个工作节点完成的任何map任务都被重置为空闲状态，并可被调度到其它工作节点上。同样地，失败的工作节点上正在处理的任何map或reduce任务也被重置为空闲状态，允许被调度 失败节点上已完成的map任务需要重执行的原因是它们的输出存储在失败机器的本地磁盘上，因此无法访问到了。已完成的reduce任务不需要重执行，因为它们的输出存储在了一个全球文件系统上 当一个map任务先被A节点执行过，随后又被B节点重执行（A节点已失败），所有执行reduce任务的工作节点都能收到重执行的通知。任何没有读取完A节点数据的reduce任务都会从B节点读取数据 2.主节点错误一种简单的方法是令主节点定期将上面描述的数据结构保存为恢复点。如果主节点任务失败，就可以从上一个恢复点状态启动一个新的程序副本。但是给定的条件是只有一个主节点，它也不太可能失败；因此我们当前的实现会在主节点失败时中止MapReduce计算 。客户可以检查到这一情况，并在他们需要时重启MapReduce操作 3.出现故障时的语义当用户提供的map和reduce操作对于它们输入的值都是确定性的，我们的分布式实现产生的输出值就如同将整个程序分成一个不间断的串行执行过程一样。 为了实现这个性质，我们依赖于map和reduce任务输出结果的提交是原子的。每个处理中的任务都会将它的输出写入私有的临时文件中。一个reduce任务产生一个这样的文件，而一个map任务则产生R个这样的文件（每个reduce任务一个）。当map任务完成时，工作节点发送给主节点的消息中带有R个临时文件的名字。如果主节点收到了一个来自已完成节点的完成消息，它就会忽略这个消息。否则，主节点会将R个文件的名字记录在相应的数据结构中。 当reduce任务完成时，工作节点会执行原子性的更名操作，将临时输出文件更名为最终输出文件。如果相同的reduce任务在多个机器上执行，就会有多个更名调用应用在相同的最终输出文件上。我们依赖于由底层文件系统提供的原子更名操作，才能保证最终的文件系统中只包含由其中一个reduce执行产生的数据。 我们的绝大多数map和reduce操作都是确定性的，这种情况下我们的语义和一个串行执行过程是等同的，这也使程序员很容易推出他们程序的行为。当map和reduce操作有不确定性时，我们提供较弱但仍然合理的语义。当存在不确定的操作时，某个reduce任务R1的输出等价于一个不确定程序的串行执行输出。但某个reduce任务R2的输出可能符合这个不确定程序的另一个串行执行输出。 考虑map任务M和reduce任务R1、R2。令e(Ri)为Ri的已提交的执行结果（只执行一次）。此时弱语义生效，因为e(R1)可能读取了M的一次输出，而e(R2)则可能读取了M的另一次输出。 局部性在计算环境中，网络带宽是一种比较稀缺的资源。我们利用下面的事实来节省带宽：输入数据（由GFS管理）就存储在组成集群的机器的本地磁盘上。GFS将每个文件分成64MB大小的区块，每块复制若干份（通常为3份）存储到不同的机器上。MapReduce主节点会把输入文件的位置信息考虑进去，并尝试将map任务分配到保存有相应输入数据的机器上。如果失败的话，它会试图将map任务调度到临近这些数据的机器上（同一网关的工作节点）。这样，大多数输入数据都是本地读取，并不消耗网络带宽。 任务粒度将map阶段分成M份，将reduce阶段分成R份。理想情况下，M和R应该比工作节点机器的数量大很多。每个工作节点处理很多不同的任务，可以增强动态负责均衡能力，也能加速有工作节点失败时的恢复情况：失败节点已经完成的map任务有很多的时候也能传递给其它所有工作节点来完成。 R通常由用户指定，因为每个reduce任务都会产生一个独立的输出文件。倾向于这样选择M：即可以将每个单独的任务分成16-64MB大的输入数据（此时上面所说的局部性优化效果最好），同时令R为待使用的工作节点数量较小的整数倍。","categories":[{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/categories/Distribution/"}],"tags":[{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/tags/Distribution/"}]},{"title":"Sparse Index","slug":"Storage/Sparse Index","date":"2024-04-07T16:13:04.000Z","updated":"2025-03-06T09:01:58.039Z","comments":true,"path":"2024/04/07/Storage/Sparse Index/","permalink":"http://example.com/2024/04/07/Storage/Sparse%20Index/","excerpt":"","text":"在数据主键有序的基础上，只为少部分数据建立索引，从而在查询时能够圈定出大致的范围，再在范围内利用适当的查找算法找到目标数据。 空间占用小，查询相对慢 Sparse Index in Kafka单个Kafka的TopicPartition中，消息数据会被切分成段（segment）来存储，扩展名为.log。log文件的切分时机由大小参数log.segment.bytes（默认值1G）和时间参数log.roll.hours（默认值7天）共同决定。数据目录中存储的部分文件如下。 12345678.├── 00000000000190089251.index├── 00000000000190089251.log├── 00000000000190089251.timeindex├── 00000000000191671269.index├── 00000000000191671269.log├── 00000000000191671269.timeindex...... log文件的文件名都是64位整形，表示这个log文件内存储的第一条消息的offset值减去1（也就是上一个log文件最后一条消息的offset值）。 每个log文件都会配备偏移量索引（index）和时间戳索引（timeindex）文件，且均为稀疏索引。由于索引文件不大，易于mmap，存取效率很高。 index 文件中存储的是offset值与对应数据在log文件中存储位置的映射 timeindex 文件中存储的是时间戳与对应数据offset值的映射 12345678910111213141516171819202122232425~ kafka-run-class kafka.tools.DumpLogSegments --files /data4/kafka/data/ods_analytics_access_log-3/00000000000197971543.indexDumping /data4/kafka/data/ods_analytics_access_log-3/00000000000197971543.indexoffset: 197971551 position: 5207offset: 197971558 position: 9927offset: 197971565 position: 14624offset: 197971572 position: 19338offset: 197971578 position: 23509offset: 197971585 position: 28392offset: 197971592 position: 33174offset: 197971599 position: 38036offset: 197971606 position: 42732......~ kafka-run-class kafka.tools.DumpLogSegments --files /data4/kafka/data/ods_analytics_access_log-3/00000000000197971543.timeindexDumping /data4/kafka/data/ods_analytics_access_log-3/00000000000197971543.timeindextimestamp: 1593230317565 offset: 197971551timestamp: 1593230317642 offset: 197971558timestamp: 1593230317979 offset: 197971564timestamp: 1593230318346 offset: 197971572timestamp: 1593230318558 offset: 197971578timestamp: 1593230318579 offset: 197971582timestamp: 1593230318765 offset: 197971592timestamp: 1593230319117 offset: 197971599timestamp: 1593230319442 offset: 197971606...... 以index文件为例，查找 offset&#x3D;197971577 的消息流程是： 通过二分查找，在index文件序列中，找到包含该offset的文件（00000000000197971543.index） 通过二分查找，在上一步定位到的index文件中，找到该offset所在区间的起点（197971592） 从上一步的起点开始顺序查找，直到找到目标offset。","categories":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/categories/Storage/"}],"tags":[]},{"title":"进程线程与中断","slug":"OS/进程与中断","date":"2023-08-15T02:09:04.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2023/08/15/OS/进程与中断/","permalink":"http://example.com/2023/08/15/OS/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E4%B8%AD%E6%96%AD/","excerpt":"","text":"进程与线程的区别老八股版本 一个线程属于一个进程，一个进程包含多个线程 进程是资源分配的基本单位 有独立的地址空间，拥有CPU资源、内存资源、文件资源等 线程是CPU调度的基本单位 私有（线程上下文）：线程栈（但能通过指针被另一个线程修改），寄存器，程序计数器 共享：进程地址空间中除线程上下文之外的所有内容：堆、全局变量、静态变量、代码段、文件等公共资源 数据共享：进程有独立的地址空间，数据隔离，共享复杂，需要IPC；线程共享进程数据 上下文切换：进程切换需要刷新TLB（对于不同进程，相同虚拟地址会映射不同物理地址产生歧义）并获取新的地址空间、然后切换硬件上下文和内核栈；线程切换时只需要切换硬件上下文和内核栈 可靠性：多进程更可靠，一个进程崩溃后，在保护模式下不会对其他进程产生影响；但线程之间没有隔离性，一个线程崩溃时可能已经破坏了其他线程的内存，导致整个进程kill 通信方式：线程共享进程数据，线程通信主要用于线程同步，所以没有IPC数据交换的机制 内核中对线程的表示在 Linux 中，无论进程还是线程，都是抽象成了 task 任务，在源码里都是用 task_struct 结构来实现的。 对于线程来讲，所有的字段都是和进程一样的（本来就是一个结构体）。包括状态、pid、task 树关系、地址空间、文件系统信息、打开的文件信息等等字段，线程也都有。 在 Linux 中，每一个 task_struct 都需要被唯一的标识，它的 pid 就是唯一标识号，即每个进程&#x2F;线程的pid都不同。对于线程，还需通过 tgid 字段来表示其所归属的进程 ID。 线程创建过程 可见两者创建过程差不多，一样使用的是内核里的 do_fork 函数，最后走到 copy_process 来完整创建。copy_process 先是复制了一个新的 task_struct 出来，然后对 task_struct 中的各种核心对象进行拷贝处理，还申请了 pid 。 区别在于二者在调用 do_fork 时传入的 clone_flags 里的标记不一样： 创建进程时的 flag：仅有一个 SIGCHLD 创建线程时的 flag：包括 CLONE_VM、CLONE_FS、CLONE_FILES、CLONE_SIGNAL、CLONE_SETTLS、CLONE_PARENT_SETTID、CLONE_CHILD_CLEARTID、CLONE_SYSVSEM。 对于线程来讲，由于传入了flags，其地址空间 mm_struct、目录信息 fs_struct、打开文件列表 files_struct 都是和创建它的任务共享的，无需创建。 对于进程来讲，没传 flags，地址空间 mm_struct、挂载点 fs_struct、打开文件列表 files_struct 都要是独立拥有的，都需要去申请内存并初始化它们。 总结因为在内核中线程和进程都是用 task_struct 来表示，只不过线程和进程的区别是会和创建它的父进程共享打开文件列表、目录信息、虚拟地址空间等数据结构，会更轻量一些，所以在 Linux 下的线程也叫轻量级进程。 对于内核任务来说，无论有多少个任务，其使用地址空间都是同一个。所以一般都叫内核线程，而不是内核进程。 注意fork的父子进程间：共享：内存映射区（mmap）、文件描述符（文件偏移量共享）、信号处理方式不共享：进程ID、内存空间（写时复制） CPU核心、线程数概念CPU物理数1cat /proc/cpuinfo | grep &#x27;physical id&#x27; | sort | uniq | wc -l 物理CPU数量，普通电脑一般只有一个CPU插槽，也就是只有一个物理CPU CORE核心数(物理核心数)1cat /proc/cpuinfo | grep &#x27;core id&#x27; | sort | uniq | wc -l 一个物理CPU拥有的运算单元个数，每个运算单元有一套寄存器、L1、L2私有缓存。一个核心同一时刻只能运行一个线程，不论这个线程是哪个进程的。每隔一定时间就会切换线程，如果切换到其它进程的线程，会切换CR3（进程切换时，会将该进程页表的指针加载到CR3寄存器）。 THREAD线程数(逻辑核心数)1cat /proc/cpuinfo | grep &#x27;processor id&#x27; | sort | uniq | wc -l 英特尔的超线程技术，可以实现一个核心同时执行多个线程，即逻辑核心数的说法：8核16线程，一个核心能跑二个线程， CPU在执行一条机器指令时，并不会完全地利用所有的CPU资源，是有大量资源被闲置着的。超线程技术允许两个线程同时不冲突地使用CPU中的资源。比如一条整数运算指令只会用到整数运算单元，此时浮点运算单元就空闲了，若使用了超线程技术，且另一个线程刚好此时要执行一个浮点运算指令，CPU就允许属于两个不同线程的整数运算指令和浮点运算指令同时执行，这是真的并行。 超线程”可能”是并行的,也可能不是并行的，但这也并不意味着两个线程在同一个CPU(也就是同一个核心)中一直都可以并行执行，只是恰好碰到两个线程当前要执行的指令不使用相同的CPU资源时才可以真正地并行执行。 进程的多个线程能多核并行吗内核态线程 优点：一个进程的多个线程可以分配到多个CORE核心同时执行，并且由于内核级线程只有很小的数据结构和堆栈，切换速度快，本身也可以用多线程技术实现提高系统的运行速率。 缺点：线程在用户态的运行，而线程的调度和管理在内核实现，在控制权从一个线程传送到另一个线程需要用户态到内核态再到用户态的模式切换，比较占用系统资源。 用户态线程 优点：线程的调度不需要内核直接参与，控制简单，可以在不支持线程的操作系统中实现 缺点：没有办法使用多核心并行执行","categories":[{"name":"OS","slug":"OS","permalink":"http://example.com/categories/OS/"}],"tags":[{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"}]},{"title":"Zookeeper","slug":"Distribution/Zookeeper","date":"2023-07-26T01:39:04.000Z","updated":"2025-03-06T09:01:58.037Z","comments":true,"path":"2023/07/26/Distribution/Zookeeper/","permalink":"http://example.com/2023/07/26/Distribution/Zookeeper/","excerpt":"","text":"ZooKeeper 由 Yahoo 开发，后来捐赠给了 Apache ，现已成为 Apache 顶级项目。ZooKeeper 是一个开源的分布式应用程序协调服务器，其为分布式系统提供一致性服务。其一致性是通过基于 Paxos 算法的 ZAB 协议完成的。其主要功能包括：配置维护、分布式同步、集群管理、分布式事务等。 ZABZookeeper 架构作为一个优秀高效且可靠的分布式协调框架，ZooKeeper 在解决分布式数据一致性问题时并没有直接使用 Paxos ，而是专门定制了一致性协议叫做 ZAB(ZooKeeper Automic Broadcast) 原子广播协议，该协议能够很好地支持 崩溃恢复 。 ZAB 中的三个角色 Leader ：集群中 唯一的写请求处理者 ，能够发起投票（投票也是为了进行写请求）。 Follower：能够接收客户端的请求，如果是读请求则可以自己处理，如果是写请求则要转发给 Leader 。在选举过程中会参与投票，有选举权和被选举权 。 Observer ：就是没有选举权和被选举权的 Follower 。 在 ZAB 协议中对 zkServer(即上面我们说的三个角色的总称) 还有两种模式的定义，分别是 消息广播 和 崩溃恢复 。 消息广播模式说白了就是 ZAB 协议是如何处理写请求的，只有 Leader 能处理写请求，那么 Follower 和 Observer 也需要同步更新数据，即在整个集群中保持数据的一致性 第一步需要 Leader 将写请求 广播 出去，问 Followers 是否同意更新，如果超过半数以上的同意那么就进行 Follower 和 Observer 的更新（和 Paxos 一样） 两个 Queue 的作用是 ZAB 需要让 Follower 和 Observer 保证顺序性 。何为顺序性，比如我现在有一个写请求A，此时 Leader 将请求A广播出去，因为只需要半数同意就行，所以可能这个时候有一个 Follower F1因为网络原因没有收到，而 Leader 又广播了一个请求B，因为网络原因，F1竟然先收到了请求B然后才收到了请求A，这个时候请求处理的顺序不同就会导致数据的不同，从而 产生数据不一致问题 。 所以在 Leader 这端，它为每个其他的 zkServer 准备了一个 队列 ，采用先进先出的方式发送消息。由于协议是 **通过 TCP **来进行网络通信的，保证了消息的发送顺序性，接受顺序性也得到了保证。 除此之外，在 ZAB 中还定义了一个 全局单调递增的事务ID ZXID ，它是一个64位long型，其中高32位表示 epoch 年代（对应leader），低32位表示事务id。定义这个的原因也是为了顺序性，每个 proposal 在 Leader 中生成后需要 通过其 ZXID 来进行排序 ，才能得到处理。 崩溃恢复模式首先要提到 ZAB 中的 Leader 选举算法，可以分为两个不同的阶段： Zookeeper 启动时如何初始化选举 假设我们集群中有3台机器，那也就意味着我们需要两台以上同意（超过半数）。比如这个时候我们启动了 server1 ，它会首先 投票给自己 ，投票内容为服务器的 myid 和 ZXID ，因为初始化所以 ZXID 都为0，此时 server1 发出的投票为 (1,0)。但此时 server1 的投票仅为1，所以不能作为 Leader ，此时还在选举阶段所以整个集群处于 Looking 状态。 接着 server2 启动了，它首先也会将投票选给自己(2,0)，并将投票信息广播出去（server1也会，只是它那时没有其他的服务器了），server1 在收到 server2 的投票信息后会将投票信息与自己的作比较。首先它会比较 ZXID ，ZXID 大的优先为 Leader，如果相同则比较 myid，myid 大的优先作为 Leader。所以此时server1 发现 server2 更适合做 Leader，它就会将自己的投票信息更改为(2,0)然后再广播出去，之后server2 收到之后发现和自己的一样无需做更改，并且自己的 投票已经超过半数 ，则 确定 server2 为 Leader，server1 也会将自己服务器设置为 Following 变为 Follower。整个服务器就从 Looking 变为了正常状态。 当 server3 启动发现集群没有处于 Looking 状态时，它会直接以 Follower 的身份加入集群。 Leader宕机时如何重新选举 假设 Leader (server2) 宕机，首先剩下的两个 Follower 的状态 从 Following 变为 Looking 状态 ，然后每个 server 会向初始化投票一样首先给自己投票（这不过这里的 zxid 可能不是0了）。 假设 server1 给自己投票为(1,99)，然后广播给其他 server，server3 首先也会给自己投票(3,95)，然后也广播给其他 server。server1 和 server3 此时会收到彼此的投票信息，和一开始选举一样，他们也会比较自己的投票和收到的投票（zxid 大的优先，如果相同那么就 myid 大的优先）。这个时候 server1 收到了 server3 的投票发现没自己的合适故不变，server3 收到 server1 的投票结果后发现比自己的合适于是更改投票为(1,99)然后广播出去，最后 server1 收到了发现自己的投票已经超过半数就把自己设为 Leader，server3 也随之变为 Follower。 崩溃恢复 就是 当集群中有机器挂了，整个集群如何保证数据一致性 如果只是 Follower 挂了，而且挂的没超过半数的时候，因为在 Leader 中会维护队列，所以不用担心后面的数据没接收到导致数据不一致性。 如果 Leader 挂了需要先暂停服务变为 Looking 状态然后进行 Leader 的重新选举，要分为两种情况了： 确保已经被Leader提交的提案最终能够被所有的Follower提交 假设 Leader (server2) 发送 commit 请求，他发送给了 server3，然后要发给 server1 的时候突然挂了。这个时候重新选举的时候我们如果把 server1 作为 Leader 的话，那么肯定会产生数据不一致性，因为 server3 肯定会提交刚刚 server2 发送的 commit 请求的提案，而 server1 根本没收到所以会丢弃。 但实际这时 server1 已经不可能成为 Leader 了，因为进行投票选举的时候会比较 ZXID ，而此时 server3 的 ZXID 肯定比 server1 的大。 跳过那些已经被丢弃的提案 假设 Leader (server2) 此时同意了提案N1，自身提交了这个事务并且要发送给所有 Follower 要 commit 的请求，却在这个时候挂了，此时肯定要重新进行 Leader 的选举，比如说此时选 server1 为 Leader （这无所谓）。但是过了一会，这个 挂掉的 Leader 又重新恢复了 ，此时它肯定会作为 Follower 的身份进入集群中，需要注意的是刚刚 server2 已经同意提交了提案N1，但其他 server 并没有收到它的 commit 信息，所以其他 server 不可能再提交这个提案N1了，这样就会出现数据不一致性问题了，所以 该提案N1最终需要被抛弃掉 。 Zookeeper的几个理论知识数据模型zookeeper 数据存储结构与标准的 Unix 文件系统非常相似，都是在根节点下挂很多子节点(树型)。但是 zookeeper 中没有文件系统中目录与文件的概念，而是 使用了 znode 作为数据节点 。znode 是 zookeeper 中的最小数据单元，每个 znode 上都可以保存数据，同时还可以挂载子节点，形成一个树形化命名空间。 每个 znode 都有自己所属的 节点类型 和 节点状态。 其中节点类型可以分为 持久节点、持久顺序节点、临时节点 和 临时顺序节点。 持久节点：一旦创建就一直存在，直到将其删除。 持久顺序节点：一个父节点可以为其子节点 维护一个创建的先后顺序 ，这个顺序体现在 节点名称 上，是节点名称后自动添加一个由 10 位数字组成的数字串，从 0 开始计数。 临时节点：临时节点的生命周期是与 客户端会话 绑定的，会话消失则节点消失 。临时节点 只能做叶子节点 ，不能创建子节点。 临时顺序节点：父节点可以创建一个维持了顺序的临时节点(和前面的持久顺序性节点一样)。 节点状态中包含了很多节点的属性，在 zookeeper 中是使用 Stat 这个类来维护的。 czxid：Created ZXID，该数据节点被 创建 时的事务ID。 mzxid：Modified ZXID，节点 最后一次被更新时 的事务ID。 ctime：Created Time，该节点被创建的时间。 mtime： Modified Time，该节点最后一次被修改的时间。 version：节点的版本号。 cversion：子节点 的版本号。 aversion：节点的 ACL 版本号。 ephemeralOwner：创建该节点的会话的 sessionID ，如果该节点为持久节点，该值为0。 dataLength：节点数据内容的长度。 numChildre：该节点的子节点个数，如果为临时节点为0。 pzxid：该节点子节点列表最后一次被修改时的事务ID，注意是子节点的 列表 ，不是内容。 会话客户端和服务端是通过 TCP 长连接 维持的会话机制，其实对于会话来说可以理解为 保持连接状态 。 在 zookeeper 中，会话还有对应的事件，比如CONNECTION_LOSS 连接丢失事件、SESSION_MOVED 会话转移事件、SESSION_EXPIRED 会话超时失效事件。 ACLACL 为 Access Control Lists ，它是一种权限控制。在 zookeeper 中定义了5种权限，它们分别为： CREATE ：创建子节点的权限。 READ：获取节点数据和子节点列表的权限。 WRITE：更新节点数据的权限。 DELETE：删除子节点的权限。 ADMIN：设置节点 ACL 的权限。 Watcher机制Watcher 为事件监听器，是 zk 非常重要的一个特性，很多功能都依赖于它，它有点类似于订阅的方式，即客户端向服务端 注册 指定的 watcher ，当服务端符合了 watcher 的某些事件或要求则会 向客户端发送事件通知 ，客户端收到通知后找到自己定义的 Watcher 然后 执行相应的回调方法 。 Zookeeper的几个典型应用场景选主因为 Zookeeper 的强一致性，能够很好地在保证 在高并发的情况下保证节点创建的全局唯一性 (即无法重复创建同样的节点)。利用这个特性，我们可以 让多个客户端创建一个指定的节点 ，创建成功的就是 master。 可以 让其他不是 master 的节点监听节点的状态 ，比如监听临时节点的父节点，如果子节点个数变了就代表 master 挂了，这个时候 触发回调函数进行重新选举；或者直接监听节点的状态，可以通过节点是否已经失去连接来判断 master 是否挂了等等。 总的来说，可以完全 利用临时节点、节点状态 和 watcher 来实现选主的功能，临时节点主要用来选举，节点状态和watcher 可以用来判断 master 的活性和进行重新选举。 分布式锁分布式锁的实现方式有很多种，比如 Redis 、数据库 、zookeeper 等。 使用 zookeeper 实现互斥锁 —— zk在高并发的情况下保证节点创建的全局唯一性 因为创建节点的唯一性，可以让多个客户端同时创建一个临时节点，创建成功的就说明获取到了锁 。 然后没有获取到锁的客户端也像上面选主的非主节点创建一个 watcher 进行节点状态的监听，如果这个互斥锁被释放了（获取锁的客户端宕机或主动释放了锁）可以调用回调函数重新获得锁。 不需要向 redis 那样考虑锁得不到释放的问题了，因为当客户端挂了，节点也挂了，锁也释放了。 使用 zookeeper 同时实现 共享锁和独占锁 —— 采用有序节点 若为读请求（获取共享锁），若 没有比自己更小的节点，或比自己小的节点都是读请求 ，则可以获取到读锁。若比自己小的节点中有写请求 ，则当前客户端无法获取到读锁，只能等待前面的写请求完成。 若为写请求（获取独占锁），若 没有比自己更小的节点 ，则表示客户端可以直接获取到写锁。若发现 有比自己更小的节点，无论是读操作还是写操作，当前客户端都无法获取到写锁 ，等待所有前面的操作完成。 优化：当一个锁得到释放它会通知所有等待的客户端从而造成 羊群效应 。此时可以通过让等待的节点只监听他们前面的节点 —— 让读请求监听比自己小的最后一个写请求节点，写请求只监听比自己小的最后一个节点 。 集群管理如果需要了解整个集群中有多少机器在工作，对每台机器的运行时状态进行数据采集，对集群中机器进行上下线操作等时， zookeeper 的 watcher 和 临时节点能很好的实现这些需求。 可以为每条机器创建临时节点，并监控其父节点，如果子节点列表有变动（我们可能创建删除了临时节点），那么我们可以使用在其父节点绑定的 watcher 进行状态监控和回调。 注册中心同样也是让 服务提供者 在 zookeeper 中创建一个临时节点并且将自己的 ip、port、调用方式 写入节点，当 服务消费者 需要进行调用的时候会 通过注册中心找到相应的服务的地址列表(IP端口什么的) ，并缓存到本地(方便以后调用)，当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从地址列表中取一个服务提供者的服务器调用服务。 当服务提供者的某台服务器宕机或下线时，相应的地址会从服务提供者地址列表中移除。同时，注册中心会将新的服务地址列表发送给服务消费者的机器并缓存在消费者本机。","categories":[{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/categories/Distribution/"}],"tags":[{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/tags/Distribution/"}]},{"title":"Staged","slug":"Software/Design","date":"2023-07-03T23:54:04.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2023/07/03/Software/Design/","permalink":"http://example.com/2023/07/03/Software/Design/","excerpt":"","text":"未完成页面FetchPage()NumNodes()MemoryBytes() Stop Kill Pause -&gt; Resume Send deliver, dispatch, announce, distribute, route find search, extract, locate, recover start launch, create, begin, open make create, setUp, build, generate, compose, add, new first&#x2F;last, min&#x2F;max 表示包含范围begin&#x2F;end，表示排除 is, has, can, should 表示bool","categories":[{"name":"Software","slug":"Software","permalink":"http://example.com/categories/Software/"}],"tags":[]},{"title":"Git","slug":"Software/Git","date":"2023-07-03T23:54:04.000Z","updated":"2025-03-06T09:01:58.039Z","comments":true,"path":"2023/07/03/Software/Git/","permalink":"http://example.com/2023/07/03/Software/Git/","excerpt":"","text":"基本操作 创建分支 git checkout -b name 创建并转到分支 git checkout -b dev_1 origin/dev_1 拉取远程分支创建本地 删除分支 git branch -d name 删除本地分支 git push origin --delete name 删除远程分支 git remote prune 远程分支删除后，本地分支同步 关联远端分支 git branch -u origin/dev_mz 关联远程分支 git branch -vv 查看本地分支与远端分支关联关系 提交到远端 git push -u origin dev_mz 推送dev_mz分支到远端并创建关联 查看状态 git status -s 查看当前修改、提交状态 git diff &lt;file&gt; 比较工作区和暂存区 git diff HEAD -- &lt;file&gt; 比较工作区和版本库的最新版本 git log -stat显示commit历史及变更文件 合并提交 git rebase -i HEAD~N 把最新的N个提交压缩成1个，保留的commit默认pick，丢弃的commit标记fixup 合并分支 &amp; 解决冲突 git rebase master 然后按编辑器指示解决冲突 git add . 将解决完冲突的文件暂存 git rebase --continue 继续rebase，保存commit git push -f 本地rebase完后，由于合并了master几个提交，无法fast-forward，如果该分支仅自己开发，强行push即可 fast-forward的前提是本地只比远程多了几个最新提交，需要之前的提交记录相同，而rebase后违反了这一点 工作区原理Git里有三个区域很重要，下图解释了这三个区域的状态的变化过程： HEAD 指向最近一次commit里的所有snapshot Index 缓存区域，只有Index区域里的东西才可以被commit Working Directory 用户操作区域 初始状态当 git checkout 的时候，git做了三件事情： 将 HEAD 指向那个分支的最后一次 commit 将 HEAD 指向的 commit 里所有文件的 snapshot 替换掉 Index 区域里原来的内容 将 Index 区域里的内容填充到 Working Directory 里 此时 HEAD、Index、Working Directory 里的内容都是一样的。Index中的内容不是空的，并非只有 git add 后才会有东西。 Changed如果你在 Working Directory 里修改了文件，则 Working Directory 里的内容和 Index 区域里不一致了。 这个时候git status的结果是：Changes not staged for commit Staged一个文件仅仅 changed 是不能被 commit 的，Git 要求只能提交 Index 里的东西。 所以需要 git add。这个命令的意思是，把 Changed 的文件的内容同步到 Index 区域里。这样 Working Directory 和 Index 区域的内容就一致了。这个过程被称之为 stage 这个时候git status的结果是：Changes to be committed Committed最后通过 git commit 提交后，HEAD 的状态和 Index 以及 Working Directory 就形成一致了。 撤销操作区别 reset 和 revert git reset 是会修改版本历史的，即丢弃掉一些版本历史。 git revert 是根据那个commit逆向生成一个新的commit，版本历史是不会被破坏的。 reset1. 用于file1git reset HEAD &lt;file&gt; 撤销add操作，把文件从index退回workspace，并将更改保存在workspace中 2. 用于commit123git reset HEAD^^ #回退到上上个版本git reset HEAD~2git reset d130664a3e6da2d2478f3c6eee8e9dc67a61b1c2 撤销commit操作，必须是未被提交到remote的改动。除了移动当前分支的HEAD，还可以更改workspace和index： --soft：修改HEAD，不修改index和workspace --mixed：修改HEAD和index，不修改workspace，默认 --hard：修改HEAD、index、workspace 已经push到远程仓库的commit不允许reset，只能用revert。如果commit已经被push到远程仓库上了，也就意味着其他开发人员就可能基于这个commit形成了新的commit，这时你去reset，就会造成其他开发人员的提交历史莫名其妙的丢失，或者其他灾难性的后果。 checkout1. 用于file1git checkout HEAD &lt;file&gt; 清除文件在workspace的修改，类似于 git restore file 2. 用于commit12git checkout b4f2fa40955cc34f441466f820b1b84350a31491 # 分离HEAD模式，HEAD可以不指向main等git checkout main 只是移动HEAD到不同的commit，如果有unstaged的文件，git会阻止操作并提示。 checkout会修改HEAD的指向，变更Index区域里的内容，修改Working Directory里的内容。 这看上去很像 reset --hard，但和 reset --hard 相比有两个重要的差别 reset会把working directory里的所有内容都更新掉 checkout不会去修改你在Working Directory里修改过的文件 reset把branch移动到HEAD指向的地方 checkout则把HEAD移动到另一个分支 对于第二个区别：假设两个分支master和develop 指向不一样的commit，现在在develop分支上（HEAD指向） 如果 git reset master，那么develop就会指向master所指向的那个commit。 如果 git checkout master，那么develop不会动，只有HEAD会移动指向master。 revert1git revert HEAD #revert该版本的修改，相当于 git reset HEAD^ 通过新建一个commit来撤销一次commit所做的修改，是一种安全的方式，并没有修改commit history。 密钥与Config配置SSH key 创建密钥 ssh-keygen -t ed25519 查看密钥 cat ~/.ssh/xxx 添加密钥 Settings -&gt; SSH and GPG keys -&gt; New SSH key 确定一下ssh-key是否添加成功 ssh -T git@github.com Config全局&#x2F;仓库配置(–global&#x2F;local) 12345678910git config --global -lgit config --global core.editor vimgit config --global init.defaultBranch maingit config --global --add pull.rebase truegit config --global user.name &quot;YOURUSERNAME&quot;git config --global user.email &quot;YOUREMAIL&quot;git config --global http.proxy http://127.0.0.1:xxxxgit config --global https.proxy http://127.0.0.1:xxxx# 取消配置git config --global --unset http.proxy 配置别名，在 .gitconfig 中加入 12[alias] lg = log --color --graph --pretty=format:&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#x27; --abbrev-commit 重新关联远程仓库 查看远程仓库的链接方式，将http方式改成git方式 git remote show origin 移除现有的http方式的远程仓库 git remote rm origin 重新添加成git@github.com的方式并关联 12git remote add origin git@github.com:Yveltals/test.gitgit push -u origin main HTTPS Auth failed123remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://*****-token-authentication-requirements-for-git-operations/ for more information.fatal: Authentication failed for &#x27;https://***/&#x27; Github 对密码认证的支持于 2021年8月13 日被删除，需要使用个人访问令牌代替。 Username: 注册 Github 的邮箱 Password: github.com&#x2F;settings&#x2F;tokens 页面的 Personal access tokens 在线演示 https://learngitbranching.js.org/?locale=zh_CN","categories":[{"name":"Software","slug":"Software","permalink":"http://example.com/categories/Software/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]},{"title":"SVN","slug":"Software/SVN","date":"2023-06-07T17:39:04.000Z","updated":"2025-03-06T09:01:58.039Z","comments":true,"path":"2023/06/07/Software/SVN/","permalink":"http://example.com/2023/06/07/Software/SVN/","excerpt":"","text":"配合Phabricator工作流12345## 保存修改svn add,delete## code reviewarc diffarc commit 代码检出 checkout把 SVN 服务器上的代码下载到电脑上，checkout 也可以简写为 co 12345svn checkout svn://svnbucket.com/xxx/xxx## 指定存储目录svn checkout svn://svnbucket.com/xxx/xxx save-dir## 指定用户名密码svn checkout svn://svnbucket.com/xxx/xxx --username xxxx --password xxx 提交代码 commitcommit 可以简写为 ci，-m 参数后面跟的是本次提交的描述内容 123456## 描述是必须的，但是可以填写空字符串，不指定svn commit -m &quot;提交描述&quot;## 只提交指定文件或目录svn commit /path/to/file-or-dir -m &quot;提交指定文件&quot;## 指定后缀的所有文件svn commit *.js -m &quot;提交所有 js 文件&quot; 更新代码 updateupdate 也可以简写为 up 123456## 更新到最新svn update## 更新到指定版本的代码。特别是最新版本代码有问题时，我们可以用这个命令回到之前的版本svn update -r xxx ## 仅更新指定文件或者目录svn up /path/to/file-or-dir 添加文件 add1234## 添加指定文件或目录svn add /path/to/file-or-dir## 添加当前目录下所有 php 文件svn add *.php 删除文件 delete此命令会从 SVN 移除版本控制，移除后需要提交一下 123svn delete /path/to/file-or-dir## 删除版本控制，但是本地依旧保留文件svn delete /path/to/file-or-dir --keep-local 查看日志 log12345678## 查看当前目录的日志svn log## 查看指定文件或目录的提交日志svn log /path/to/file-or-dir## 查看日志，并且输出变动的文件列表svn log -v## 限定只输出最新的 5 条日志svn log -l 5 查看变动 diff12345678## 查看当前工作区的改动svn diff## 查看指定文件或目录的改动svn diff /path/to/file-or-dir## 本地文件跟指定版本号比较差异svn diff /path/to/file-or-dir -r xxx## 指定版本号比较差异svn diff /path/to/file-or-dir -r 1:2 撤销修改 revert1234## 撤销文件的本地修改svn revert test.php## 递归撤销目录中的本地修改svn revert -R /path/to/dir 添加忽略 ignoreSVN 的忽略是通过设置目录的属性 prop 来实现的，添加后会有一个目录属性变动的修改需要提交 123456789101112## 忽略所有 log 文件。点号表示在当前目录设置忽略属性svn propset svn:ignore &quot;*.log&quot; .## 递归忽略 global-ignoressvn propset svn:global-ignores &quot;*.log&quot; .## 从文件读取忽略规则，一行一个规则svn propset svn:ignore -F filename.txt .## 打开编辑器修改忽略属性svn propedit svn:ignore .## 查看当前目录的属性配置svn proplist . -v## 删除当前目录的忽略设置svn propdel svn:ignore . 忽略仅对还未添加到版本库的文件生效，已经在版本库里的文件，添加忽略后是不会自动删除的也不会忽略，需要手动 delete 命令删除下才行。 查看状态 status任何时候，你可以用下面的命令查看当前工作目录的 SVN 状态喔，会列出来哪些文件有变动。 12svn statussvn status /path/to/file-or-dir 清理 cleanupSVN 出现报错时可以执行一下，会清理掉本地的一些缓存 1svn cleanup 查看信息 info1svn info 查看文件列表 ls123svn ls ## 指定版本号svn ls -r 100 查看文件内容12## 查看指定版本的文件内容，不加版本号就是查看最新版本的svn cat test.py -r 2 查看 blame1svn blame filename.php 地址重定向如果你的 SVN 地址变了，不需要重新 checkout 代码，只需要这样重定向一下就可以了 1svn switch --relocate 原 SVN 地址 新 SVN 地址 分支操作1234567891011## 创建分支，从主干 trunk 创建一个分支保存到 branches/online1.0svn cp -m &quot;描述内容&quot; http://svnbucket.com/repos/trunk http://svnbucket.com/repos/branches/online1.0## 合并主干上的最新代码到分支上cd branches/online1.0svn merge http://svnbucket.com/repos/trunk ## 分支合并到主干svn merge --reintegrate http://svnbucket.com/repos/branches/online1.0## 切换分支svn switch svn://svnbucket.com/test/branches/online1.0## 删除分支svn rm http://svnbucket.com/repos/branches/online1.0","categories":[{"name":"Software","slug":"Software","permalink":"http://example.com/categories/Software/"}],"tags":[]},{"title":"日常实习面经","slug":"Archive/日常实习面经","date":"2023-05-09T22:17:00.000Z","updated":"2025-03-06T09:01:58.041Z","comments":true,"path":"2023/05/09/Archive/日常实习面经/","permalink":"http://example.com/2023/05/09/Archive/%E6%97%A5%E5%B8%B8%E5%AE%9E%E4%B9%A0%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"TIMELINE3月11日开始投简历，接连投了四五个音视频岗秒挂，百度挂、字节三投三挂、牛客投网易被嫌弃webserver烂大街，故一边继续背八股、音视频，一边开始突击CMU15445。开始考虑放弃学了三个月的音视频方向 3月底投了最后一个字节的音视频岗，秒挂，转而投了快手基架、字节后端。彻底放弃音视频，只要是个C++沾边的岗就投 4月初接到了快手一面和字节一面（后端挂了被转到了基架岗），于是又接着投了华为云计算、腾讯后台开发（TEG基架）。有种C++投后端都被 Java干掉了的感觉，所以之后只投基架&#x2F;偏嵌入式方向 4月中旬因快手字节面试情况不容乐观，官网投了小米自动驾驶，BOSS上投了蔚来和百度（至今未读），几天后毫无进展，又在官网投了360、字节、百度 4月底意料之外，一周内小米、快手先后OC，总算从字节被挂又被捞、循环往复的主线里解脱了出来，没时间拖着面后边的了，实际也心累了，接了快手offer 5月初腾讯、字节、华为约面，腾讯是微信搜索部门大概率KPI，华为面试不刷人至少泡到六月，所以全拒了没面 反思的结论就是：3月初神仙打架，简历不完善，项目不充分，而且投递的岗位不对路，天真的以为简历里一句“熟悉音视频“就匹配岗位了，所以在个位数HC和满配项目&#x2F;实习的大佬面前像个小丑。一个月前有个面试邮件都会小激动，如今只想赶紧做个了结，耗不动了 时间久远，很多面试细节已经记不清了，不知道实习之后再看是什么感想 快手一面 80minWebserver：QPS、Epoll八股、如何区分多个客户端并发的请求 CMU15445：高位可扩展哈希（这个没组织好语言，解释了好久）、B+树索引的优点 算法：手写堆，包括数组初始化、push()、pop()、empty() 发挥较好，因HR离职导致招聘流程停滞了两周，15天后约二面，一度以为挂了 二面 50minCMU15445：介绍这个项目、高位可扩展哈希、闭散列和开散列（后来才知道就是开放地址法和拉链法）、乐观锁并发优化、如何不加锁实现读写并发 CPP：虚函数表、好多忘了 算法：没见过的题，上来看见O(n)复杂度宕机了，后来发现就是回溯实际就是O(n)。但面试官要求优化常系数，经提醒得出了拓扑+回溯的思路，硬着头皮写出来了，中途两次想放弃 算法发挥的一般，但毕竟题难凑合写出来了，15min后约HR面 HR面 10min介绍项目中自己负责的部分、成果和收获，遇到的最大困难、如何解决 三个词形容自己，对于第三个词举个例子证明 到岗时间和实时时长 三个小时后OC 总结问八股比较少，主要针对项目问的比较细、但不刁钻，大部分时候是在解释项目，压力不大 小米一面 50minCS144：介绍这个项目、如何实现和真实网络通信、还有一些计网八股，基本都会就没啥印象了 CPP：关于数据类型表示的范围、size_t范围、可移植性、如何表示一个非常大的数等等，这方面没了解过，所以一头雾水，面试官耐心的引导+讲解了一番 算法：链表版两数相加秒了，面试官很满意 最后还有一些时间，面试官看我不了解小米造车，就很的详细的介绍了部门的具体工作 发挥较好，第二天上午约二面 二面 50min无项目，全八股 操作系统：虚拟内存、指令乱序、内存屏障、一个线程写完变量，另一个线程能立即读到吗、volatile具体从哪级内存中读 CPP：编程时候如何解决死锁、死锁的条件、破坏循环等待条件怎样实现、介绍智能指针、malloc原理、mutex实现原理、map和unordered_map区别 算法：LRU cache、判断链表是否有环（追问快慢指针是否可能判断不出来，这个答错了。实际当慢指针步数1、快指针步数为圈长+1时，两者永远不会相遇） 发挥不太好，但第三天直接HR电话面 HR面 4min电话简单沟通入职时间和实习时长 总结TCP&#x2F;IP协议栈项目和部门工作匹配度高，算法稳定发挥，所以虽然八股答错的不算少，但也很快OC了 字节一面 65minCMU15445：LRU-K算法、SQL执行器优化 CS144：缓冲区结构优化 Webserver：异步日志、Epoll、为什么用多个线程处理任务，而redis却是单线程 CPP：static、vector、多线程并发写的安全问题、构造和析构函数可以抛异常吗 算法：写LRU-K伪代码，项目场景太复杂，结构体都写了好久，最后没写完讲了讲思路 发挥较好，10min后约二面 二面 60min算法： 第一题是很抽象的一个场景题，搞清楚题意就10min，也没想到好算法，随便说了说思路 第二题合并K个有序链表，很快写完了，但飞书环境编译就各种报错，最后全注释掉只cout都没输出，硬生生拖到了45min，最后看实在不行就把代码讲了一遍 CMU15445：解释下SQL执行器、火山模型、调用的三方库了解吗、自己实现有什么思路、了解哪些SQL语法 Webserver：解释基于最小堆的定时器、epoll_wait有什么优点、定时器有什么问题&#x2F;什么时候不准 发挥不好，算法拖太久八股都来不及问，第二天HR告知加一轮技术面再看看 三面 60minMysql：binlog、如何保存某一时段的日志、sql注入攻击、写一个例子、了解orm吗 CPP：C++内存分区、auto和使用场景、迭代器的使用、遇到过什么bug 计网：TCP可不可以两次握手、两次握手有什么问题、TCP和HTTP的keep-alive区别 算法： 接雨水进阶：高度为0时水可以漏下去，秒了 数组从任意处分为左右两部分，求两侧最大值的差最大多少，没想出一次遍历的方法，遍历了两次 发挥一般，“深度够，广度不足”，因为算法第二题没写出最优解，还是挂了 四天后被另一个部门捞了，不过太晚了就没面 总结字节很重视基础，各方面考察的很综合，但不至于很深很刁钻，算法题是底线，写不出来必挂","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[]},{"title":"CMU 15445","slug":"Archive/CMU 15445","date":"2023-04-26T15:36:04.000Z","updated":"2025-03-06T09:01:58.040Z","comments":true,"path":"2023/04/26/Archive/CMU 15445/","permalink":"http://example.com/2023/04/26/Archive/CMU%2015445/","excerpt":"","text":"内存缓冲池原理存储管理器中实现缓冲池。缓冲池负责将物理页面从磁盘中读入内存、或从内存中写回磁盘，使得DBMS可以支持大于内存大小的存储容量。页面读入缓冲池时，从free-list（空位页面）后lru_replacer中（未被访问的可替换页面）寻找空间，淘汰的dirty-page还需写回磁盘，page_table映射page到frame的关系 并行缓冲池的思想是分配多个独立的缓冲池，并将不同的页面ID映射至各自的缓冲池中，从而减少整体缓冲池的锁粒度，以增加并行性。负载均衡：采用轮转方法选取分配物理页面时使用的缓冲池，start_idx++ 为什么不用 OS 磁盘管理模块 OS 的磁盘管理模块没有 DBMS 中的领域知识，无法恰当地决定数据移动的时机和数量 将 dirty pages 按正确地顺序写到磁盘 定制化缓存置换策略 根据具体情况预获取数据 淘汰算法LRU-K：最近使用过1次 —&gt; 最近使用过K次，降低了“缓存污染”问题，命中率比LRU高 需要保存每个页面的访问次数、最近K次时间戳，用两个队列按顺序记录这些页面，优先淘汰访问次数不足K的 历史队列：访问小于k次的页面，按FIFO存放，每次访问将页面计数++，满k次放入缓存队列 缓存队列：访问满k次的页面，按照前第K次时间排序，用SET结构存放 LRU-K实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455struct cmp&#123; bool operator()(const pair&lt;int, int&gt;&amp; a,const pair&lt;int, int&gt;&amp; b) const&#123; return a.second &lt; b.second; &#125;&#125;;//历史队列list&lt;int&gt; hist;unordered_map&lt;int, list&lt;int&gt;::iterator&gt; hist_map;//缓存队列set&lt;pair&lt;int, int&gt;&gt; cache;unordered_map&lt;int, set&lt;pair&lt;int,int&gt;&gt;::iterator&gt; cache_map;//页面时间戳与访问次数unordered_map&lt;int, list&lt;int&gt;&gt; timestamp;unordered_map&lt;int, int&gt; count;void record(int id)&#123; count[id]++; timestamp[id].push_back(TIME++); int cnt = count[id]; if (cnt == 1) &#123; hist.push_back(id); hist_map[id] = --hist.end(); &#125; else if (cnt == 2) &#123; hist.erase(hist_map[id]); hist_map.erase(id); int k_time = timestamp[id].front(); auto it = cache.insert(&#123;id, k_time&#125;); cache_map[id] = it.first; &#125; else &#123; timestamp[id].erase(timestamp[id].begin()); cache.erase(cache_map[id]); int k_time = timestamp[id].front(); auto it = cache.insert(&#123;id, k_time&#125;); cache_map[id] = it.first; &#125;&#125;bool evict(int &amp;id) &#123; if (hist.empty() &amp;&amp; cache.empty()) return false; if (hist.size()) &#123; auto it = hist.begin(); id = *it; count.erase(id); timestamp.erase(id); hist.erase(it); hist_map.erase(id); &#125; else &#123; auto it = cache.begin();; id = it-&gt;first; count.erase(id); timestamp.erase(id); cache.erase(it); cache_map.erase(id); &#125; return true;&#125; 可扩展哈希原理通常的哈希表如Redis在负载因子高时，把HashTable大小翻倍，HashNode全部rehash一遍 可扩展哈希表是一种动态哈希表，其思想在于多个目录项对应一个桶，其特点为桶在充满或清空时可以桶为单位进行桶分裂或合并，并且仅需在特定情况下进行HashTable的扩展和收缩，以减小扩展和收缩操作对全表的影响 映射关系：key-&gt;index 的逻辑是hash(key) &amp; mask，即64位hash的低k位，hashTable大小为 $2^k$。 哈希表的扩展： 对于大小为 4 的 HashTable，第一次扩展时，必须把HashTable reserve 为8。此后的key hash映射因为mask了低 k+1 位，如果是 Bucket[0] 链表满了，那么rehash到 Bucket[0] 和 Bucket[4] 链表，但 Bucket[1~3] 因为不满就无需rehash，把指针赋值给 Bucket[5~7] 即可，即两个 Bucket_idx 对应相同的链表。 等下次 Bucket[1] 链表满需要扩展时，因为下标1和5共用这一个链表，只需要rehash成两个链表分别对应两个Bucket_idx即可，其他都不用动 如何区分以上两种情况： 全局深度：HashTable的大小，即mask位数，每次reserve时+1 局部深度：每次rehash链表时，对应Bucket的局部深度++。局部深度 &lt; 全局深度 时，仅需rehash对应链表节点。局部深度 = 全局深度时，需要先 reserve 再 rehash 对应链表。 桶的合并：满足两桶均空、局部深度相同时，合并桶后局部深度-1，合并后可能缩减全局深度 并发控制 Getvalue：哈希目录加读锁 Insert/Remove：Bucket一定会插入或分裂，但 HashTable 只有在桶满分裂时才修改，故采用乐观锁优化：默认 HashTable 只加读锁，Bucket 加写锁；只有桶满时，释放锁并调用另一分裂插入函数，一开始就获取两个写锁，还要注意判断桶是否仍满 踩坑在 Insert 中释放读锁和写锁到 SplitInsert 之间存在空隙，其他线程可能在该空隙中被调度，从而改变桶页面或目录页面数据。因此，在这里需要重新获取 key 对应的 Bucket（可能与Insert中判断已满的 Bucket 不相同），并检查对应的桶页面是否已满。如果仍是满的，则分配新 Bucket 并 rehash。 B+Tree 索引 TREE_PAGE: 保存在Page的data中，共4KB，包含size、max_size、parent_page_id、page_id TREE_INTERNAL_PAGE: kv数组 &lt;keyType, page_id&gt; TREE_LEAF_PAGE: next_page_id 与 kv数组 &lt;keyType, record_id&gt; 定义 参考链接 B+树分为内部结点和叶子结点，根结点既可以是内部结点，也可以是叶子结点，关键字个数最少1个 B+树内部结点不保存数据，只用于索引，所有数据都保存在叶结点中 m阶B+树内部结点最多有m-1个关键字、m个子树，叶子结点最多存储m-1个记录 内部结点中的key都按照从小到大的顺序排列，key左子树中的key都小于等于右子树中的key 叶子结点双向链表相连，自小而大有序 插入理论上B+树内部结点是由指针、关键字交替组成的，实现是一个键值对数组&lt;key, page_id&gt;。所以M阶的B+树内部结点最多存放M个键值对，第一个键值对键是空的，而叶子结点键值对个数为 M-1 如果是空树，创建一个叶节点作为根。更新root_page_id ，因为需要通过它访问B+树 从根节点向下查找到键值应该所在的叶节点，在每个内部节点找到最后一个小于等于插入值的键，得到下层结点的 Page_id，最终找到叶子结点并插入键值对。规定不支持重复键，否则直接返回 false。 如果叶节点插入后超过 M-1 要进行分裂，将原节点的一半内容拷贝到新节点，分裂点的键插入父节点，让父节点该键的值指向新的叶节点 如果父节点（内部节点）插入后超过了M，同样要递归进行分裂并向上插入，还要调整子节点的父指针指向新的内部节点。 如果上溢到了根节点，则要创建一个新的根节点，使得 B+ 树长高一层 删除下溢：内部结点 (M+1)&#x2F;2，叶结点 M&#x2F;2 从叶节点中删除键值，如果出现下溢就进行后续处理： 对于叶结点，如果兄弟节点键值对个数大于 M&#x2F;2，从兄弟节点借一个键值对（左侧兄弟就借尾，右侧兄弟就借头），把兄弟节点的键上移替换父节点中的键（保证左&lt;父&lt;右）；如果兄弟节点不够借出，将该节点与兄弟节点合并，同时删除父节点中对应的键值。 如果删除后父节点（内部节点）下溢出，仍然是借&amp;修改或合并&amp;删除两种方法处理，但规则与叶节点不同：借&amp;修改时，同样把兄弟节点的键上移，但借来的是 &lt;父节点的键,兄弟节点的值&gt;；合并&amp;删除时，要把父节点的键和兄弟节点的键值一块和该节点合并。 如果下溢出到了根节点，而且根节点只剩下一个子节点，说明树应该减少一层，将这个子节点设为新的根。 并发控制安全节点：插入后不上溢，删除后不下溢，读取时均安全。如果子节点安全，那么对其下面的节点做插入&#x2F;删除操作引起的树结构变化最多会传递到该层，不会影响上层，所以可以放掉祖先节点的锁允许其它操作访问 读操作 子节点获取读锁后就释放父节点读锁，只需要一个 prev_page 指针解锁父节点 插入&#x2F;删除操作 从根节点开始往下依次加写锁，直到安全节点才释放祖先节点的所有锁。在实现上，用 page_set 记录查找过程中加写锁的页面。 对于插入，page_set保存的写锁就足够了，因为新生成的兄弟结点不会被其它操作访问到 对于删除，需要对访问的兄弟节点上写锁，不在 page_set 中，单独释放。删除或合并页导致删除的页面记录到 deleted_page_set 中，最后调用内存池接口删除掉 另需一把锁保护根节点，只有根结点安全情况才能解锁，否则堵塞前后 root_page_id_ 可能变了 瓶颈在于每次都要获取根节点写锁，优化方法：“乐观” 地假设插入&#x2F;删除不会发生分裂或合并，于是只需沿路径像读取一样获取和释放读锁，最后检查叶节点是否安全：如果安全，则假设正确，只需对叶节点加写锁更新；如果不安全则假设错误，重新调用基础版算法。 踩坑Unlock 和 Unpin 的顺序：先 Unlock 后 Unpin，因为 Unpin 后这个 Page 的 pin count 可能降为 0，buffer_pool_manager 可能会将该 Page 指针的内容改写为另一个 Page 的，导致 Unlock 错误 事务与并发控制LockManagerLockManager 实现了基于 2PL 的行级锁，自动为并发事务执行加锁解锁。当一个事务需要读写元组时候，根据自身的隔离级别尝试获得元组对应的读锁或写锁，并在适当的时刻将其释放。 LockManager 为每个表&#x2F;行维护一个请求队列，用条件变量阻塞&#x2F;唤醒请求，用 map 建立资源到队列的索引。队列按请求先后排序，记录了每个请求的事务、锁级别、是否授予等。 实现了三种隔离级别： 隔离级别 加锁模式 效果 可重复读 在执行器中只加锁，在commit&#x2F;abort时一次性解锁 仅存在幻读 读已提交 在Growing阶段解读锁(即读完立即释放)+写锁 不可重复读、幻读 读未提交 读不加锁，写加锁 脏读、不可重复读、幻读 加锁操作： 检查加锁是否兼容隔离级别：如 RR 在 shrinking 时不能加任何锁，RC 只能加读锁 获取 table 对应的表级锁请求队列 检查是否是升级锁操作，即队列里是否有相同的 tid，若有： 是否有另一个事务尝试升级锁？通过upgrading字段判断，抛异常 升级是否兼容，即升级后数据是否安全（限制越严越安全）：IS -&gt; [S, X, IX, SIX], S -&gt; [X, SIX], IX -&gt; [X, SIX], SIX -&gt; [X] 释放此前持有的锁，后续把升级作为一个新的请求加入队列 将锁加入请求队列：普通锁直接放到队尾，升级锁因为优先级高，应插入首个未授权的请求前 后续该请求基于while循环和条件变量尝试获取锁，按 FIFO 遍历请求队列判断能否满足锁请求： 获取读锁：如果当前txn已经是最早的事务，或前面都持有读锁，则授予 获取写锁：只有当前txn是最早的事务才授予，否则一定冲突，被 cv.lock() 阻塞 解锁操作： 找到表&#x2F;元组的锁请求队列，遍历找到要解锁的txn 根据隔离级别修改事务状态： RR 时，事务进入 Shrinking RC、RU 时，仅 X 锁释放使事务进入 Shrinking cv_.notify_all() 唤醒所有阻塞在此请求队列上的事务 死锁检测 构建有向图，遍历表锁和元组锁中的所有请求队列，把每对符合等待关系的事务 &lt;a, b&gt; 加入图的边集，a 是 waiting 请求，b 是 granted 请求。 用 DFS 来进行环检测，需要记录环上的所有节点。挑选 tid 最大的事务终止，删除图中的边，唤醒阻塞的请求 重复环检测直到无环为止 SQL执行器 SQL 语句先经过 Parser 生成一棵抽象语法树（libpg_query 库）； Binder 遍历树，将关键字&#x2F;标识符绑定到数据库实体上（c++类）； Planner 遍历这棵树，生成初步的查询计划 Plan Tree，每个Plan结点都代表了一个操作，树中上层的Plan结点调用 next() 从下层结点取出一条数据，从而数据自底向上地流动，在根节点输出结果。 Optimizer 遍历 Plan Tree 进行逻辑规则，这种优化器不需要知道数据的具体内容，仅是根据预先定义好的规则修改 Plan 结点。 Executor 遍历查询计划树，将树上的 PlanNode 替换成对应的执行算子 OptimizerTopN：对 Plan Tree 进行后续遍历，在遇到父节点 Limit、子节点 Sort 时，则将这两个节点替换为一个 TopN HashJoin： 把 NestedLoopJoin 替换为 HashJoin 让小表驱动大表，减少表连接次数，调用已提供的api估计table大小，再根据大小来调整 Plan Tree 里 join 的顺序 IndexJoin：识别 B+Tree Index，默认只会为右表匹配 index，因此如果 左表有 index &amp;&amp; 右表没有 &amp;&amp; 等值连接，则把左右顺序替换一下，便于之后正确识别索引 谓词下推：需要把 Filter 正确下推至 Join 算子下，尽量接近叶子节点，减少数据拷贝耗时。自顶向下地改写，提取 predicate 中的所有 comparison，判断表达式的两边是否一个是 column value，一个是 const value，只有这样的 predicate 可以被下推，再将所有的 predicate 重新组合为 logic expression 生成新的 Filter，根据 column value 的 idx 来选择下推的分支 列裁剪：遇到连续的两个投影，合并为 1 个，只取上层投影所需列，其余直接抛弃 Executor火山模型 每个算子都有 Init() 和 Next() 两个方法。Init() 对算子进行初始化工作，Next() 向下层算子请求下一条数据，返回 false 时说明下层算子已经没有剩余数据，迭代结束。 简单，每个 Operator 可以单独抽象实现、不需要关心其他 Operator 的逻辑 数据以行为单位进行处理，不利于CPU cache；且每处理一行需要调用多次next() 函数，虚函数开销大 HashJoinExecutor 使用基础哈希算法进行连接操作，其原理为将元组的连接键（即某些属性列的组合）作为哈希表的键，并使用其中一个子计划节点的元组构造哈希表。由于具有相同连接键的元组一定具有相同的哈希键值，因此另一个子计划节点中的元组仅需在该元组映射的桶中寻找可与其连接的元组 用unordered_multimap直接存放等于连接键的元组，再用右子节点的元组作为”探针”寻找与其连接键相同的左子计划节点的元组，可能有多个左子结点对应 AggregationExecutor 用哈希表将所有聚合键（即元组的属性列组合）相同的元组映射在一起，以此统计所有聚合键元组的聚合信息 并发控制将 transaction 应用到之前实现的算子中，以支持并发的查询：为查询计划执行器的顺序扫描、插入、删除计划的NEXT()方法提供元组锁的保护 只需修改以下三个算子，因为其他算子获取的tuple数据均为中间结果： seq_scan 不同隔离级别怎么加锁？读未提交不加锁；读已提交读完 table 立即解锁；可重复读在COMMIT或ABORT后才释放锁 加什么锁？表加 IS 锁，再给行加 S 锁。 为什么不给表加 S 锁？对于 DELETE...WHERE...，同个 query 先在下层加 S 锁，又在 Delete 里加 IX，因为 S 锁不能升级 IX 锁就会卡死（整表读 -&gt; 某行写，锁升级不兼容） insert元组插入表时由 tablePage 锁保证并发安全，插入后为了更新索引，需要先获得元组的写锁，保证此期间元组不被修改，之后再更新索引依靠 B+tree 的锁 delete调用 next() 收到子计划节点要删除的元组后（如seq_scan），应当为该元组加写锁，然后标记元组删除，并删除索引，等到事务提交时缓冲池删除。注意在 RR 级别时，子计划节点此时拥有该元组的读锁，因此应该采用升级锁 参考链接 CMU 15-445&#x2F;6452021 CMU 15-445 实验笔记CMU 15445 -2022通关小结[Github] CMU15445-2021-FALLCMU 15445 BufferPoolManager2021 CMU-15445&#x2F;645 Project #3 : Query ExecutionCMU15-445 Lab3 Query Execution全记录Concurrency Control TheoryCMU15-445 22Fall通关记录记录一下 CMU 15445 项目Bustub Project #2：B+ Tree（下）","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[]},{"title":"操作系统","slug":"Archive/操作系统","date":"2023-04-20T12:59:04.000Z","updated":"2025-03-06T09:01:58.041Z","comments":true,"path":"2023/04/20/Archive/操作系统/","permalink":"http://example.com/2023/04/20/Archive/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"进程和线程线程与进程区别线程与协程区别 协程是一种用户态的轻量级线程，一个线程可以有多个协程，其特性在于CPU的执行权是由协程主动让出的，相比内核态线程而言，调度协程的时机开发者是比较清楚的 创建开销：协程的栈空间占用只有 2k~4k，在一个地址空间中可以运行 10w 级别的协程 切换开销：进程和线程切换时都涉及内核切换（陷入内核态运行调度程序）；而协程调度由用户程序控制，只需要保存寄存器上下文和栈，不涉及内核切换的开销，提高了性能，但也失去了使用多CPU的能力 同步问题： 从狭义的角度来看，因为调度协程的线程只有一个，所以不存在数据竞态（多线程并发访问共享资源），不需要类似线程锁的机制保障安全 从用户进程的角度看，调度协程时虽然是主动让出CPU的，但如果a协程在让出CPU之前引用了全局变量，随后执行b协程时修改了全局变量，等调度回协程a时就可能导致运行结果不符预期。所以也需要通过编程上的一些技巧来避免协程调度的过程中产生的数据污染（比如引用全局变量的一个副本等） 进&#x2F;线程间同步方式 临界区：让多个线程串行化访问公共资源或代码，在有一个线程进入后其他访问临界区的线程将被挂起，以CRITICAL_SECTION结构对象保护共享资源 优点：方法简便，速度快 缺点：不能同步多个进程中的线程 互斥量：跟临界区相似但更复杂，互斥对象只有一个，只有拥有互斥对象的线程才能访问资源 优点：可以在不同应用程序的线程之间实现资源共享 缺点：互斥量是可以命名的，可以跨越进程使用，但创建所需的资源更多，所以只在进程内使用时不如临界区速度快、资源占用少；不能允许多个线程同时对资源的访问 信号量：允许多个线程同时访问一资源，并限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数&#x3D;1就是互斥量了 优点：适用于对 Socket 程序中线程的同步 缺点：基于公共内存，不能用于分布式操作系统；P-V 操作分散在各用户程序的代码中， 读写和维护都很困难，加重了编码负担； 事件：用来通知线程有一些事件已发生，从而启动后继任务的开始。事件处于激发或未激发状态，分为两类：①手动设置：只能手动设置事件对象，事件发生后手动重置对象；②自动恢复：事件发生并处理后，自动恢复，无需手动设置 优点：通过通知操作可以实现不同进程中的线程同步。 进程间的通信方式 匿名管道：一种半双工的通信方式，数据单向流动，简单但是只能在有亲缘关系的进程间使用（父子、兄弟） 命名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信 缺点：缓冲区有限；命名管道在使用完后依然存在于文件系统中，不会自动删除 信号量：允许多个进程同时访问一资源，并限制在同一时刻访问此资源的最大进程数目 信号：信号是在软件层次上对中断机制的一种模拟，一种异步通信方式。信号可以让一个正在运行的进程被另一个异步进程中断，转而处理某个突发事件 缺点：不能传递复杂消息，只能用来同步 消息队列：是存放在内核中的消息链表，每个消息队列由消息队列标识符标识 优点：可以实现任意进程间的通信，通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合 共享内存：将不同进程的虚拟内存地址映射到相同的物理内存地址，所有的进程都可以访问共享内存中的地址，一个进程对共享内存所做的改动将立即影响到其他进程，Linux共享内存最多128个 优点：无须复制，快捷，信息量大 缺点：并未提供同步机制；只能由同一个计算机系统中的进程共享，不方便网络通信 套接字：可用于不同计算机间的进程通信 优点：传输数据为字节级，传输数据可以自定义；客户端服务器之间信息实时交互；可以加密，安全性强 缺点：需对传输的数据进行解析，转化成应用级的数据。 线程间的通信方式 锁机制：包括互斥锁、读写锁、自旋锁、条件变量 详见 “线程的几种锁“ 信号量：无名线程信号量、命名线程信号量 信号：类似进程间的信号处理，用法：处理signal(SIGINT, fun)，忽略signal(SIGINT, SIG_IGN) SIGINT 中断信号，Ctrl+C SIGTERM 终止信号，kill -15，可以被捕获处理 SIGKILL 强制终止信号，kill -9 SIGSEGV 段错误信号，访问了未分配内存 SIGCHILD 子进程状态变化信号，当子进程终止或停止时发送给父进程 线程的几种锁 互斥锁：一次只能一个线程拥有互斥锁，抢锁失败的线程主动放弃CPU并进入睡眠状态 读写锁：允许多个线程同时读共享数据，而写操作是互斥的，写优先于读（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者） 自旋锁：线程无法取得锁时不会立刻放弃CPU，而是一直循环尝试获取锁。如果别的线程长时期占有锁，那么自旋会浪费CPU，一般应用于加锁时间很短的场景，此时效率比较高 条件变量：直到某个特定条件为真为止，以原子的方式阻塞进程。条件测试是在互斥锁的保护下进行的，若条件不满足，线程解开互斥锁并阻塞线程，等到某个线程改变了条件变量时，他将通知相应的条件变量唤醒被阻塞线程。互斥锁是线程间互斥的机制，条件变量是同步机制 递归锁：也叫可重⼊锁，在一个线程在不解锁的情况下多次锁定同一个递归锁，而且不会产生死锁 进程与线程的切换（3.5μs）进程切换 切换页表以使用新的地址空间，一旦切换上下文，处理器中所有已缓存的内存地址一瞬间都作废了 切换内核栈和硬件上下文 线程切换 切换内核栈和硬件上下文（地址空间不变） 为什么虚拟地址空间切换比较耗时？ 每个进程都有自己的虚拟地址空间和页表，所以进程切换后页表也要进行切换。页表切换后TLB失效，Cache失效导致命中率降低，虚拟地址转换物理地址速度变慢，最终表现为程序运行变慢。 线程切换不会导致TLB失效，因为线程共享所在进程的虚拟地址空间，无需切换地址空间，因此线程切换快。 进程调度算法 先来先服务 FCFS 按照请求的先后顺序进行调度，是非抢占式的调度算法。利于长作业但不利于短作业，因为短作业必须等待前面的长作业执行完毕才能执行，造成等待时间过长。 短作业优先 SPF 选择估计运行时间最短的作业，将它们调入内存运行。但长作业的运行得不到保证。 优先级调度 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 高响应比优先 选择响应比最大的作业执行，响应比&#x3D;(等待时间+要求服务时间)&#x2F;要求服务时间。既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务，但每次调度前对响应比的计算会增加系统开销。 时间片轮转 RR 将所有就绪进程按 FCFS 的原则排成一个队列，每次让队首进程执行一个时间片，当时间片用完后计时器发出时钟中断，调度程序便停止执行该进程并送往就绪队列的末尾，再把 CPU时间分配给新的队首进程。 算法效率和时间片大小有关：因为进程切换都要保存和载入进程信息，如果时间片太小，会导致进程切换太频繁、浪费时间，如果时间片过长则不能保证实时性。 多级反馈队列 MLFQ 设置多个就绪队列，每个队列的优先级不同，进程执行时间片的大小也不同。 首先将进程放入第一队列的末尾，按 FCFS 原则排队等待调度。若在时间片内未执行完，调度程序便将该进程转入第二队列的末尾，再同样按 FCFS 原则等待调度…… 若最终降到第 n 队列则采取时间片轮转方式。 仅当前 i 个队列均空时，才会调度第 i 队列中的进程运行。如果正在处理第 i 队列某进程时，有新进程进入优先权较高的队列，则新进程将抢占处理机，由调度程序把正在运行的进程放回原队列末尾。 守护进程、孤儿进程和僵尸进程 守护进程：指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等 孤儿进程：如果父进程退出而子进程还在运行，则子进程成为孤儿进程。孤儿进程将被 init 进程接收并完成状态收集工作避免：⽗进程调⽤ wait 或者 waitpid 函数等待⼦进程完成再退出 僵尸进程：如果子进程退出而父进程还在运行，那么子进程必须等到父进程捕获到了其退出状态才真正结束，否则这个时候子进程就成为僵尸进程。设置僵尸进程的目的是维护子进程的信息，以便父进程在以后某个时候获取子进程ID、终止状态等避免：⼦进程退出时向⽗进程发送 SIGCHILD 信号，⽗进程处理 SIGCHILD 信号。在信号处理函数中调⽤ wait 进⾏处理僵⼫进程 中断内中断1. 内中断的产生 除法错误:0 单步执行:1 执行 into 指令:4 执行 int 指令,格式为int n ,n为字节型立即数,是中断类型码 2. 中断过程 由中断类型码找到中断向量,并自动用它设置 CS和IP，随后执行中断处理程序 从中断信息取得中断类型码N pushf &#x2F;&#x2F;标志寄存器入栈(中断过程中值改变) TF=0,IF=0 &#x2F;&#x2F;设置标志寄存器的TF、IF位 push CS push IP (IP)=(N*4),(CS)=(N*4+2) 3. 中断向量表 中断向量表是中断处理程序入口地址的列表，在内存0000:0000到0000:03FF的1024个单元中存放，一个表项存放一个中断向量,占两个字,高地址存放段地址,低地址存放偏移地址 4. 中断处理程序 中断处理程序必须一直存储在内存某段空间之中，而中断向量必须存储在对应的中断向量表表项中。中断处理程序常规的步骤: 保存用到的寄存器; 处理中断; 恢复用到的寄存器; 用 iret 指令返回。 外中断外设随时都可能发⽣需要CPU及时处理的事件，这种中断来⾃于CPU的外部，当CPU外部有需要处理的事情发⽣的时候，⽐如说，外设的输⼊到达，相关芯⽚将向CPU发出相应的中断信息。CPU在执⾏完当前指令后，可以检测到发送过来的中断信息，引发中断过程，处理外设输⼊。 在PC系统中，外中断源⼀共有以下两类。 可屏蔽中断 当CPU检测到可屏蔽中断信息时，如果IF&#x3D;1，则CPU在执⾏完当前指令后响应中断，引发中断过程：如果IF&#x3D;0，则不响应可屏蔽中断。 可屏蔽中断所引发的中断过程，除在第1步的实现上有所不同外，基本上和内中断的中断过程相同。因为可屏蔽中断信息来⾃于CPU外部，中断类型码是通过数据总线送⼊CPU的；⽽内中断的中断类型码是在CPU内部产⽣的。 故中断过程中将IF置为0的原因：在进⼊中断处理程序后，禁⽌其他的可屏蔽中断。当然，如果在中断处理程序中需要处理可屏蔽中断，可以⽤指令将IF置1。指令：sti ，设置IF&#x3D;1；cli ，设置IF&#x3D;0 不可屏蔽中断 当CPU检测到不可屏蔽中断信息时，则在执⾏完当前指令后，⽴即响应，引发中断过程。 不可屏蔽中断的中断类型码固定为2，所以中断过程中，不需要取中断类型码，则不可屏蔽中断的中断过程为 ⼏乎所有由外设引发的外中断，都是可屏蔽中断。 死锁死锁和活锁 死锁：指两个及以上的进程在执行过程中，由于竞争资源或彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。 活锁：指的是任务没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 死锁条件 互斥条件：一个资源每次只能被一个进程使用 不可剥夺条件：进程已获得的资源在未使用完之前不能强行剥夺 请求与保持条件：一个进程因请求资源而阻塞时，不释放已获得的资源 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系 解决死锁的方法 预防：采用某种策略，限制并发进程对资源的请求，从而使得死锁的必要条件在任何时间都不满足。 避免：系统在分配资源时，根据资源的使用情况提前做出预测，从而避免死锁的发生 检测：系统设有专门的机构检测死锁的发生，并确定与死锁有关的进程和资源。 解除：配合死锁检测，将进程从死锁状态下解脱出来。 死锁预防 破坏互斥条件。允许进程同时访问资源，但有的资源不能同时被访问。 破坏不可剥夺条件：允许进程抢占资源。这种预防方法实现起来困难，会降低系统性能。 破坏请求与保持条件：实行预先分配策略，在进程运行前就申请它所需要的全部资源，若不能满足则不分配任何资源。 进程执行是动态的，很难提前预测它所需的全部资源。 资源利用率低，即使有些资源最后才被用到，也会被进程长期占有。 破坏循环等待条件：给资源统一编号，让进程按序请求资源。 相比之下资源利用率和系统吞吐量有所提高 限制了进程对资源的请求，也难以给资源合理编号，增加了系统开销。 Mutex原理Mutex 的本质就是一个内存标志，这个标志可以是一个flag（占用标志，底层基于硬件原子操作），也可以是一个指向持有者线程ID的指针，另外还有一个阻塞队列等若干信息。当 Mutex 被标记成占用、或持有者指针非空时，它就不能被被别的线程访问。只有等到空闲时，操作系统会从阻塞队列里取出第一线程调度执行（或标为就绪态等待调度）。 死锁避免 将系统的状态分为安全状态和不安全状态，分配资源前先测试系统状态，若分配资源后会产生死锁则拒绝分配，否则才为它分配资源。安全状态：操作系统能够保证所有的进程在有限的时间内得到需要的全部资源。安全状态不会发生死锁，不安全状态可能发生死锁。银行家算法：进程申请使用资源时，先试探分配给该进程资源，然后通过安全性算法判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，否则才真正分配资源给该进程。 死锁检测 不限制资源分配，也不采取死锁避免措施，但系统定时地运行一个 “死锁检测”的程序，判断系统内是否出现死锁，如果检测到了死锁再采取措施解除。 死锁解除 资源剥夺法：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源，而处于资源匮乏的状态。 撤销进程法：撤销部分死锁进程，并剥夺它的资源。撤销的原则可以按进程优先级和撤销进程代价进行。 进程回退法：让部分进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。 内存管理分页存储将程序的逻辑地址空间划分为固定大小的页，物理内存划分为同样大小的页框，大小取2的整数幂。程序加载时，可将任意一页放入内存中任意一个页框，因为页框不必连续，所以实现了离散分配。 需要用页表来记录页号到物理块号的映射关系，进程未执行时，页表的始址和长度放在 PCB 中，进程调度后放到页表寄存器 PTR 中。 地址映射： 地址结构由页号和页内地址（位移量）组成。CPU中的内存管理单元 (MMU) 按逻辑页号通过查进程的页表得到物理页框号，将物理页框号与页内地址相加形成物理地址。 优点： 没有外碎片，提高内存的利用率 实现离散分配，一个程序不必连续存放 缺点： 无论数据有多少，都只能按照页面大小分配，容易产生内部碎片 不能体现程序逻辑，页长与程序的逻辑大小不相关 不利于编程时的独立性，不易于存储保护和信息共享 快表操作系统引入快表来加速虚拟地址到物理地址的转换。可以把快表理解为一种特殊的高速缓冲存储器，其中存放了页表的部分内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。因为采用页表做地址转换读写内存数据时，CPU 要访存两次，而通过快表可以只访问一次高速缓冲存储器，一次主存。 使用快表之后的地址转换流程是这样的： 根据虚拟地址中的页号查快表，如果该页在快表中，直接从快表中读取相应的物理地址； 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将映射表项添加到快表中； 当快表填满又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。 分页和分段存储区别共同点： 都是为了提高内存利用率，减少内存碎片。 都是离散分配内存的方式，但每个页和段中的内存是连续的。 区别： 页是信息的物理单位，分页是为了离散分配提高内存的利用率；段是信息的逻辑单位，分段是为了更好地满足用户的需要。 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度却不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。 分页的地址空间是一维的，程序员只需用一个记忆符即可表示一个地址；而分段的作业地址空间是二维的，标识一个地址需要给出段名+段内地址。 段是信息的逻辑单位，便于存储保护和信息共享；页的保护和共享受到限制。 Folding 内存管理要做什么操作系统负责内存空间的分配与回收。操作系统需要提供某种技术从逻辑上对内存空间进行扩充。操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。操作系统需要提供内存保护功能，保证各进程在各自存储空间内运行，互不干扰内存管理机制连续分配管理：为用户程序分配一个连续的内存空间。如单一连续分配、固定分区分配和动态分区分配动态分区分配算法：首次适应算法：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。最佳适应算法：优先使用更小的空闲区最坏适应算法：优先使用最大的空闲区邻近适应算法：每次从上次查找结束的位置开始查找空闲分区表，找到大小满足的第一个空闲分区非连续分配管理：允许内存分布在离散内存中，如页式管理、段式管理和段页式管理机制分段存储将用户程序地址空间分成大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配以段为单位，段之间可以不相邻，也实现了离散分配。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。地址映射：在段式管理系统中，整个进程的地址空间是二维的，其逻辑地址由段号和段内地址两部分组成。地址转换时，处理器会查找内存中的段表，由段号得到段的首地址，再加上段内地址就得到了物理地址。这个过程也是由处理器的硬件直接完成的，操作系统只需在进程切换时，将进程段表的首地址装入段表地址寄存器中即可。 优点：段的逻辑独立性使其易于存储保护和信息共享，方便编程。段长可以根据需要动态改变，以便有效利用主存空间。缺点：容易在段间产生外部碎片，造成存储空间利用率降低。由于段长不相同，在地址转换时，不能像分页方式那样用虚拟地址的低几位作为段内地址直接拼接，必须用加法操作通过段起址与段内地址的求和运算得到物理地址，需要更多的硬件支持。段页存储段页存储管理方式综合了段式管理和页式管理的优点，但需要经过两级查表才能完成地址转换，消耗时间多。它首先将程序按其逻辑结构划分为若干个大小不等的逻辑段，然后再将每个逻辑段划分为若干个大小相等的逻辑页。主存空间也划分为若干个同样大小的物理页，辅存和主存之间的信息调度以页为基本传送单位，每个程序段对应一个段表，每页对应一个页表。段页式存储地址结构包含三部分：段号，页号，页内位移量。地址变换的过程：首先用段号和段表长进行比较，防止越界；利用段表始址和段号来求出段表项的位置，从中得到该段的页表始址；利用段内页号来获得页表项位置，从中读出该页所在的物理块号；利用块号和页内位移量来构成物理地址多级页表对于 4G 大小的虚拟地址空间，每个页空间大小4K，每个页表项4B，如果采用一级页表则需要 4M 的连续内存来存放 4G/4K = 1M 个页表项，每个进程都要存储一个 4M 的页表，开销太大，并且很多页表项访问不到，没必要保存在内存中。如果使用二级页表，4G 的内存空间只需一个 4K 的一级页表管理 1024 个二级页表，然后每个二级页表管理1024 个页即可。根据局部性原理只需一级页表在内存中，二级页表放在外存，等缺页中断的时再调入内存。多级页表虽然节约了存储空间，却带来了时间上的开销，属于时间换空间。原本只需访存一次就能找到物理地址，但在用了多级页表后，就需要访问多次内存才能找到物理页号了。 虚拟内存什么是虚拟内存基于局部性原理，可以将程序的一部分装入内存就启动执行，而其他部分留在外存。由于外存往往比内存大很多，所以运行的软件内存大小可以比计算机的实际内存更大。如果程序在运行中发生缺页（通过页表项标记位判断），则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。这样，计算机好像为用户提供了一个远大于实际内存的存储器，也叫虚拟存储器。 虚拟内存是一种时间换空间的策略，用 CPU 的计算时间、页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。 为什么要用虚拟内存？因为早期的内存分配方法存在以下问题： 进程地址空间不隔离，会导致数据被随意修改。 内存使用效率低。 操作系统随机为进程分配内存空间，所以程序运行的地址是不确定的。 虚拟内存的优点： 扩大了地址空间，虽然真实物理内存没那么多 内存保护：防止不同进程对物理内存的争夺，可以对特定内存地址提供写保护 可以实现内存共享，方便进程通信 可以避免内存碎片，虽然物理内存可能不连续，但映射到虚拟内存上可以连续 虚拟内存的缺点： 虚拟内存需要额外构建数据结构，占用空间 虚拟地址到物理地址的转换和页面换入换出，增加了执行时间 页面置换算法 OPT 最佳页面置换算法 ：淘汰以后最久不再访问的页面，这样可以保证获得最低的缺页率。但由于无法预知哪个页面未来最久不再被访问，因而该算法无法实现，一般作为衡量其他置换算法的方法。 FIFO 先进先出页面置换算法：淘汰最先进入内存的页面。 LRU 最近最久未使用页面置换算法：赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。 LFU 最少使用页面置换算法：选择之前使用最少的页面作为淘汰页 用户态和内核态⽤户态转化内核态 系统调⽤⽤户态进程主动切换到内核态的⼀种⽅式，是操作系统提供给⽤户程序的⼀组特殊接⼝，从而让⽤户程序获得操作系统内核提供的服务，⽐如 fork() 实际上就是执⾏了⼀个创建新进程的系统调⽤。系统调⽤的核心机制是使⽤了操作系统为⽤户开放的⼀个中断来实现，例如 Linux 的 int 80h 中断。 异常由 CPU 执行指令的内部事件引起异常，如非法操作码、地址越界、算术溢出等。这时会触发当前进程切换到内核态的异常处理程序中。 外中断当外围设备完成⽤户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执⾏下⼀条要执⾏的指令，转⽽去执⾏相应的中断处理程序，如果先前执⾏的指令是⽤户态下的程序，就发⽣了由⽤户态到内核态的切换。如 I&#x2F;O 完成中断、时钟中断、控制台中断等 内核级和用户级线程 内核级线程：依赖于内核，又称为内核支持的线程或轻量级进程。无论是在用户程序中还是系统进程中的线程，它们的创建、撤销和切换都由内核实现，可以在进程内并发，但创建、切换开销大 用户级线程：它仅存在于用户级中，不依赖于内核，操作系统内核无法感知用户级线程的存在，不能并发（一个堵塞所有堵塞）。应用进程利用线程库来完成其创建和管理，速度比较快 用户级线程和内核级映射关系：一对一，多对多，多对一 IO模型网络IO涉及用户空间和内核空间，一般会经历两个阶段： 一阶段：等待网络数据被copy到内核缓冲区 此阶段内核数据没准备好时（等待socket中数据到来），根据用户进程是否睡眠分为阻塞和非阻塞 二阶段：将数据从内核缓冲区copy到用户空间 此阶段根据用户进程是否参与数据读写，分为同步和异步 同步：数据读写都是请求方自己来完成 异步：请求方并没有参与事件读写，由他人完成 根据以上两阶段的不同，分为以下五种网络IO模型： 五种I&#x2F;O模型 阻塞 I&#x2F;O调⽤I&#x2F;O函数会使进程阻塞，先等待数据准备好，再从内核拷⻉到⽤户空间。两个阶段均堵塞。 ⾮阻塞 I&#x2F;O当I&#x2F;O操作⽆法完成时不将进程睡眠，⽽是返回⼀个错误如 EWOULDBLOCK、EAGAIN。I&#x2F;O操作函数将不断询问内核数据是否准备好（⼤量的占⽤CPU的时间），当数据准备好时，用户进程会阻塞直到数据从内核空间copy到用户空间完成。一阶段不阻塞，二阶段阻塞。 I&#x2F;O 多路复⽤通过一种机制监视多个描述符，一旦某个描述符就绪，就通知程序进行相应的读写操作，会⽤到select、poll、Epoll 函数。I&#x2F;O多路复用通常是非阻塞的，因为它允许你同时监控多个I&#x2F;O操作而不必等待任何一个特定操作完成，但是第二阶段的I&#x2F;O操作仍阻塞，属于同步。 信号驱动 I&#x2F;OLinux通过 sigaction 系统调用，建立起信号驱动IO的socket，并绑定一个信号处理函数；sigaction 不会阻塞，立即返回，进程继续运行。当数据准备好，内核就为进程产生一个 SIGIO 信号，随后在信号处理函数中接收数据。与非阻塞IO的区别在于它提供了消息通知机制，不需要用户进程不断地轮询检查，减少了系统调用次数，提高了效率。一阶段不阻塞，二阶段阻塞。 以上四种模型在真正IO操作时都需要用户进程参与，均称为同步IO模型。 异步 I&#x2F;O如 libaio 库、POSIX 标准定义的异步IO的 aio 接口。用户进程调用 aio_read 之后会立即返回不阻塞，aio_read 会给内核传递文件描述符，缓冲区指针，缓冲区大小等；数据准备好时，内核直接将数据copy到用户空间，copy完后给用户进程发送一个信号，进行用户数据异步处理。因此用户进程不需要将数据从内核空间copy到用户空间。两阶段均不阻塞。 I&#x2F;O复用的原理进程预先告诉内核需要监视的IO条件，内核⼀旦发现进程指定的⼀个或多个IO条件就绪，就通过进程处理，从⽽不会在单个IO上阻塞了。Linux中提供了select、poll、Epoll三种接⼝函数来实现IO复⽤。 Select 监视文件描述符 fd 的三种事项：读事件、写事件、异常事件。 可监视的最大文件描述符数量有限（1024） 每次监听都要将文件描述符集合 fd_set 从用户态重新拷贝到内核态，返回结果时再拷贝出来 调用完 Select 函数后需要循环获取发生变化的 fd，在大量 fd 并发、少量活跃时效率低 Poll 使⽤链表保存⽂件描述符，没有了监视⽂件数量的限制，但 Select 的其他三个缺点依然存在 Epoll 底层是一棵红黑树和一个就绪链表（双向链表），红黑树结点是一个与 fd 相关的结构体，包括了fd、事件和回调函数。当 fd 上有对应感兴趣事件发生时，内核自动调用回调函数将其添加到链表里，返回结果时（ET模式下清空链表）将就绪的 fd 集合返回用户空间，同时返回就绪事件的数量。使用红黑树查找删除添加都是 logn 的时间复杂度，有较稳定的时间复杂度，通过查找红黑树防止重复添加文件描述符。 相比与 Select 和 Poll，Epoll 更加高效： 没 fd 数量限制：是一个很大的值，和内存大小有关 减少拷贝(用户态&lt;-&gt;内核态)：Select、Poll都需要将有关 fd 的数据结构拷贝进内核，返回结果时再拷贝出来。Epoll红黑树中已上树的 fd 不用再次拷贝，并且返回文件描述符时使用 mmap() 内存映射避免了内核态到用户态之间的拷贝 回调(监测方式)：Select、Poll采用轮询的方式来检查 fd 是否处于就绪态，而Epoll采用回调机制。随着 fd 的增加，Epoll性能不会线性降低，除非活跃的socket很多。 无需遍历(处理返回结果)：Select、Poll、Epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而Epoll会。因此系统调用返回后，Epoll无需遍历监听的整个文件描述符找到是谁处于就绪，直接处理即可。 ET触发：Epoll的边缘触发模式效率高，系统不会充斥大量不关心的就绪文件描述符 虽然Epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，Select和Poll的性能可能比Epoll好，毕竟Epoll的通知机制需要很多函数回调。 LT模式和ET模式水平触发 触发条件：只要缓冲区非空、不满时。 当 epoll_wait 检测到描述符事件时，应⽤程序可以不⽴即处理该事件，之后每次调⽤ epoll_wait 时还会继续通知此事件。但如果系统中有大量不需读写的就绪 fd ，而它们每次都返回，就会大大降低效率。 边缘触发 触发条件：缓冲区从不可读变为可读、不可写变为可写、数据量增减、 EPOLL_CTL 进行了 MOD 操作时。 当 epoll_wait 检测到描述符事件时，应⽤程序必须⽴即处理该事件。如果不处理，下次调⽤ epoll_wait 时不会再通知此事件，直到这个文件描述符上出现第二次该事件时才会通知。在很大程度上降低了同一个事件被 Epoll 触发的次数，因此效率比LT模式高 Select、Poll和Epoll区别 用户态将 fd 传入内核的方式 select：创建3个文件描述符集并拷贝到内核中，分别监听读、写、异常动作。这里受到单个进程可以打开的fd数量限制，默认是1024 poll：将传入的 pollfd 结构体数组拷贝到内核中进行监听 Epoll：执行 epoll_create 会在内核的高速cache区中建立一颗红黑树以及就绪链表。接着用户执行的 epoll_ctl 函数添加文件描述符会在红黑树上增加相应的结点 内核态检测 fd 就绪状态的方式 select：轮询方式遍历所有 fd，最后返回一个 fd 是否就绪的mask掩码，根据这个掩码给 fd_set 赋值。 poll：轮询遍历每个 fd 状态，如果就绪则加入等待队列中。 Epoll：采用回调机制。在执行 epoll_ctl 的 ADD 操作时，不仅将文件描述符放到红黑树上，而且也注册了回调函数，内核在检测到 fd 就绪时会调用回调函数，该回调函数将文件描述符放在就绪链表中。 将就绪 fd 传递给用户态的方式 select &#x2F; poll：将之前传入的fd数组拷贝传出用户态并返回就绪的文件描述符总数，需要遍历判断 Epoll：epoll_wait将就绪链表的数据放入传入的数组中并返回数量，无需判断直接依次处理即可。并且返回文件描述符时使用 mmap() 内存映射避免了内核态到用户态之间的拷贝 重复监听的处理方式 select &#x2F; poll：将新的监听文件描述符集合 &#x2F; 结构体数组拷贝传入内核中 Epoll：无需重新构建红黑树，直接沿用已存在的即可 其他问题硬链接和软链接 inode：索引节点，和文件唯一对应，记录文件的属性，同时记录此文件的内容所在的 block 号码 dentry：目录项，存储文件的文件名与inode编号，通过读取目录项来判断文件是否存在于这个目录中 block：用来存储文件的内容，可能占用多个 block 硬链接：普通文件。就是在目录下创建一个目录项，记录文件名与 inode 编号，这个 inode 和源文件相同。删除一个条目后，只要剩余引用数量不为 0，文件就还存在。但是硬链接有限制，它不能跨越文件系统，也不能链接目录 软链接：符号链接文件。保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为快捷方式。因为记录的是路径，所以可以链接目录。但当源文件被删除时，链接文件就打不开了 键盘敲入字母时 用户输入键盘字符后，键盘控制器就会产生扫描码数据并缓冲在其寄存器中，然后键盘控制器通过总线发送中断请求 CPU 收到中断请求后，保存中断进程的上下文，然后调用键盘的中断处理程序（键盘驱动程序初始化时注册的），从键盘控制器的寄存器的缓冲区读取扫描码，如果是显示字符如 ABC，则翻译成对应的 ASCII 码，放到读缓冲区队列 若要显示至屏幕，显示设备的驱动程序会定时从读缓冲区队列读取数据放到写缓冲区队列，最后把数据写入到显示设备的控制器的寄存器数据缓冲区中，显示在屏幕里 零拷贝一种 I&#x2F;O 操作优化技术，是指 IO 操作时 CPU 不需要将数据从一个存储区复制到另一个存储区，从而可以减少上下文切换以及CPU的拷贝时间。在实现方式上，也并非完全不拷贝数据，而是减少用户&#x2F;内核态的切换以及CPU拷贝的次数 以读SSD+写网卡为例，两种实现方式：1. mmap+write：4次用户&#x2F;内核态切换，2次DMA拷贝和1次CPU拷贝借助虚拟内存可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，因此 mmap 将 page cache 与用户空间的缓冲区映射到一起，只需从磁盘拷贝数据到内核缓冲区，省掉了向用户缓冲拷贝的过程，使得读操作 IO 都在内核中完成 2. sendfile：2次用户&#x2F;内核态切换，2次DMA拷贝和1次CPU拷贝在两个文件描述符之间传输数据，全程由内核操作的，彻底避免了数据从内核缓冲区和用户缓冲区之间的拷贝操作 mmap原理1. 基本概念mmap 可以将一个文件映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的对映关系。这样进程就可以采用指针的方式读写操作这一段内存：读操作时可能引发缺页异常，会把文件内容拷贝到主存，写操作后系统会自动回写脏页面到对应的文件磁盘上，不必再调用read,write等系统调用函数。 2. 优点 减少显式调用read/write的系统调用，且mmap直接返回指向page cache的指针，避免OS到用户空间的一次拷贝 共享内存进程间通信。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域，从而达到进程间通信和进程间共享的目的。 3. 瓶颈 当SSD带宽高，DBMS 管理的数据量大于内存空间时，OS的页驱逐机制多线程扩展性比较差（因为 SSD I&#x2F;O 带宽大、访问速度快，页驱逐机制成了瓶颈） mmap的cache命中率不如read，因为OS会自动剔除一些内存页，这样可能导致频繁的缺页中断。在命中cache时，mmap没有用户态到内核态切换，LRU的内核页面无法+1，热点数据更新掉了 使用 mlock 锁hashtable，但一个进程能锁住的内存页数量有限制 使用 madvise 的 MADV_SEQUENTIAL 标记，积极顺序预取 4. 细节 mmap映射区域大小必须是 4K 大小的整倍数，否则实际映射区域向上取整，padding 部分填充为0且无法写入 映射的是磁盘地址和文件无关，只要映射范围的数据合法即可，和文件扩张&#x2F;关闭没有直接联系 指令乱序编译器：优化会将源代码中的一些指令顺序进行重排序，或者使用寄存器进行优化 处理器：CPU可能将没有数据依赖的指令执行顺序重排；现代 CPU 都是流水线结构，因此在 CPU 上多条指令并行执行，如果一个除法的指令占据了很久的除法器，可能下一条加法指令会更早执行完，导致代码执行后的内存顺序和我们预想的不一样。 内存屏障：编译器和CPU可以在保证输出结果一样的情况下对指令重排序，使性能得到优化。 阻止屏障两侧的指令重排序：插入一个内存屏障，相当于告诉CPU和编译器先于这个命令的必须先执行，后于这个命令的必须后执行 强制把写缓冲区&#x2F;高速缓存中的脏数据等写回主存，让缓存中相应的数据失效","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"计算计网络","slug":"Archive/计算计网络","date":"2023-04-05T12:59:04.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"2023/04/05/Archive/计算计网络/","permalink":"http://example.com/2023/04/05/Archive/%E8%AE%A1%E7%AE%97%E8%AE%A1%E7%BD%91%E7%BB%9C/","excerpt":"","text":"网络分层模型OSI分层 应用层：为应用程序提供交互服务，通过调用应用层的不同协议实体，从而调用传输层服务来进行网络传输 HTTP&#x2F;HTTPS、DNS、Telnet(远程登录服务协议) SMTP、POP3、FTP、TFTP(简单文件传输协议) 表示层：主要负责数据格式的转换，如加密解密、转换翻译、压缩解压缩等 会话层：负责建立、维持和终止会话，如服务器验证用户登录便是由会话层完成的 传输层：为主机进程提供端到端的数据传输 TCP：提供面向连接的、可靠的数据传输服务 UDP：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性 网络层：将传输层的报文段封装成IP分组，选择合适的路由转发 IP：定义了数据传输的基本单元和格式，以及数据报的递交方法和路由选择 ICMP：错误侦测与回报机制，能够检测网路的连线状况，是ping和traceroute的工作协议 IGMP：用于实现组播、广播等通信 数据链路层：将网络层的IP数据报组装成帧，在相邻节点的链路上传送 ARP、RARP：IP和MAC地址转换 PPP：通过拨号方式为点对点链路上直接相连的两个结点之间提供数据传输 物理层：实现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和通信手段的差异 TCP&#x2F;IP分层 网络接口层：负责将数据报发送到网络介质上，以及从网络上接收数据报，相当于OSI的物理层和数据层 网际层：将传输层的报文段封装成IP分组，选择合适的路由转发 传输层：为主机进程提供端到端的数据传输服务 应用层：为应用程序提供交互服务，通过调用应用层的不同协议实体，从而调用传输层服务来进行网络传输 输入URL回车 URL解析 判断输入的是一个URL 还是一个待搜索的关键词，若URL不完整则进行补全（前后缀） 然后检查本地缓存是否缓存了该请求资源，如果有则直接将该资源返回给浏览器显示 DNS解析 先查找缓存，没有再使用DNS服务器解析，查找顺序为： 浏览器缓存–&gt;本机缓存–&gt;路由器缓存–&gt;本地DNS服务器缓存 若都没有缓存，本地DNS服务器会先查询根域名服务器，若不存在则继续查询顶级域名服务器、权限域名服务器，以此类推。最后本地域名服务器得到IP地址并缓存，返回给主机。 建立TCP连接 这时我们已知IP地址以及默认的端口号了，一般会先尝试建立HTTP连接，经过三次握手建立TCP连接后： 使用HTTP协议 浏览器发送请求到服务器，如果使用的是HTTP协议，则直接返回结果 使用HTTPS协议 若不是HTTP协议，服务器返回3开头的重定向消息，告诉浏览器用的是HTTPS，即IP不用变，但端口号要从80变成443了 完成四次挥手后重建TCP连接，沟通好双方使用的加密传输和身份认证算法，在此过程中也会检验对方的CA安全证书，采用SSL的加密技术来保证传输数据的安全性 浏览器发送HTTP&#x2F;HTTPS请求 服务器处理请求并返回响应，包括所要访问的网址的一些数据 浏览器将界面进行渲染，还会发送GET请求以获取网页上的其他元素，最后呈现出完整网页 断开TCP连接，四次挥手 Linux 接收网络包的流程 网卡接收网络包后会通过DMA技术写入Ring Buffer环形缓冲区，接着通过中断告诉 OS 网络包已到达 内核线程从Ring Buffer中获取一个数据帧 sk_buff ，再依次交付给网络接口层、网络层、传输层处理 在传输层根据四元组「源 IP、源端口、目的 IP、目的端口」作为标识，找出对应的 Socket，并把数据放到 Socket接收缓冲区 应用层程序调用 Socket 接口，将内核的 Socket 缓冲区数据拷贝到应用层缓冲区，然后唤醒用户进程 Linux 发送网络包的流程 应用程序调用 Socket 发送数据包的接口，陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到Socket发送缓冲区 网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP&#x2F;IP 协议栈从上到下逐层处理，最后放到网卡发送队列中 传输层填充TCP头 网络层选取路由、填充IP头、分片处理 网络接口层获取下一跳MAC地址、填充帧头帧尾 通过软中断通知网卡驱动程序，将发送队列的中sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送 OSI和TCP&#x2F;IP的区别 OSI精确定义了服务、协议和接口，符合面向对象程序设计思想，而TCP&#x2F;IP没有明确区分。 OSI没有偏向任何特定的协议，通用性良好，但容易不知道将哪些功能放到哪一层。TCP&#x2F;IP模型实际上是对已有协议的描述，因此不会出现协议不能匹配的模式。 TCP&#x2F;IP考虑了异构网的互联问题，而OSI只考虑用一种标准的公用数据网将各种不同系统互连。 OSI在网络层支持无连接和面向连接的通信，但在传输层仅有面向连接通信。而TCP&#x2F;IP则相反，在网际层仅有无连接服务，在传输层支持无连接和面向连接两种模式。 TCPTCP的三次握手 三次握手过程 第一次握手：客户端请求建立连接，向服务端发送一个同步报文（SYN&#x3D;1），同时选择一个随机数 seq=x作为初始序列号，并进入 SYN_SENT 状态，等待服务器确认。 第二次握手：服务端收到连接请求报文后，向客户端发送同步确认报文（SYN&#x3D;1，ACK&#x3D;1），确认号为 ack=x+1，同时选择一个随机数 seq = y 作为初始序列号，此时服务器进入 SYN_RECV 状态。 第三次握手：客户端收到服务端的确认后，向服务端发送一个确认报文（ACK&#x3D;1），确认号为 ack=y+1，序列号为 seq=x+1，客户端和服务器进入ESTABLISHED状态，完成三次握手。 为什么不是两次握手 防止已过期的连接请求报文突然又传送到服务器，因而产生错误和资源浪费。在两次握手即可建立连接的情况下，假设客户端发送 A 报文段请求建立连接，但由于网络原因暂时无法到达服务器，客户端会在超时后重新发送请求报文段 B，这次 B 顺利到达服务器，双方建立连接并传输数据，之后正常断开连接。此时 A 报文段才到达服务器，服务器随即返回确认报文并进入 ESTABLISHED 状态，但是已经进入 CLOSED 状态的客户端无法再接受确认报文段，更无法进入 ESTABLISHED 状态，这将导致服务器长时间单方面等待，造成资源浪费。 三次握手才能让双方均确认自己和对方的发送和接收能力都正常。第一次握手：客户端只是发送处请求报文段，什么都无法确认，而服务器可以确认自己的接收能力和对方的发送能力正常；第二次握手：客户端可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常；但服务器方还不能确定自己发送和客户端接收是否正常；第三次握手：服务器可以确认自己发送能力和接收能力正常，对方发送能力和接收能力正常； 告知对方自己的初始序号值，并确认收到对方的初始序号值。TCP 报文段中维护了序号字段和确认序号字段，从而确定发出的数据中哪些已经被对方确认接收。这两个字段的值会在初始序号值得基础递增，如果是两次握手，只有发起方的初始序号可以得到确认，而另一方的初始序号则得不到确认。 三次握手可以携带数据吗第三次握手可以携带数据的，但是前两次握手不可以 第一次握手不可以带数据，因为会让服务器更加容易受到攻击（不断发送SYN，并携带长数据） 第三次握手时，客户端已经处于 ESTABLISHED 状态，对客户端来说已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据 TCP的四次挥手 四次挥手过程 第一次挥手：客户端向服务端发送连接释放报文（FIN&#x3D;1，ACK&#x3D;1），主动关闭连接并等待服务端的确认。 序列号 seq = u，即客户端上次发送的报文的最后一个字节的序号 + 1 确认号 ack = k, 即服务端上次发送的报文的最后一个字节的序号 + 1 第二次挥手：服务端收到连接释放报文后，立即发出确认报文（ACK&#x3D;1） 序列号 seq = k，确认号 ack = u + 1。 这时 TCP 连接处于半关闭状态，即客户端到服务端的连接已经释放了，但是服务端可能还要给客户端发送数据。 第三次挥手：服务端向客户端发送连接释放报文（FIN&#x3D;1，ACK&#x3D;1），主动关闭连接，同时等待 A 的确认。 序列号 seq = w，即服务端上次发送的报文的最后一个字节的序号 + 1。 确认号 ack = u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据 第四次挥手：客户端收到服务端的连接释放报文后，立即发出确认报文（ACK&#x3D;1） 序列号 seq = u + 1，确认号为 ack = w + 1。 此时，客户端就进入了 TIME-WAIT 状态，必须经过 2*MSL（最长报文段寿命）的时间后，才进入 CLOSED 状态。而服务端只要收到客户端发出的确认，就立即进入 CLOSED 状态。 为什么TIME-WAIT状态等待 2MSL 确保 ACK 报文能够到达服务端，从而使服务端正常关闭连接第四次挥手时，客户端第四次挥手的 ACK 报文不一定会到达服务端。服务端会超时重传 FIN&#x2F;ACK 报文，此时如果客户端已经断开了连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到 FIN&#x2F;ACK 报文的确认，就无法正常断开连接 防止已失效的连接请求报文段出现在之后的连接中客户端在发送完最后一个ACK报文段后，再经过2MSL就可以使本次连接的所有报文段都从网络中消失，使得下一个连接中不会出现旧的报文段 TIME-WAIT状态的危害与优化危害： 占用系统资源：比如文件描述符、内存资源、CPU 资源、线程资源等 占用端口资源：若客户端占满了所有端口资源，就无法对「目的 IP+ 目的 PORT」一样的服务端发起连接了 优化： 调整系统内核参数 tcp_tw_reuse 选项，超过一秒直接被复用，但仅适用客户端 tcp_max_tw_buckets 选项，新关闭的连接数超过该参数时直接关闭 调整短连接为长连接 服务器大量 TIME_WAIT 的原因即服务端主动关闭连接的情况： HTTP 没有使用长连接 任意一方未开启长连接时，大多数Web服务器的实现都是服务端主动关闭连接 HTTP 长连接超时 HTTP 长连接的请求数量达到上限 没有Accept、Listen还能建立TCP连接吗没有 accept() 可以 每一个socket执行listen时，内核都会自动创建一个半连接队列（哈希表）和全连接队列（链表）。 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。 accept方法只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎毫无关系。 没有 listen() 可以 客户端没有半连接队列和全连接队列，但可以通过 一个全局hash 实现自连接或TCP同时打开。例如自连接：客户端在 connect 时会将连接信息放入这个 hash，然后将消息发出，消息经过回环地址重新回到传输层时，根据 IP + 端口 从这个全局 hash 中取出信息，成功连接。 TCP的可靠性如何保证可靠性 基于数据块传输 ：应用数据被分割成报文段再传输给网络层。 对失序数据包重新排序以及去重：将接收到的数据根据序列号排序，并且去掉重复序列号的数据。 校验和 : TCP 将保持它首部和数据的检验和。如果收到段的检验和有差错，TCP 将丢弃这个报文段。 超时重传 : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，就假设为已丢失并进行重传。 流量控制 : 接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题。 拥塞控制 : 当网络拥塞时，减少数据的发送。 TCP的流量控制目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题，所以流量控制是点对点控制。TCP流量控制通过滑动窗口协议实现。 TCP是全双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。 发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。 接收窗：用来标记可以接收的数据大小。 TCP是流数据，发送出去的数据流被分为四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 &#x3D; 已发送未确认部分 + 未发但可发送部分。接收到的数据流分为：已接收 | 未接收但准备接收 | 未接收不准备接收，其中接收窗 &#x3D; 未接收但准备接收部分。 发送窗只有收到接收端的确认时才向右移动，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才向右移动。 TCP的拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，防止路由器或链路过载。拥塞控制是一个全局性的过程，涉及到所有的主机和路由器，以及与降低网络传输性能有关的所有因素。 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 变量，其大小取决于网络的拥塞程度，并且动态变化。发送窗口为拥塞窗口与接收窗口的最小值。 TCP 的拥塞控制采用了四种算法： **慢开始：**一开始先发送小量的数据，从小到大成倍增加拥塞窗口的大小，达到慢开始门限后再采用拥塞避免 **拥塞避免：**每经过一个传输轮次就把 cwnd 加1而不是加倍，这样拥塞窗口按线性规律缓慢增长 **快重传：**所谓快重传，就是使发送方尽快进行重传，而非等计时器超时才重传。接收方即使收到一个失序的报文段也要立即发出重复确认，而不要等到自己发送数据时捎带确认。发送方只要收到三个连续的重复确认，就立即重传对方尚未收到的报文段，而不必等待计时器超时。 **快恢复：**当发送方连续收到三个重复确认时，把慢开始门限和 cwnd 调整为当前窗口的一半（为了预防网络发生拥塞），接下来开始执行拥塞避免算法，而非慢开始算法。因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三个重复确认说明网络状况还可以。 ARQ协议自动重传请求是数据链路层和传输层的错误纠正协议，通过确认和超时机制实现可靠的信息传输。如果在发送后一段时间之内没有收到确认信息（ACK）就会重新发送，直到收到确认或者重试超过一定的次数。 停止等待ARQ协议每发完一个分组就停止发送，等待对方确认，超时未接收到确认就重新发送。 连续 ARQ 协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止之前都正确收到了。 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出已经正确收到的所有分组的信息。中间几条丢失后，由于接收方只能确认前面几条，所以发送方只能将后边几条也重传。这也叫回退N帧，表示需要退回来重传已经发送过的 N 个消息。 TCP和UDP的区别 首靠序 传连景 UDP TCP 是否连接可靠 无连接的不可靠传输，不使用流量控制和拥塞控制 面向连接的可靠传输，使用流量控制和拥塞控制 首部开销 8Bytes：端口号、长度、校验和 20~60Bytes：还包括序列号、确认号、数据偏移量、窗口、紧急指针 是否有状态、有序 无状态、无序 有状态（记录发消息的状态，是否发送、被接收）、有序（乱序排序） 传输速度与方式 传输快，面向报文，有数据边界 传输慢，面向字节流，无数据边界，粘包拆包 连接对象个数 一对一，一对多，多对一和多对多交互通信 一对一通信 适用场景 适用于实时应用（视频会议、直播），包总量较少的通信（DNS） 适用于要求可靠传输（FTP，HTTP） UDP如何保证可靠最简单的方式是在应用层模仿传输层TCP的可靠性传输 添加seq&#x2F;ack机制，确保数据发送到对端 添加发送和接收缓冲区，主要是用户超时重传 添加超时重传机制 TCP和UDP对应的协议TCP： FTP(21)：定义了文件传输协议，控制端口21，数据端口20或协商而定。 SSH(22): 专为远程登录会话和其他网络服务提供安全性的协议。 Telnet(23)：远程登陆协议是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于DOS模式下的通信服务。 SMTP(25)：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。 POP3(110)：它是和SMTP对应，POP3用于接收邮件。 HTTP(80)协议：是从Web服务器传输超文本到本地浏览器的传送协议。 UDP： DNS(53)：用于域名解析服务，将域名地址转换为IP地址 RIP(520)：路由信息协议 TFTP(69)：简单文件传输协议 TCP的其他问题第三次握手的ACK包丢失会发生什么 服务端：第三次的 ACK 在网络中丢失，那么服务端的状态为 SYN_RECV，会根据超时重机制不断重发 SYN+ACK 包，等待客户端确认。如果重发超过指定次数仍未收到应答，服务端自动关闭连接。 客户端：客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以 RST 包（Reset，标示复位，用于异常的关闭连接）响应。此时，客户端知道第三次握手失败。 建立连接后客户端故障会发生什么（服务端同理） 客户端进程崩溃：客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，负责与服务端四次挥手。 客户端主机宕机：不会发生四次挥手，后续要看服务端会不会发送数据： 如果服务端发送数据，将收不到响应报文，服务端的数据报文会超时重传，当重传总间隔时长达到一定阈值后，会断开 TCP 连接； 如果服务端不发送数据，再看服务端有没有开启 TCP keepalive 机制 如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接； 如果没开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。 同一个端口能否重复使用 TCP 和 UDP 可以同时绑定相同的端口吗？可以。TCP 和 UDP 传输协议，在内核中是由两个完全独立的软件模块实现的。当主机收到数据包后，可以根据 IP Header 的协议号字段将数据包传到TCP或UDP模块处理，再根据端口号传给对应的应用程序处理。因此 TCP&#x2F;UDP 各自的端口号也相互独立，互不影响。 多个 TCP 服务进程可以绑定同一个端口吗 &#x2F; 客户端的端口可以重复使用吗？TCP 连接是由四元组 &lt; 源IP地址，源端口，目的IP地址，目的端口 &gt; 唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接，可以重复使用。 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？若连接同一个服务器，四元组的目的IP、目的端口、源IP均已固定，而源端口又都被占用，所以不能建立连接若连接其他服务器，由于目的IP变化，建立的是新TCP连接，就可以复用端口了 同一端口最大 TCP 连接数服务端： 理论：客户端IP数 x 客户端端口数 &#x3D; 2^48 实际：受文件描述符（进程、用户、系统三个级别）、线程并发过多、内存、CPU限制 **客户端：**Chrome 最多允许对同一个 Host 建立六个 TCP 连接，不同的浏览器有区别 TCP粘包和拆包由于UDP有消息保护边界，不会发生粘包拆包问题。 由于TCP面向字节流传输的，没有消息保护边界。一方发送的多个报文可能会被合并成一个大的报文进行传输，这就是粘包；也可能发送的一个报文，可能会被拆分成多个小报文，这就是拆包。 原因： socket缓冲区：数据拷贝到socket的内核缓冲区后可能并不立即发送。 MSS&#x2F;MTU限制：分片，见“MTU和MSS“ Nagle算法：思路是延时处理，发送方一直在囤积数据，只有满足下面任意一个条件，才可以发送数据： 条件一：要等到可用窗口大小 &gt;&#x3D; MSS 并且 可发送数据大小 &gt;&#x3D; MSS 条件二：收到之前发送数据的 ack 回包由于当前带宽充裕，TCP&#x2F;IP协议栈默认关闭Nagle算法 解决： 在每个包的末尾使用固定的分隔符，例如\\n\\r，\\t。 将消息分为头部和消息体，头部中保存整个消息的长度 应用层发送数据时定长发送。 Established 状态收到SYN会怎样一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？ 1. 客户端的 SYN 报文里的端口号与历史连接不同 服务端会通过三次握手来建立新的连接。而旧连接里处于 Established 状态的服务端最后会： 若服务端发送了数据包，此时客户的内核就会回 RST 报文，释放连接。 若服务端一直没有发送数据包，一段时间后由 TCP 保活机制探测并释放掉该连接。 2. 客户端的 SYN 报文里的端口号与历史连接相同 处于 Established 状态的服务端收到乱序的 SYN 后（因为初始序列号是随机数），会回复一个携带了正确序列号和确认号的 ACK 报文（Challenge ACK）。接着，客户端收到 Challenge ACK 发现确认号并不是期望的，就会回 RST 报文，服务端收到后释放掉该连接。 TIME-WAIT 状态收到SYN会怎样合法 SYN：客户端的 SYN 的序列号比服务端期望下一个收到的序列号大 非法 SYN：客户端的 SYN 的序列号比服务端期望下一个收到的序列号要小 收到合法 SYN ，就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着进行建立连接过程 收到非法 SYN ，就会再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端 既然IP层会分片，为什么还需要MSS？ 如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。因为IP层没有超时重传机制，由TCP负责的。若某个IP分片丢失，就无法组装成完整的TCP报文交付到TCP层，也就无法发送确认报文。所以发送方只能重传整个TCP报文。 而经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。 ARP与路由ARP协议每个主机都存有一个ARP高速缓存，存放本局域网上各主机和路由器的IP地址到MAC地址的映射表，使用ARP协议动态维护此表。 ARP工作在网络层中（但OSI模型中划分在链路层），其工作原理是：当主机A想要向主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址: 如果有，可以查出其对应的MAC地址写入帧，然后通过局域网发往此地址 如果没有，就封装一个目的MAC地址为32位全1的帧来广播ARP请求分组。同一个局域网里的所有主机都会收到ARP请求，并检查是否与自己的IP地址匹配，如果不匹配则丢弃ARP请求 如果主机B在局域网中，会把A的IP和MAC地址存入自己的ARP表中，再以单播方式发送ARP响应报文给主机A，其中包含了自己的MAC地址，主机A在收到后进行缓存并向此MAC地址发送 ARP是解决同一个局域网上IP和MAC的映射问题。如果主机B不在一个局域网上，则通过ARP协议找到某个路由器MAC地址，然后把分组发送给这个路由器，从而转发给下一个网络。 路由选择协议 RIP（路由信息协议）：基于距离向量的路由选择协议，应用层协议，使用 UDP 传输数据。它选择路由的度量标准是跳数，跳数大于15就丢弃数据包。仅和相邻路由器交换当前路由器所知道的全部信息，定期发送。 优点：简单、开销小、收敛快 缺点：限制规模、故障收敛慢、子网掩码必须相同(RIP2不用) OSPF（开放最短路由优先）：底层是 Dijkstra 算法，是链路状态路由选择协议，网络层协议，直接IP数据报传输。它选择路由的度量标准是带宽，延迟，计算代价灵活。向本自治系统中所有路由器发送与本路由器相邻的路由器链路状态，但这只是路由器知道的部分信息，只有链路变化才泛洪发送 描述RARP协议RARP是逆地址解析协议，作用是完成MAC地址到IP地址的映射 (请求是广播，应答是单播) 每台设备都有一个独一无二的硬件地址，通常是由设备厂商分配的。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器分配一个IP地址 本地网段上的RARP服务器收到此请求后，检查其RARP列表中是否有该MAC地址对应的IP地址，如果有就返回，否则不做任何的响应 如果一直没有收到RARP服务器的响应信息，则初始化失败 交换机、路由器和网关简介 路由器：多个输入输出端口的专用计算机，其任务是连接不同的网络并完成路由转发。当源主机向目标主机发送数据报时，路由器先检查源主机与目标主机是否连接在一个网络上，如果在一个网络上则直接交付，否则根据路由器转发表将数据报转发给下一个路由器，即间接交付。路由器隔离了广播域 交换机：多个端口的网桥，其任务是连接多个以太网成为更大的以太网。它能隔离冲突域，为每个工作站提供更高的带宽。其原理是，检测数据帧的MAC地址，然后与系统内部的动态查找表进行比较。若数据帧的MAC地址不在查找表中，则将该地址加入查找表中，并将数据帧发送给相应的端口 区别 路由器：工作在网络层，连接不同的广域网形成更大的广域网，连接的是异构网络。根据IP地址转发 交换机：工作在数据链路层，连接以太网形成更大的以太网，同一个网络。根据MAC地址进行转发 网关：网关在网络层以上实现网络互连，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备，使用在不同的通信协议、数据格式的两种系统之间，是一个翻译器 DNSDNS：域名系统，一个域名和IP地址相互映射的分布式数据库，能让用户更方便的访问互联网而不用去记IP地址 域名解析：通过域名得到对应的IP的过程，应用层协议，底层基于UDP和TCP协议 TCP：辅域名服务器定时向主域名服务器查询数据有变化，若有则用TCP传输同步（同步的数据量大） UDP：客户端向DNS服务器查询域名（一般返回不超过512B，UDP省去了三次握手，减小服务器压力） 解析过程 递归查询：主机和本地DNS服务器之间迭代查询：本地DNS服务器和根&#x2F;顶级&#x2F;权限域名服务器之间 查找浏览器、操作系统（host文件）、路由器缓存中有无域名对应的DNS解析结果 查询本地域名服务器中有无缓存，如果没有就直接查询根域名服务器。根域名服务器返回一个顶级域名服务器地址如 .com、.cn 等 本地域名服务器再查询顶级域名服务器。顶级域名服务器返回对应的权限域名服务器的地址（可能有多级） 本地域名服务器再查询权限域名服务器，最终查询出来的IP地址和TTL值（缓存时间）返回给本地域名服务器 本地域名服务器缓存IP映射关系，再把解析结果返回给本地电脑，缓存在本地系统缓存中 PINGPing的工作原理ping 命令执行的时候，源主机会发送 ICMP 回送请求消息，目的主机返回 ICMP 回送响应消息。在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了则说明可达，此时源主机会用当前时刻减去该数据包最初从源主机上发出的时刻，得到 ICMP 数据包的时间延迟。 几个地址的区别 127.0.0.1：回环地址，与ping本机IP地址的效果一致 localhost：是域名，默认映射为 127.0.0.1 0.0.0.0 在IPV4中，0.0.0.0地址无效，因此不能ping通。 在服务器中，若一个服务监听的地址是0.0.0.0，则指的是本机上的所有IPV4地址。例如一个主机有两个IP地址，则通过这两个ip地址都能够访问该服务。 在路由中，0.0.0.0表示的是默认路由。 为什么断网还能Ping通127.0.0.1、本机地址到了网络层转发时，发现目标 IP 是回环地址，就不会送到”真网卡”的ring buffer中，而是选择本地网卡，它会把数据推到一个链表后就会触发一个软中断，由内核线程会去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。因此消息发到这个地址上就不会出网络，在本机打个转就又回来了。 HTTPGET和POST的区别使用区别： GET使用URL或Cookie传参，有长度限制，而POST将数据放在BODY中可以很大 POST比GET安全，因为数据在地址栏上不可见（但在 HTTP 下都不安全，因为明文传输可以被抓包） GET产生一个TCP数据包，将 http header 和 data 一并发送出去，服务器响应200 ok (返回数据)；POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，再发送data，服务器响应200 ok (返回数据)。不过 POST 分开发送是部分浏览器或框架的请求方法，并不是必然行为 GET请求会被浏览器主动缓存，而POST不会，除非手动设置 本质区别： GET是幂等的，而POST不是幂等的。幂等性是指一次和多次请求某一个资源应该具有同样的副作用，即对同一URL的多个请求应该返回同样的结果。所以不应该 GET 请求做数据的增删改操作，因为 GET 请求是幂等的，在网络不好的隧道中会尝试重试，有重复操作的风险。 HTTP状态码 301：(永久移动) 请求的网页已永久移动到新位置。服务器返回此响应时，会自动将请求者转到新位置 302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求 401：(未授权) 请求要求进行身份验证 403：(禁止) 服务器收到请求，但是拒绝提供服务 404：(未找到) 服务器找不到请求的网页 409：(Conflict) 表示请求的资源与资源的当前状态发生冲突 410：(Gone) 资源被永久性的删除 503：(服务不可用) 无法使用服务器，由于超载或进行停机维护，一般是暂时的 504：(网关超时) 服务器作为网关，未及时从上游服务器接收请求 HTTP请求方式 序号 方法 描述 1 GET 请求指定资源并返回主体。 2 HEAD 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 3 POST 向指定资源提交数据进行处理请求，数据被包含在请求体中。可能会创建资源或已有资源修改 4 PUT 提交数据并替代已有资源，若不存在则创建（必须明确知道要操作的对象，幂等性） 5 DELETE 请求服务器删除指定资源 6 CONNECT HTTP&#x2F;1.1 协议中预留给能够将连接改为管道方式的代理服务器。 7 OPTIONS 允许客户端查看服务器的性能 8 TRACE 回显服务器收到的请求，主要用于测试或诊断 9 PATCH 是对 PUT 方法的补充，用来对已知资源进行局部更新 HTTP报文格式请求格式： 请求行（请求方法+URL+协议版本） GET /sample.jsp HTTP/1.1 请求头部 空行 请求主体 响应报文： 状态行（协议版本+状态码+状态码描述） HTTP/1.1 200 OK 响应首部 空行 响应主体 HTTP1.0和HTTP1.1的区别 长连接：HTTP1.1 默认开启Connection：keep-alive，支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，弥补了HTTP1.0每次请求都要创建连接的缺点。 缓存处理：HTTP1.1 则引入了更多的缓存控制策略，提供了更多可选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1.1则在请求头引入了range头域，允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 状态响应码：在 HTTP1.1 中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 Host头处理：在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的URL并没有传递主机名。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，它们共享一个IP地址。所以 HTTP1.1 的请求消息和响应消息都应支持Host头域，请求消息中如果没有Host头域会报 400 错误。 HTTP2相比HTTP1.1的改进 头部压缩：如果同时发出多个请求且header相似，协议会压缩帮助消除重复的部分 二进制格式：HTTP2 不像 HTTP1.1 的纯文本形式，而是采用了二进制格式，增加了数据传输的效率。 并发传输：HTTP1.1 基于请求-响应模型，同一个连接中要完成一个事务才能处理下一个事务，容易阻塞。而 HTTP2 引入了帧、消息和数据流，每个请求&#x2F;响应为消息、每个消息被分成若干帧，各个帧在流和连接上独立传输，到达之后再组装成消息。HTTP2 将多个流复用在一条 TCP 连接，可以并行交错地发送请求和响应。 服务器推送：服务端不再是被动地响应，可以主动向客户端发送消息。 HTTP长连接和短连接 HTTP1.0 默认使用短连接。浏览器和服务器每进行一次HTTP操作就建立一次连接，任务结束就中断连接。如果客户端请求频繁的话，会在TCP的建立和释放上浪费大量的时间 HTTP1.1 起默认使用长连接，会在响应头加入：Connection:keep-alive。当一个网页打开完成后，客户端和服务器之间传输HTTP数据的TCP连接不会关闭，等下次时还会用这条连接，从而节省TCP连接和释放的时间。Keep-Alive不会永久保持连接，它的保持时间可以在不同的服务器软件中设定。实现长连接要客户端和服务端都支持长连接。 HTTP和TCP的Keep-Alive区别 HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由应用程序实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求&#x2F;应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。 TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由内核实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核就会发送探测报文，若对方不在线则关闭该连接。 HTTP和HTTPS的区别 HTTP HTTPS 连接很简单，无状态 SSL+HTTP协议构建的可加密传输、身份认证的协议 端口 80 443 是否证书 不需要 需要 安全性 信息无加密传输，安全性较差 采用对称加密，安全性高对称加密的密钥是用服务器证书进行非对称加密的 资源消耗 响应快，资源消耗较少 由于加密处理，响应慢、资源消耗多 协议 运行在TCP协议之上 运行在SSL协议之上，SSL运行在TCP协议之上 HTTPS的原理&#x2F;流程（SSL是怎么保证安全的） 客户端请求 HTTPS 网址连接443 端口，将 SSL 协议版本的信息发送给服务端 采用 HTTPS 协议的服务器必须要有一套数字 CA 证书。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏，公钥则是附带在证书的信息中，可以公开。证书本身也附带一个证书电子签名，用来验证证书的完整性和真实性，防止被篡改 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等 客户端解析证书并对其进行验证。如果证书的机构不可信、域名不一致或证书过期，就会向访问者显示警告；如果证书没问题，客户端就会从证书中取出服务器的公钥A 双向认证还需： 客户端将客户端公钥证书发送给服务器端 服务器端使用根证书解密客户端公钥证书，拿到客户端公钥 客户端发送自己支持的加密方案，服务器端选择一个，并使用客户端的公钥加密后发送给客户端 客户端使用自己的私钥解密加密方案 客户端生成一个随机码 KEY，并使用公钥A加密发送给服务器，作为后面对称加密的密钥 服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，防止了对称加密的密钥泄露，接下来就可以用对称加密进行通信了 服务器使用密钥 (随机码 KEY) 对数据进行对称加密并发送给客户端，客户端使用相同的密钥解密 双方使用对称加密传输所有数据 HTTP缓存 强制缓存：只要浏览器判断缓存没有过期，就直接使用浏览器的本地缓存，而不需要再发送请求获取资源。决定是否使用缓存的主动性在于浏览器。 协商缓存：协商缓存是一种服务端的缓存策略，即通过服务端来判断是不是可以被缓存。接收到浏览器请求之后，服务器如果判断资源一致，则返回 304 告知使用浏览器缓存，否则返回 200 和最新的资源 优先级：强制缓存 &gt; 协商缓存 HTTPS的优缺点优点： 使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器 HTTPS协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全，可防止数据被窃取、改变，确保完整性。 HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。 缺点： HTTPS 比 HTTP 的响应时间、耗电量、服务器资源更高，成本更高。 安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用，依然可能遭受中间人攻击。 Cookie与Session什么是CookieHTTP 协议是无状态的，所以HTTP1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。 Cookie 曾一度用于客户端数据的存储，但现在随着现代浏览器开始支持各种各样的存储方式（本地存储和会话存储），Cookie 渐渐被淘汰。 用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 什么是SessionSession 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。 这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。 Session 可以存储在服务器上的文件、数据库或者内存中，也可以存储在 Redis 这种内存型数据库中，效率更高。 Cookie和Session的工作原理用户第一次请求服务器时，服务器创建 Session ，请求返回时将 SessionID 返回给浏览器，浏览器将 SessionID 和对应的域名存入到 Cookie 中。 用户以后访问服务器的时候，自动判断此域名下是否存在 Cookie 信息，如果存在就将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息。如果没有找到说明用户没有登录或者登录失效，否则说明用户已经登录可执行后面操作。 SessionID 是连接 Cookie 和 Session 的桥梁，大部分系统也是根据此原理来验证用户登录状态。所以不能产生一个容易被猜到的 SessionID 值，防止被攻击者轻易获取。 Cookie和Session的区别 作用范围不同，Cookie 保存在客户端，Session 保存在服务器端。 存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型。 存储大小不同，单个 Cookie 不能超过 4K，Session 可存储数据远高于 Cookie。 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。 隐私策略不同，Cookie 存储在客户端容易被窃取，Session 存储在服务端安全性要好一些。 概念了解SQL注入在用户输入的字符串中加入 SQL 语句，如果程序中忽略了检查，这些注入的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。 例如，输入用户名为 alice&#39;-- 或 alice&#39; or &#39;1&#39;=&#39;1 跳过密码检查 1234567-- 原语句SELECT * FROM users WHERE username=&#x27;alice&#x27; and password=&#x27;any&#x27;-- SQL注入后程序将执行以下查询SELECT * FROM users WHERE username=&#x27;alice&#x27;--&#x27; and password=&#x27;any&#x27;SELECT * FROM users WHERE username=&#x27;alice&#x27; or ‘1&#x27;=‘1&#x27; and password=&#x27;any&#x27;-- 两条查询均等同于如下，跳过了密码SELECT * FROM users WHERE username=&#x27;alice&#x27; 避免： 限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。 对进入数据库的特殊字符转义处理。 提供参数化查询接口，不直接使用原生SQL。 Dos攻击拒绝服务攻击。发送大量恶意数据包，占用目标主机的资源，导致需要正常访问的数据包得不到及时的处理，网络延迟过高、甚至无法响应。 DDoS攻击分布式拒绝服务攻击，将多个计算机联合起来作为一个攻击平台发起攻击，原理、检测和预防同SYN洪泛 SYN洪泛攻击利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源。 原理： 在 TCP 三次握手过程中，服务器发送完 [SYN/ACK] 包、收到 [ACK] 包之前称为半连接，此时服务器处于 SYN_RECV（等待客户端响应）状态。如果接收不到到客户端的 [ACK]，就会不断重发请求。 SYN 攻击的攻击者向服务器不断地发送 [SYN] 包，服务器产生大量半连接等待客户的确认，占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。 检测：服务器上有大量的半连接且源 IP 地址是随机的，则很可能是 SYN 攻击。 预防： 限制同时打开SYN半链接的数目 缩短SYN Time out 时间 通过防火墙、路由器等过滤网关防护 CSRF攻击跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。比如攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。 解决：token验证，服务器生成一个随机字符串保存在session中，并作为token返回给客户端，以隐藏的形式保存在客户端中，客户端每次请求都会带着这个token，服务器根据该token判断该请求是否合法 XSS攻击跨站点脚本攻击，指攻击者通过篡改网页，嵌入恶意脚本程序，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式 防范：核心是对输入的数据做过滤处理。限制字符串输入的长度，对HTML转义处理，将其中的”&lt;”,”&gt;”等特殊字符进行转义编码 RTO和RTT RTO：重传间隔，每次翻倍，重传次数到达上限之后停止重传 RTT：往返时延 URI和URL URI：Uniform Resource Identifier ，统一资源标志符，可以唯一标识一个资源。 URL：Uniform Resource Locator ，统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 MTU和MSS MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。 MSS：maximum segment size，最大分节大小，为TCP数据包传输的最大数据分段大小，一般由对端TCP通知。MSS值为MTU值减去 IPv4 Header（20B）和 TCP header（20B）得到","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"Redis","slug":"Archive/Redis","date":"2023-04-01T15:45:13.000Z","updated":"2025-03-06T09:15:29.196Z","comments":true,"path":"2023/04/01/Archive/Redis/","permalink":"http://example.com/2023/04/01/Archive/Redis/","excerpt":"","text":"Redis线程模型Redis基于Reactor模式开发了自己的网络事件处理器，也就是文件事件处理器。它使用IO多路复用技术，同时监听多个套接字，当套接字的可读或者可写事件触发时，就会调用相应的事件处理函数。 Redis 使用的IO多路复用技术主要有：select、epoll等，会根据不同的操作系统按不同的优先级选择。 文件事件处理器有四个组成部分：套接字、I&#x2F;O多路复用程序、文件事件派发器以及事件处理器。 文件事件是对套接字操作的抽象，对应 accept、read、write、close 等操作。I&#x2F;O多路复用程序负责监听多个套接字，并把产生事件的套接字传递给文件事件派发器。尽管文件事件可能并发出现，但套接字都会放到同一个队列里，然后由文件事件处理器以有序、同步方式处理，也就是处理就绪的文件事件。 Redis 6.0 之后引入多线程为了提高网络IO读写性能，因为 Redis 的瓶颈主要受限于内存和网络。但是执行命令仍然是单线程顺序执行，因此不用担心线程安全问题。 Redis为什么快 redis数据都保存内存当中，绝大部分请求都是基于内存 服务器进程大部分时间是单线程操作，避免上下文切换和加锁 有高效的底层数据结构，为优化内存，对每种类型基本都有两种底层实现方式 采用的是非阻塞IO多路复用 Redis对象类型string：二进制安全，可以存储任何类型的数据（字符串、整数、浮点数、图片、序列化对象） 简单动态字符串SDS list： 压缩列表 双端链表：链表结点嵌套了字符串对象。 hash：是一个 String 类型的键值对的映射表，特别适合用于存储对象，可以直接修改对象中的字段值。 压缩列表：存入时将键结点、值结点依次相邻压到列表尾 字典：键值对直接使用字典键值对保存。 set：去重的集合 整数集 字典：将集合元素作为键，值设置为nil zset：集合元素按 score 有序排列，还可以通过 score 的范围来获取元素的列 压缩列表：集合元素用相邻的节点依次保存元素成员和权重。 字典+跳表：字典可以实现O(1)复杂度查找，跳表可以实现范围型操作。 Redis底层数据结构SDS简单动态字符串常用在缓存、计数、限速等场景，底层结构包含 free、len、buf[] 字段 len：可以获取字符串长度、防止溢出，保证二进制安全\\0 free：预分配和惰性释放空间，可以减少修改字符串时的内存重分配 链表用于列表键包含元素数量较多、元素都是长字符串时，双端链表，包括了头尾结点和长度 字典 用于实现map类型，由两个哈希表构成，每个哈希表里包含一个数组，数组的每个slot连接若干个哈希表结点KV 哈希算法：MurmurHash，即使输入的键规律也能得到很好的随机分布性，计算速度快 REHASH：负载因子&gt;1且没执行bgsave或bgrewriteof || 负载因子&gt;5： 为字典的ht[1]哈希表分配内存空间 扩展大小为首个大于 ht[0].used*2 的$2^n$，收缩大小为首个大于 ht[0].used 的$2^n$ (便于key映射索引时用&amp;替换%) 将存储在ht[0]中的数据迁移到ht[1]上，重新计算键的哈希值和索引值。包括两种方式：渐进式HASH 和 定时HASH 清空ht[0]，再交换ht[0]和ht[1]的值 渐进式HASH 增删改查操作的时候都会检查 rehashidx 参数，校验是否正在迁移，如果正在迁移那么会调用到 dictRehash(dict *d, int n) 函数。这里 n&#x3D;1，即只迁移 1 个桶 为 ht[1] 分配空间，此时字典同时存在两个哈希表 将 rehashidx 置为 0，rehash 工作正式开始 期间每次对字典执行增删改查操作时，程序在执行指定操作之外，还会将 ht[0] 在 rehashidx 索引上的所有键值对rehash 到 ht[1]，然后 rehashidx++ 最终 ht[0] 的所有键值对最终会全部移动到 ht[1]，此时程序会将 rehashidx 设为 -1表示已完成 定时HASH主线程会默认每间隔 100ms 执行一次迁移操作，同样调用 dictRehash(dict *d, int n)，这里 n&#x3D;100，即迁移100个桶的数据，并限制超时时间为 1ms REHSH期间：字典同时持有两个哈希表，此时的访问将按照如下原则处理： 插入键值对直接保存到ht[1]中，保证了 ht[0] 中的已经被清空的单向链表不会新增元素 删除、修改、查找等其他操作，会在两个哈希表上进行，即程序先尝试去ht[0]中访问要操作的数据，若不存在则到ht[1]中访问，再对访问到的数据做相应的处理。 跳跃表 跳跃表的查找复杂度为平均O(logN)，最坏O(N)，效率堪比红黑树但实现更简单。跳跃表是在链表的基础上，通过增加索引来提高查找效率的。 跳跃表是从有序链表中选取部分节点，组成一个新链表，并以此作为原始链表的一级索引。再从一级索引中选取部分节点，组成一个新链表，并以此作为原始链表的二级索引，以此类推。 跳跃表在查找时，优先从高层开始查找，若next节点值大于目标值或为NULL，则从当前节点下降一层继续向后查找，这样便可以提高查找的效率了。 跳表结点的底层结构包括一个元素数组、前进后退双向指针、层数（跳表查询过程中跨度）。插入跳表结点时会随机生成一个层数值以保证查询效率。 整数集合用于保存整数值的集合，整数不重复且类型可以不同，底层结构只包括编码格式、长度、底层数组三个字段。 升级操作：由于集合中可以插入不同类型整数，当插入更长类型时会触发升级，首先将底层数组扩容到相应的大小，再依次将元素转换成新类型，最后插入新元素。 压缩列表 用于节约内存的一种线性数据结构，由一系列特殊编码的连续内存块组成，列表中可以包含多个节点，每个节点可以保存字节数组或者整数值，每个节点都有一个属性记录前一个节点的长度。 Redis持久化RDB快照把内存中的数据库状态以快照形式压缩保存到一个二进制文件。创建快照之后，可以对快照进行备份，可以复制到其他服务器从而创建具有相同数据的服务器副本，还可以将快照留在原地以便重启服务器的时候使用。 快照需要保存全部数据，可能导致阻塞主线程运行，redis提供了两种方式： save：同步保存，阻塞redis主线程 bgsave：开一个子进程来单独生成RDB，只有fork时主进程会短暂阻塞，之后就能正常处理请求 bgsave子进程是由主进程fork出来的：通过 fork 创建的子进程能够获得和父进程完全相同的内存空间（内存数据相同）。另外，创建子进程采用了写时拷贝，不会立刻触发大量内存的拷贝，只有父进程对内存修改时，才会复制相应的内存页 bgsave子进程会不断读取主线程的内存数据写入RDB文件中 如果主线程需要修改一块数据，这块数据会被复制出一份副本，主线程在副本上修改，bgsave子进程读取原来的数据写入RDB文件 优点：生成的二进制文件体积小，恢复数据的速度非常快 缺点：bgsave需要执行fork操作创建子进程，属于重量级操作，不宜频繁执行，所以RDB无法实时持久化 AOF只追加文件AOF日志中记录的是Redis收到的每一条命令，这些命令都是以文本的形式保存的。 写后日志 AOF先执行命令再记录日志 ①避免检查开销，后记录日志不用检查命令的正确性 ②不会阻塞当前的写操作 刷盘机制 AOF存在一定风险：如果执行完命令还没保存AOF就宕机就会数据丢失，并且写AOF可能堵塞下一个命令执行，为此AOF写入磁盘机制有三种： Always：每次执行完命令立即写回，基本不丢失数据 Everysec：每次执行完命令，先把日志写入AOF缓冲区，每隔一秒刷盘，宕机也只会丢失1秒的数据 No：只写入AOF缓冲区，由OS决定什么时候刷盘，丢失数据多 AOF重写 AOF文件越来越大，继续可能导致写入效率变低、恢复过程变长、超过文件大小限制，需要重写机制。 AOF重写就是根据所有的键值对创建一个新的AOF文件，可以减少大量的文件空间。因为AOF对于命令的添加是追加的方式，如果某个键值被反复更改会产生冗余数据，因此在重写的时候过滤掉这些指令： bgrewriteaof 触发重写，主进程 fork 子进程，防止主进程阻塞无法提供服务 子进程遍历 Redis 内存快照中数据写入临时 AOF 文件，同时会将新的写指令写入缓冲区 子进程写入临时 AOF 文件完成后，主进程会将缓冲区中的写指令数据写入临时 AOF 文件中 主进程使用临时 AOF 文件替换旧 AOF 文件，完成重写 优点：与RDB持久化可能丢失大量的数据相比，AOF持久化的安全性要高很多。使用everysec选项可以将数据丢失的时间限制在1秒之内。 缺点：AOF文件存储的是协议文本，体积更大、恢复速度更慢。AOF在进行重写时也需要创建子进程，在数据库体积较大时将占用大量资源，会导致服务器的短暂阻塞。 混合持久化两次RDB快照期间的所有命令操作由AOF日志文件进行记录。 RDB快照不需要很频繁的执行，可以避免频繁fork对主线程的影响，还能将丢失数据的时间限制在1s之内 AOF日志只记录两次快照期间的操作，不用记录所有操作，防止文件过大导致重写开销 Redis数据同步Redis其实采用了主从库的模式，以保证数据副本的一致性，主从库采用读写分离的方式：从库和主库都可以接受读操作，主库接收写操作，然后同步到从库 主从同步第一次同步： 从库向主库发送 sync 命令代表进行数据同步，主库执行 bgsave 生成 RDB 文件，并发送给从库 从库接收数据，清空当前数据，并加载RDB文件。过程中主库不会阻塞，仍然可以接收数据，将写操作记录到 replication buffer 中 最后，主库把 replication buffer 中的修改操作发给从库，从库执行这些操作，实现主从同步 如果从库太多，为了减少主库过多的fork阻塞主线程，可以采用主-从-从模式，选择一个从库用来同步其他从库的数据，以减少主库生成RDB文件和传输RDB文件的压力 完成第一次同步后，双方之间就会维护一个 TCP 长连接。后续通过这个连接继续将写命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。 若网络断开又恢复，会采用增量复制的方式继续同步，只会把网络断开期间主服务器的写命令同步给从服务器。 缺点： 没有自动容错功能，需要人工干预 难以在线扩容 主机宕机且有部分数据未同步到从库时，切换IP后会有数据不一致问题 Sentinel机制为了解决主从模式下主库挂的问题，用哨兵机制实现主从库自动切换。哨兵是一个独立的进程，通过发送命令，等待Redis服务器响应，从而监控多个 Redis 实例。 监控：哨兵周期性地给所有的主从库发送 PING 命令，检测是否仍在运行。如果 Master 一段时间没有响应，这个实例会被哨兵标记为主观下线，当足够数量的哨兵确认下线时，该 Master 会被标记为客观下线 选主：主库挂了之后，哨兵需要按照一定的规则选择一个从库，并将他作为新的主库 通知：哨兵会把新主库的连接信息发给其他从库，让它们和新主库建立连接，并进行数据复制；同时哨兵也会将新主库的消息发给客户端 Redis集群 深入分析Cluster 集群模式 为什么要用Cluster 单机的CPU、内存、连接数、计算力都是有极限的，不能无限制的承载流量的扩增 当数据量过多的情况下，RDB持久化时响应会变慢，因为fork会阻塞主线程，数据量越大阻塞时间越长 数据分片原理一致性哈希 哈希算法是对节点的数量取模，而一致哈希算法是对固定的 2^32 取模，将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。查找数据时，将key的映射位置往顺时针的方向的找到第一个节点，就是存储该数据的节点。 优点：增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。 缺点：不保证节点能够在哈希环上分布均匀，会有大量的请求集中在一个节点上。 解决：将真实节点映射成多个虚拟节点，再将虚拟节点映射到哈希环上。节点数量多了后，分布就相对均匀了。 哈希槽Redis集群将数据划分为 16384（2^14）个 slots，每个实例节点将管理其中一部分的槽位，并记录各自的槽位信息。节点的数据量可以不均匀，性能好的可以多分担一些压力。 集群之间的信息通过 Gossip协议 广播，因此每个实例都知道整个集群的 slots 分配情况以及映射信息。 每个 key 映射到一个固定的 slot，slot = crc16(key) % 16384，这样不论节点数量如何变化，key所对应的 slot 是不变的。 客户端访问过程： 连接任一实例，获取到 slots 与节点的映射关系并缓存在本地 对 key 经过 CRC16 计算后取模，得到 slot id 通过 slot id 定位到实例，发送请求 数据复制Cluster 具备 Master 和 Slave 模式，Slave 节点是通过主从方式同步主节点数据。节点之间保持TCP通信，当Master发生了宕机， Redis Cluster 自动会将对应的 Slave 节点选为 Master，来继续提供服务。与纯主从模式不同的是，主从节点之间并没有读写分离，Slave 只用作 Master 宕机的高可用备份，所以更合理来说应该是主备模式。 故障检测与转移Redis 集群的节点采用 Gossip 协议来广播信息，每个节点都会定期向其他节点发送 ping 命令，如果超时未回复就认为节点失联了，标记为主观下线。对于主节点A，如果超过半数主节点都将其标记为了主观下线，则标记成客观下线，并向整个集群广播节点A已经下线，开始进行主从切换： 如果有多个 slave 节点，先通过选举投票竞选出新的 Master 新的主节点将下线主节点的 slots 指派给自己 新的主节点向集群广播一条 PONG 消息，让其他节点知道自己变成了主节点，并且接管了下线节点负责的slots 新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成 缓存各种问题缓存雪崩缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。 设置不同的失效时间比如随机设置缓存的失效时间 缓存击穿缓存击穿中，请求的 key 对应的是 热点数据 ，该数据在数据库中但不在缓存中（已经过期），导致瞬时大量的请求直接打到了数据库上 设置热点数据永不过期或者过期时间比较长。 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力 缓存穿透数据库和缓存内都没有数据导致缓存永远不能命中，导致每次请求都会传到数据库加大压力。 缓存空对象：即使数据库不命中也把返回的空对象缓存起来，并设置一个较短的过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源 需要更多的空间存储很多空值的键 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，影响一致性 布隆过滤器：用很低的代价估算出数据是否真实存在。初始化一个大的位数组，添加key时通过不同hash计算出位数组中的不同的位置置为1；查询时检查key的hash值所对应的位点是否都被置1，若任意一个位点未被置1，则代表数据不存在，否则极有可能存在（也有可能其他的key运算导致该位为1）。 数据相对固定即实时性较低 数据过期策略定期删除：默认是每隔 100ms 就随机抽取（非全表）一些设置了过期时间的key，检查如果过期就删除。定期删除可能会导致很多过期 key 到了时间并没有被删除掉 惰性删除：获取key时先判断是否过期，若过期则删除。这种策略则是会一直占用内存资源，若已经过期key未被使用，则会一直保存在内存中 内存淘汰机制：若均没被删除，内存占用越来越高 volatile-lru、volatile-lfu、volatile-ttl、volatile-random allkeys-lru、allkeys-lfu、allkeys-random no-eviction 缓存双写一致性先删缓存再写数据库：删完缓存、写入数据库前，另一个线程访问数据库后把旧值又写入了缓存，脏数据 先写数据库再删缓存：如果删缓存前线程崩溃，则脏数据 延时双删策略：在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。具体步骤是： 先删除缓存 再写数据库 休眠500毫秒（根据具体的业务时间来定） 再次删除缓存。 分布式锁基于SET命令Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：key 不存在 -&gt; 插入成功 -&gt; 表示加锁成功； 加锁: SET lock_key unique_value NX PX 10000 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以带上 NX 选项来实现加锁； 锁变量需要设置过期时间，以免客户端发生异常，导致锁无法释放，所以用 EX&#x2F;PX 选项设置过期时间； 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时误释放，所以用 unique_value 区分来自不同客户端的锁操作； 解锁: DEL lock_key 要先判断锁的 unique_value 是否为加锁客户端，是的话才删除 解锁有两个操作，因此需要 Lua 脚本来保证解锁的原子性 缺点 超时时间不好设置：太长影响性能，太短无法保护共享资源。可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程去判断锁的情况，在锁快失效时续约加锁，当主线程执行完成后 主从复制模式是异步复制的，导致分布式锁不可靠。如果在 Redis 主节点获取到锁后，还没同步到其他节点就宕机了，此时新的主节点依然可以获取锁，违背锁的唯一性原则。 RedLock算法它是基于多个 Redis 节点的分布式锁，推荐至少部署 5 个 Redis 节点，它们都是主节点，之间没有任何关系。 Redlock 算法的基本思路，是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，就认为客户端成功地获得分布式锁，否则加锁失败。 这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。 加锁: 以相同的 KEY 向 N 个节点加锁，如果超过一半节点获取到了锁，且总耗时没超过锁有效时间，则认定加锁成功。之后要重新计算锁的有效时间，减去获取锁的耗时。 解锁: 向所有的节点发送 DEL 命令，和单节点一样，执行释放锁的 Lua 脚本即可。","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"MySQL","slug":"Archive/Mysql","date":"2023-03-30T12:59:04.000Z","updated":"2025-03-06T09:01:58.040Z","comments":true,"path":"2023/03/30/Archive/Mysql/","permalink":"http://example.com/2023/03/30/Archive/Mysql/","excerpt":"","text":"SQL与NoSQL关系型数据库采用了关系模型来组织数据， 关系模型可以简单理解为二维表格模型，而一个关系型数据库就是由二维表及其之间的关系组成的一个数据组织 优点：①容易理解，二维表比网状模型贴近逻辑世界 ②使用方便，支持SQL复杂查询 ③易于维护，通过完整性降低了数据不一致和数据冗余 ④支持事务 ⑤数据存在磁盘中可靠 实体完整性 每个元组唯一、可识别，不允许主键空/重复引用完整性 元组间的关联，外键为参照的某个元组主键或空用户定义完整性 指明属性取值范围，防止和应用语义矛盾 缺点：①表结构固定、数据不易扩展 ②海量数据情况下读写效率低 ③ 高并发读写能力差，数据库连接数、IO受限 非关系型数据库通常指数据以对象的形式存储在数据库中，而对象之间的关系通过每个对象自身的属性来决定，常用于存储非结构化的数据。分为键值、列族、文档、图形数据库 优点：①支持多种存储格式：kv、图片、文档 ②速度快、效率高，可以用内存作为载体 ③数据不耦合易扩展 ④可以实现数据分布式处理 缺点：①不支持SQL学习使用成本高 ②没有事务处理，无法保证数据完整性和安全性 事务隔离级别 隔离级别 特点 脏读 不可重复读 幻读 READ UNCOMMITTED 事务没提交，其他事务就能看到修改的数据 可能 可能 可能 READ COMMITTED 只能看到其他已提交事务的结果，不能看到正在执行的事务修改 不可能 可能 可能 REPEATABLE READ 事务执行中看到的数据和启动时一致 不可能 不可能 可能 SERIALIZABLE 强制事务串行执行，避免幻读，但大量加锁性能低下 不可能 不可能 不可能 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 RC 与 SQL 标准不同的地方在于：InnoDB 在默认的隔离级别 RR 下使用的是Next-Key Lock 锁算法，能避免幻读，已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE 隔离级别。 MVCCMVCC 是 InnoDB 实现隔离级别的一种方式，用于实现读已提交和可重复读这两种隔离级别。而读未提交级别总是读取最新的数据行，无需使用 MVCC。可串行化级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。优点是执行普通的SELECT操作时通过访问记录的版本链，使不同事务的读-写操作并发执行，不用加锁 快照读与当前读在MVCC并发控制中，读操作可以分成两类： 快照读：读取的是快照生成的数据，如简单select操作。不用加锁，通过undo log和MVCC访问历史版本数据。 在RR下，事务启动时会生成readView直至事务提交，所以之后其它事务所做的更新版本对当前事务并不可见，实现了可重复读 在RC下，每次select都会生成readView，所以事务期间多次读一个数据可能不一致 当前读：读取的是记录的最新版本，如插入&#x2F;更新&#x2F;删除操作。要对读的记录上锁，保证其他事务不会再并发修改这条记录，除了lock in share mode / for update 加读锁，其他都加写锁 原理和实现 隐藏字段：每行数据都有隐藏字段，包含了最后一次插入&#x2F;更新事务DB_TRX_ID、指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。 ReadView：在进行快照读的时候生成的记录快照，保存当前系统中活跃的事务ID，可以解决可见性问题。当要读取记录行的时候，会将该记录行的 DB_TRX_ID 与 Read View 进行比较，判断是否满足可见性条件，否则通过undo log将数据恢复到指定版本： 记录行事务ID &lt; up_limit_id（ReadView中最小的事务ID）：该事务在创建 ReadView 前已经提交了，可见 记录行事务ID &gt; low_limit_id（ReadView时刻下一个要分配的事务ID）：该事务在创建 ReadView 之后才开启，不可见 up_limit_id &lt; 记录行事务ID &lt; low_limit_id：判断是否在活跃事务ID列表中，不在说明该事务已经提交了，可见，否则不可见 解决幻读如果其它事务在当前事务查询范围内插入就会产生幻读，InnoDB存储引擎在 RR 级别下通过 MVCC和 Next-key Lock 来解决幻读问题： 快照读：通过 MVCC 避免幻读。RR 隔离级别只会在事务第一次查询生成 Read View ，直至事务提交。所以在生成 Read View 之后其它事务所做的插入版本对当前事务并不可见 当前读：通过 Next-key Lock 避免幻读Record Locks + Gap Locks，前者锁定一个记录上的索引项来锁定当前记录，后者锁定索引之间的间隙来防止其它事务在查询范围内插入数据。当查询的索引含有唯一属性的时候，Next-Key Lock 会降级为Record Lock 引擎MyISAM适合：插入不频繁、查询非常频繁，大量SELECT InnoDB适合：表更新和查询都频繁， 大量INSERT或UPDATE；可靠性要求比较高，或者要求事务 MyISAM 只支持表级锁，InnoDB 支持行级别的锁。 MyISAM 不提供外键、事务、MVCC，InnoDB 支持。 MyISAM 索引文件和数据文件分离，而 InnoDB 数据文件本身就是按 B+Tree 组织的一个索引结构，叶节点 data 域保存了完整的数据记录。 MyISAM 不支持崩溃后恢复，而 InnoDB 支持。 InnoDB 的性能比 MyISAM 更强大。 索引 索引是Xxx数据结构、加快查询 -&gt; 不同引擎实现不同 -&gt; 优缺点 -&gt; 类型 -&gt; 使用注意事项索引原理（数据文件组织成B+Tree） -&gt; 主索引与辅助索引 -&gt; B+Tree是啥 -&gt; 与Hash对比 索引是一个单独的、存储在磁盘上的数据库结构，包含着对数据表里所有记录的引用指针。使用索引可以提高查询速度，快速找出在某个或多个列中为特定值的行。索引是在存储引擎中实现的，每种存储引擎的索引都不一定完全相同。MySQL中索引类型有 B+TREE 和 HASH，InnoDB存储引擎只支持 B+TREE 索引。 优点： 创建唯一索引可以保证表中每一行数据的唯一性。 加快查询速度、查询中分组和排序的时间。 缺点： 创建和维护索引要耗费时间 索引需要占磁盘空间 索引类型 普通索引：仅加速查询 唯一索引：列值唯一（可以有null） 主键索引：列值唯一（不可以有null）+ 表中只有一个 组合索引：多列值组成一个索引，专门用于组合搜索 全文索引：对文本的内容进行分词，进行搜索 覆盖索引：select的数据列只用从索引中就能够取得，不必回表查询数据行 聚集索引：索引和数据一起存放，如InnoDB的主键索引。查询速度非常快，比非聚簇索引少了一次读取数据的 IO 操作；但更新代价大，数据被修改导致对应的索引也会被修改 非聚集索引：索引和数据分开存放，如InnoDB的辅助索引、MyISAM 的主键&#x2F;非主键索引。更新代价小，因为叶子节点不存放数据（指针或主键），但是可能会二次查询(回表) 索引注意事项 尽量用在经常搜索、排序的列上，长期不用及时清理 尽量用覆盖索引，减少 select * 能减少回表次数 多个单列索引每次查询只能使用一个，换成组合索引 索引失效： 组合索引不遵循“最左前缀匹配”原则、含NULL 在索引列上计算&#x2F;函数、不等于（&gt;&lt; !&#x3D;） 使用like &quot;%value%&quot; or连接 字符串不加单引号可能隐式转换 索引原理InnoDB中表数据文件本身就是按B+Tree组织的一个索引结构，这个索引的key是数据表的主键，因此数据文件本身就是主索引，B+Tree的叶节点data域保存了完整的数据记录。 InnoDB的辅助索引data域存储相应记录主键的值而不是地址，所以辅助索引搜索需要检索两遍索引：先检索辅助索引获得主键，然后用主键到主索引中检索获得记录 B+Tree：多路平衡查找树，所有数据都按键值的大小顺序存在叶结点中，通过指针连接。B+树索引的特点就是高扇出性，例如在InnoDB存储引擎中，每个页的大小为16KB，B+树的高度一般不超过4层，查找的IO次数很少。 B+树内部结点不保存数据，只用于索引，所有数据都保存在叶结点中 m阶B+树内部结点最多有m-1个关键字、m个子树，叶子结点最多存储m-1个记录 内部结点中的key都按照从小到大的顺序排列，key左子树中的key都小于等于右子树中的key 叶子结点双向链表相连，自小而大有序 Hash索引和B+Tree索引区别 hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围 hash索引不支持使用索引进行排序 hash索引不支持模糊查询以及多列索引的最左前缀匹配 hash索引虽然在等值查询上较快但是不稳定（发生hash碰撞），而B+树的查询效率比较稳定 B+Tree比BTree优势 方便扫库，B树只能中序遍历 查找效率更稳定，叶结点存放数据内容，每次查询路径都相同 磁盘读写代价更低，因为内部结点只包含关键字，体积小，一个盘块内容纳的关键字数量多，IO读写次数就少 三种日志 bin log：逻辑日志，把对数据库的所有修改操作（SQL语句）以二进制的形式记录在日志文件中，包括了SQL语句的执行时间和消耗资源，以及相关的事务信息。 用途：主从同步、数据恢复（但无法判断哪些数据已刷盘） 刷盘策略：先写到 bin log cache 中，① 每次刷盘 ② 只写到页缓存，不刷盘 ③ 写到页缓存，N 次事务提交后才刷盘 redo log：事务持久性 物理日志，把对数据库页的物理修改操作（包括页地址和修改前后的数据值）记录到二进制文件中，当事务进行修改操作时，采用 WAL 机制，先写 redo log 日志，再写数据。这些记录会先写入到内存中的redo log buffer，后续刷盘到redo log文件中。redo log 分配了固定大小，循环且顺序写入，写满了就等待脏页刷新到磁盘。 用途：① 崩溃恢复，记录了未刷盘的数据页变化 ② 优化磁盘随机I&#x2F;O-&gt;顺序I&#x2F;O，减少无效I&#x2F;O（避免每次刷16KB） 事务提交时刷盘策略：① 立刻刷盘fsync() ② 立即写页缓存，但每秒刷盘 ③ 每秒写页缓存并刷盘 undo log：事务原子性和一致性，逻辑日志，记录了事务所做的更改的相反操作。数据修改前，根据SQL生成相应的 undo log 记录保存到buffer中，后台线程定期刷盘。 用途：事务回滚、MVCC：当读取记录时，若该记录当前版本对该事务不可见，则通过 undo log 读取之前的版本数据，从而避免锁竞争，提高并发性能 ACID的实现A 原子性：undo log 事务的操作要么全成功、要么全失败回滚 D 持久性：redo log 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失 I 隔离性：多个并发事务之间要相互隔离，不能干扰，包括四个级别 写对写：锁机制保证隔离性事务先获得锁才可以修改数据，期间其他事务等待。InnoDB支持表锁和行锁，出于性能考虑通常使用行锁。 写对读：MVCC保证隔离性InnoDB默认的隔离级别是RR，使用MVCC解决脏读、不可重复读、幻读等问题，优点是读不加锁，因此读写不冲突，并发性能好 C 一致性：数据库本身确保插入数据类型、长度正确，应用层面如转账逻辑。其余三个是一致性的前提。 锁表级锁 表锁 元数据锁：防止其他线程修改表结构，不用手动，而是由数据库自动加上 意向锁：加读&#x2F;写锁前要加读&#x2F;写意向锁，用于快速判断表里是否有记录被加锁，从而在加独占表锁时不用去遍历每条记录是否加了锁 行级锁 记录锁：实际是给索引项加锁，不同事务可以使用不同的索引锁定不同行。注意：只有通过索引条件检索数据才使用行锁，否则会把表里的索引项都加锁，相当于锁了整表。 间隙锁：为了解决可重复读隔离级别下幻读 Next-Key Lock：前两者结合 插入意向锁：插入一条记录时，如果插入位置已被其他事务加了间隙锁，插入操作会生成一个插入意向锁并阻塞。不属于意向锁，而是一种特殊的间隙锁，只锁住一个点。 主从复制主从复制流程 主库db的更新事件(update、insert、delete)被写到binlog 从服务器 I&#x2F;O 线程向主服务器请求 binlog 文件，主库用 binlog dump 线程发给从库。 从库接收 binlog 内容并写入到relay log（中继日志） 从库创建一个SQL线程，从relay log里面读取事件并执行，使主从库数据一致 用途 读写分离：主库写、从库读，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作 数据实时备份：当系统中某个节点发生故障时，可以方便的故障切换 架构扩展：把IO访问的负载分布到多个节点 高性能数据库结构优化（联合查询的建立中间表、合理加冗余字段） 加缓存层、加索引 主从读写分离 数据库拆分、分布式架构 分库分表优势：分表解决单表海量数据的查询性能问题，分库解决单台数据库的并发访问压⼒问题 缺点：表在不同结点上难以join查询、需要各自排序最后汇总重排，自增主键重复，分布式事务 垂直切分 垂直分库：根据业务耦合性，将关联度低的不同表存储在不同的数据库 垂直分表：如果某个表字段较多，可以将不常用或长度大的字段拆分到扩展表中。 通过”大表拆小表”，更便于开发与维护 避免跨页问题，MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外开销 数据库以行为单位加载到内存中，表中字段长度越短内存能加载行就越多、命中率更高，减少磁盘IO 水平切分 水平分表：按照某规则（HASH、RANGE）把一张行数多的大表分到多张表，仍在同一个数据库 水平分库：分到多个数据库中 没有减轻MySQL服务器压力，仍然竞争一个CPU、内存、IO 优化查询优化 使用索引：如果查询时没有使用索引，查询语句将扫描表中的所有记录，使用索引则可以快速定位到待查询记录。但几种特殊情况下索引可能失效。 优化子查询：子查询嵌套SELECT执行效率不高，因为 MySQL 需要为内层查询语句的结果建立一个临时表，用于外层查询语句从临时表中查询记录，最后撤销临时表。可以使用连接查询来替代子查询，无需建立临时表，如果查询中使用索引性能会更好。 插入优化 禁用唯一性检查 禁用外键检查 禁止事务的自动提交 慢查询优化 索引失效情况 优化数据库结构 低频字段分离出来形成新表 经常联合查询可以建立中间表 分解关联查询对每个表进行单表查询，然后将查询结果在应用程序中进行关联。 优化LIMIT分页当偏移量非常大的时候，如 limit 10000,20，前面的10000条记录都将被舍弃，代价很高。对此要尽可能用索引覆盖扫描，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候这样做的效率会得到很大提升。 1234select * from table where id in ( select id from table where age &gt; 20 limit 1000000,10) 表数据量过大 优化SQL 增加索引、缓存 读写分离，如主从复制 使用MySQL自带的分区表，这对应用是透明的，无需改代码，但SQL语句是要针对分区表做优化的； 分库分表 ExplainExplain关注的结果： 列名 备注 type 本次查询表联接类型，从这里可以看到本次查询大概的效率 key 最终选择的索引 key_len 用到的索引实际长度，越短越好 rows 预计需要扫描的记录数，越小越好 Extra 额外附加信息 Type关注以下几种结果： 类型 备注 ALL 全表扫描，最差 range 利用索引进行范围查询 ref 基于索引的等值查询 const 基于主键或唯一索引查询，最多返回一条结果 system 查询对象表只有一行数据，最好 Extra关注以下两种结果： 关键字 备注 Using filesort 将用外部排序而不是按照索引顺序排列结果，在磁盘完成排序代价非常高 Using temporary 将创建临时表来存储结果，通常由于对没有索引的列进行GROUP BY 其他范式 1NF：数据库表的每一列都是不可分割的原子数据项。如果不能满⾜第⼀范式，就不称为关系型数据库 2NF：非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖） 3NF：非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 自增ID如果使用自增ID，每次就不把新的纪录插入到当前索引结点的后续位置，一页写满再开辟下一页。若不使用自增ID（如身份证号），则每次插入的主键随机，记录会被插入索引页中间的位置，导致频繁移动、分页造成大量碎片，后续不得不用OPTIMIZE TABLE来重建表并优化填充页面 执行SQL过程 客户端请求-&gt; 连接器（验证用户身份，给予权限） -&gt; 查询缓存（存在缓存则直接返回，不存在则执行后续操作）-&gt; 分析器（对SQL进行词法分析和语法分析操作） -&gt; 优化器（主要对执行的sql优化选择最优的执行方案方法） -&gt; 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）-&gt; 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果） 海量数据排序数据库海量数据排序（外排） 在分割段的阶段，使用内部排序，生成n个大小等于可用内存的顺串，最后再进行归并，使得数据整体有序 但是，为了避免 I&#x2F;O 操作带来的影响，可以使用替换-选择排序的方式，使得在分割段阶段生成的顺串大小大于可用内存大小。 同时为了能够再次减小 I&#x2F;O 开销，合并阶段可以适量增加归并的路数，不过增大路数就意味着内部缓冲区数量增加（一个缓冲区一个顺串），每次要在更多的缓冲区中选取最小值，所以引入败者树将比较次数从 O(k) 降到 O(logk)","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"Leetcode","slug":"Archive/Leetcode","date":"2023-03-24T08:39:04.000Z","updated":"2025-03-06T09:01:58.040Z","comments":true,"path":"2023/03/24/Archive/Leetcode/","permalink":"http://example.com/2023/03/24/Archive/Leetcode/","excerpt":"","text":"数组堆排序123456789101112131415161718void adjust(vector&lt;int&gt;&amp; a, int len, int i)&#123; int l = i * 2 + 1, r = l + 1, maxId = i; if (l &lt; len &amp;&amp; a[maxId] &lt; a[l]) maxId = l; if (r &lt; len &amp;&amp; a[maxId] &lt; a[r]) maxId = r; if (maxId != i) &#123; swap(a[i], a[maxId]); adjust(a, len, maxId); &#125;&#125;void hsort(vector&lt;int&gt;&amp; a)&#123; for(int i = a.size() / 2 - 1; i &gt;= 0; --i)&#123; adjust(a, a.size(), i); &#125; for(int i = a.size() - 1; i &gt; 0; --i)&#123; swap(a[0], a[i]); adjust(a, i, 0); &#125;&#125; 归并排序 在merge过程中，易知两子数组元素大小的个数关系，如以下两题 数组中的逆序对 计算右侧小于当前元素的个数 1234567891011121314151617181920212223242526272829303132int ans&#123;0&#125;; // 逆序对vector&lt;int&gt; tmp;vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; tmp.assign(nums.size(), 0); mergesort(nums, 0, nums.size() - 1); return nums;&#125;void mergesort(vector&lt;int&gt;&amp; nums, int l, int r)&#123; if (l &lt; r) &#123; int m = l + r &gt;&gt; 1; mergesort(nums, l, m); mergesort(nums, m + 1, r); merge(nums, l, m, r); &#125;&#125;void merge(vector&lt;int&gt;&amp; nums, int l, int m, int r)&#123; int i = l, j = m + 1, k = l; while (i &lt;= m &amp;&amp; j &lt;= r) &#123; if (nums[i] &lt;= nums[j]) &#123; // ans += j - m - 1; tmp[k++] = nums[i++]; &#125; else &#123; tmp[k++] = nums[j++]; &#125; &#125; while (i &lt;= m) &#123; // ans += j - m - 1; tmp[k++] = nums[i++]; &#125; while (j &lt;= r) tmp[k++] = nums[j++]; for (int i = l; i &lt;= r; ++i) nums[i] = tmp[i];&#125; 原地哈希 限制不使用额外空间，哈希函数为：f(nums[i]) = nums[i] - 1 原地哈希就相当于，让每个数字 n 都回到下标为 n-1 的家里（或者下标为 n 的家里） 而那些没有回到家里的就成了孤魂野鬼流浪在外，他们要么是根本就没有自己的家（n&lt;=0 || n&gt;=nums.size()），要么是自己的家被别人占领了（出现了重复）。这些流浪汉被临时安置在下标为 i 的空房子里，之所以有空房子是因为房子 i 的主人 i+1 失踪了（数字 i+1 缺失） 因此通过原地构建哈希让各个数字回家，我们就可以找到原始数组中重复的数字还有消失的数字 几道例题 前缀和+哈希和为K的子数组：求和为K的子数组个数（无法用滑动窗口，因为存在负值不好收缩窗口） 题解：哈希记录每个前缀和出现次数，当 mp[prefix - K] 存在时，ans += mp[prefix - K] 剑指 Offer II 011. 0 和 1 个数相同的子数组：找到含有相同数量的 0 和 1 的最长连续子数组长度 题解：将数组中的 0 视作 −1，则原问题转换成「求最长的连续子数组，其元素和为 0」 前缀和：求任意区间元素和，前缀和 s[i]=s[j] 时，区间[i,j]元素和为0 哈希表：保存前缀和每个值首次出现的下标，可直接查找左区间 12345678910111213141516int findMaxLength(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(),ans=0,sum=0; unordered_map&lt;int, int&gt; mp; mp[sum] = -1; for (int i = 0; i &lt; n; i++) &#123; if (nums[i] == 1) sum++; else sum--; if (mp.count(sum)) &#123; int prevIndex = mp[sum]; ans = max(ans, i-prevIndex); &#125; else &#123; mp[sum] = i; &#125; &#125; return ans;&#125; 链表K个一组反转链表（不遍历求长度） Folding 12345678910111213141516171819202122232425262728ListNode *reverseKGroup(ListNode *head, int k) &#123; ListNode *dummy = new ListNode(), *cur = dummy; ListNode *p = head, *q = nullptr; while (p) &#123; int cnt = k; ListNode *last_reverse_node = p; while (cnt &amp;&amp; p) &#123; q = p-&gt;next; p-&gt;next = cur-&gt;next; cur-&gt;next = p; p = q; cnt--; &#125; if (cnt &gt; 0) &#123; // tail_k not enough, should reverse again p = cur-&gt;next; cur-&gt;next = nullptr; while (p) &#123; q = p-&gt;next; p-&gt;next = cur-&gt;next; cur-&gt;next = p; p = q; &#125; break; &#125; cur = last_reverse_node; &#125; return dummy-&gt;next;&#125; 排序链表：找链表中位数 + 合并链表 123456789101112131415161718ListNode *midLeft(ListNode* p)&#123; ListNode *f = p, *s = p; while(f-&gt;next &amp;&amp; f-&gt;next-&gt;next)&#123; s = s-&gt;next; f = f-&gt;next-&gt;next; &#125; return s;&#125;ListNode *reverse(ListNode* p)&#123; ListNode *dummy=new ListNode(),*q; while(p)&#123; q=p-&gt;next; p-&gt;next=dummy-&gt;next; dummy-&gt;next=p; p=q; &#125; return dummy-&gt;next;&#125; 字符串字符串加法1234567891011121314string addStr(string num1, string num2) &#123; string ans; int add = 0,i = num1.size() - 1, j = num2.size() - 1; while(add || i &gt;= 0 || j &gt;= 0)&#123; int x= i &gt;= 0 ? num1[i] - &#x27;0&#x27;: 0; int y= j &gt;= 0 ? num2[j] - &#x27;0&#x27;: 0; int result = x + y + add; ans += char(&#x27;0&#x27; + result % 10); add = result / 10; i--; j--; &#125; reverse(ans.begin(), ans.end()); return ans;&#125; 字符串乘法123456789101112131415161718string ans;string multiply(string num1, string num2) &#123; if (num1 == &quot;0&quot; || num2 == &quot;0&quot;) return &quot;0&quot;; int m = num1.size(), n = num2.size(); for(int i = n - 1; i &gt;= 0; i--)&#123; string tmp(n - 1 - i, &#x27;0&#x27;); int add = 0, y = num2[i] - &#x27;0&#x27;; for(int j = m - 1; j &gt;= 0 || add; --j)&#123; int x = j &lt; 0 ? 0 : num1[j] - &#x27;0&#x27;; int multi = x * y + add; tmp += char(&#x27;0&#x27; + multi % 10); add = multi / 10; &#125; reverse(tmp.begin(), tmp.end()); ans = addStr(tmp, ans); &#125; return ans;&#125; 字符串分割12345678vector&lt;string&gt; ret;void split(string s, char del)&#123; stringstream ss(s); string tmp; while(getline(ss, tmp, del))&#123; if(tmp.size()) ret.push_back(tmp); &#125;&#125; 计算器基本计算器 II 参考『宫水三叶』题解 对遍历到的字符做分情况讨论： 空格 : 跳过 ( : 直接加入 op 中，等待与之匹配的 ) ) : 使用现有的 num 和 op 进行计算，直到遇到左括号为止，将结果存入 num 数字 : 从当前继续往右，取出完整数字加入 num 运算符 : 放入 op 中，并且在放入前应先把栈内可以算的 运算符优先级更高&#x2F;同 的都算掉，每次取 2 个 num 和 1 个 op 计算并存储，直到 没有操作 或者 遇到左括号 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950stack&lt;char&gt; op;stack&lt;int&gt; num;unordered_map&lt;char,int&gt; level &#123; &#123;&#x27;+&#x27;, 1&#125;, &#123;&#x27;-&#x27;, 1&#125;, &#123;&#x27;*&#x27;, 2&#125;, &#123;&#x27;/&#x27;, 2&#125;, &#123;&#x27;^&#x27;, 3&#125;&#125;;void cal()&#123; long b = num.top(); num.pop(); long a = num.top(); num.pop(); char op_ =op.top(); op.pop(); long long res; switch(op_)&#123; case &#x27;+&#x27;: res = a + b; break; case &#x27;-&#x27;: res = a - b; break; case &#x27;*&#x27;: res = a * b; break; case &#x27;/&#x27;: res = a / b; break; case &#x27;^&#x27;: res = pow(a, b); break; &#125; num.push(res);&#125;int calculate(string s) &#123; num.push(0); //确保2个操作数 int n = s.size(); for (int i = 0; i &lt; n; ++i) &#123; if (s[i] == &#x27; &#x27;) continue; else if (s[i] == &#x27;(&#x27;) &#123; op.push(&#x27;(&#x27;); if(s[i + 1] == &#x27;-&#x27;)&#123; num.push(0); //确保2个操作数 op.push(&#x27;-&#x27;); i++; &#125; &#125; else if(s[i] == &#x27;)&#x27;) &#123; while (op.top() != &#x27;(&#x27;) cal(); op.pop(); &#125; else if(isdigit(s[i])) &#123; int k = i + 1; while(k &lt; n &amp;&amp; isdigit(s[k])) k++; num.push(stoi(s.substr(i, k - i))); i = k - 1; &#125; else &#123; while(!op.empty() &amp;&amp; op.top() != &#x27;(&#x27; &amp;&amp; level[op.top()] &gt;= level[s[i]]) cal(); op.push(s[i]); &#125; &#125; while(!op.empty() &amp;&amp; op.top() != &#x27;(&#x27;) cal(); return num.top();&#125; KMP Folding 123456789101112131415161718192021222324int strStr(string haystack, string needle) &#123; int k=-1,n=haystack.length(),p=needle.length(); if(!p) return 0; vector&lt;int&gt; next(p,-1); calNext(needle,next); for(int i=0;i&lt;n;++i)&#123; while(k&gt;-1 &amp;&amp; needle[k+1]!=haystack[i]) k=next[k]; if(needle[k+1]==haystack[i]) k++; if(k==p-1) return i-p+1; &#125; return -1;&#125;void calNext(string&amp; needle,vector&lt;int&gt;&amp; next)&#123; for(int j=1,p=-1;j&lt;needle.length();++j)&#123; while(p&gt;-1 &amp;&amp; needle[p+1]!=needle[j]) p=next[p]; if(needle[p+1]==needle[j]) p++; next[j]=p; &#125;&#125; 二叉树ACM模式树插入 1234567891011121314151617TreeNode *buildTree(vector&lt;int&gt;&amp; vec) &#123; vector&lt;TreeNode*&gt; tree(vec.size(), nullptr); for (int i = 0; i &lt; vec.size(); ++i) &#123; if (vec[i] != -1) tree[i] = new TreeNode(vec[i]); &#125; for (int i = 0; i &lt; vec.size() / 2; ++i) &#123; if (vec[i] != -1) &#123; tree[i]-&gt;left = tree[i * 2 + 1]; tree[i]-&gt;right = tree[i * 2 + 2]; &#125; &#125; return tree[0];&#125;int main()&#123; vector&lt;int&gt; v = &#123;4,1,6,0,2,5,7,-1,-1,-1,3,-1,-1&#125;; TreeNode* root = Build(v);&#125; 迭代遍历 push 节点的顺序与遍历序相反： 先序遍历：右 左 中 中序遍历：右 中 左 后序遍历：中 右 左 1234567891011121314// 先序遍历stack&lt;TreeNode*&gt; st;if (root) st.push(root);while (!st.empty()) &#123; TreeNode* node = st.top(); st.pop(); if (node) &#123; if (node-&gt;right) st.push(node-&gt;right); // 添加右节点 if (node-&gt;left) st.push(node-&gt;left); // 添加左节点 st.push(node); st.push(nullptr); // 添加中节点，虽然访问过但没处理，空节点标记 &#125; else &#123; // 弹出空节点 node = st.top(); st.pop(); // 重新取出栈中元素 cout &lt;&lt; node-&gt;val &lt;&lt; endl; &#125;&#125; 二叉树的最近公共祖先：找 p、q 的最近公共祖先节点 12345678TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; if (!root || root == p || root == q) return root; auto l = lowestCommonAncestor(root-&gt;left, p, q); auto r = lowestCommonAncestor(root-&gt;right, p, q); if (!l) return r; if (!r) return l; return root;&#125; 图论DFS&#x2F;BFS最短的桥：二维数组A中0代表海，1代表岛（四个方向相连），求至少将几个 0 变为 1能把两岛连起来 题解： 找到任意一个岛 通过dfs将整个岛1标记为2，并把边缘点0入队列 从边缘点0作bfs扩散，访问过的记录为2，碰到另一个岛1时的层数为所得 Folding 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123;public: int n; vector&lt;int&gt; d&#123;-1, 0, 1, 0, -1&#125;; queue&lt;pair&lt;int, int&gt;&gt; q; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int i, int j) &#123; if (i &lt; 0 || j &lt; 0 || i == n || j == n || grid[i][j] == 2) return; if (grid[i][j] == 0) &#123; q.emplace(i, j); return; &#125; grid[i][j] = 2; for (int k = 0; k &lt; 4; ++k) &#123; dfs(grid, i + d[k], j + d[k + 1]); &#125; &#125; int shortestBridge(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; n = grid.size(); for (int i = 0, stop = 0; i &lt; n &amp;&amp; !stop; ++i) &#123; for (int j = 0; j &lt; n &amp;&amp; !stop; ++j) &#123; if (grid[i][j] == 1) &#123; dfs(grid, i, j); stop = 1; &#125; &#125; &#125; int ans = 0; while (!q.empty()) &#123; ans++; int size = q.size(); while (size--) &#123; auto [i, j] = q.front(); q.pop(); for (int k = 0; k &lt; 4; ++k) &#123; int r = i + d[k], c = j + d[k + 1]; if (r &lt; 0 || c &lt; 0 || r == n || c == n) continue; if (grid[r][c] == 1) return ans; if (grid[r][c] == 0) &#123; q.emplace(r, c); grid[r][c] = 2; &#125; &#125; &#125; &#125; return -1; &#125;&#125;; 被围绕的区域：矩阵包含 X 和 O ，找到所有被 X 围绕(四个方向)的区域，并将这些区域里所有的 O 用 X 填充。 题解： 找到未被包围区域不填充即可，且注意到未包围区域一定挨着边界，故从四个边界开始dfs找到O区域即可 状态转换 关键在于“建图”，过程灵活，只需能完成遍历即可 相关题目：剑指 Offer II 109. 开密码锁，剑指 Offer II 111. 计算除法 单词接龙：求字符串 start 转换至 end 最小步数，每次转换仅改变一个字符，且改变后字符串在所给 dic 中 题解： 字符串之间的转换关系可抽象为无向图。遍历找相邻结点时，依次查找改变字符后的新字符串是否在 dic 内 无向图中顶点间的最短路径的长度通过BFS得到。为防止回路，将访问过的结点记录下来 Folding 1234567891011121314151617181920212223242526272829303132333435363738queue&lt;string&gt; q;int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) &#123; unordered_set&lt;string&gt; dic(wordList.begin(), wordList.end()); if(!dic.count(endWord)) return 0; int step = 1; q.push(beginWord); dic.erase(beginWord);//访问后直接删除，防止回路 while(!q.empty())&#123; int k = q.size(); while(k--)&#123; string s = q.front(); q.pop(); //判断更改一个字符后是否满足结果 if(check(s, endWord, dic))&#123; return step + 1; &#125; &#125; step++; &#125; return 0;&#125;bool check(string cur, string target, unordered_set&lt;string&gt;&amp; dic)&#123; for(int i = 0; i &lt; cur.size(); ++i)&#123; char tmp = cur[i]; for(char c = &#x27;a&#x27;; c &lt;= &#x27;z&#x27;; c++)&#123; if(tmp == c) continue; cur[i] = c; if(dic.count(cur))&#123; if(cur == target) return true; else&#123; q.push(cur); dic.erase(cur);//访问后直接删除，防止回路 &#125; &#125; &#125; cur[i] = tmp; &#125; return false;&#125; 水壶问题：两水壶容量x,y，能否经操作使得盛水之和为z：①装满一水壶 ②清空一水壶 ③相互倒水至满或空 题解：记当前盛水量为状态(a,b) 每次操作有6种状态转换： ① a倒满至(x,b) ② b倒满至(a,y) ③ a清空至(0,b) ④ b清空至(a,0) ⑤ a往b倒水至(a-move,b+move) ⑥ 反之(a+move,b-move) BFS进行搜索，set记录已访问过状态（将pair转换成int64_t存储） Folding 12345678910111213141516171819202122232425262728293031323334353637383940inline int64_t hash(int a, int b) &#123; return (int64_t)a &lt;&lt; 32 | b;&#125;pair&lt;int, int&gt; op(int i, int a, int b, int x, int y) &#123; switch (i) &#123; case 0: return make_pair(0, b); case 1: return make_pair(a, 0); case 2: return make_pair(x, b); case 3: return make_pair(a, y); case 4: &#123; int move = min(a, y - b); return make_pair(a - move, b + move); &#125; case 5: &#123; int move = min(b, y - a); return make_pair(a + move, b - move); &#125; &#125; return make_pair(0, 0);&#125;bool canMeasureWater(int x, int y, int target) &#123; queue&lt;pair&lt;int, int&gt;&gt; q; unordered_set&lt;int64_t&gt; vis; q.emplace(0, 0); while (!q.empty()) &#123; int size = q.size(); while (size--) &#123; auto [a, b] = q.front(); q.pop(); for (int i = 0; i &lt; 6; ++i) &#123; auto [new_a, new_b] = op(i, a, b, x, y); if (new_a + new_b == target) return true; if (!vis.count(hash(new_a, new_b))) &#123; vis.insert(hash(new_a, new_b)); q.emplace(new_a, new_b); &#125; &#125; &#125; &#125; return false;&#125; Dijkstra Folding 123456789101112131415161718192021222324int n;vector&lt;int&gt; vis,dis;vector&lt;vector&lt;int&gt;&gt; g; // 邻接矩阵void dijkstra(int start)&#123; vis.assign(n, 0); dis.assign(n, INT_MAX); dis[start]=0; while (true) &#123; int nearest_id = -1, min_dis = INT_MAX; for (int i = 0; i &lt; n; ++i)&#123; if (!vis[i] &amp;&amp; dis[i] &lt; min_dis)&#123; min_dis = dis[i]; nearest_id=i; &#125; &#125; if (nearest_id &lt; 0) break; vis[nearest_id] = 1; for (int i = 0; i &lt; n; ++i) &#123; if(!vis[i] &amp;&amp; g[nearest_id][i] &lt; INT_MAX)&#123; dis[i] = min(dis[i], dis[nearest_id] + g[nearest_id][i]); &#125; &#125; &#125;&#125; 回溯 两个诀窍：一是按值传状态，二是所有的状态修改在递归完成后回改。两种情况：一种是修改最后一位输出，如排列组合；一种是修改访问标记，如矩阵里搜字符串 一维全排列 II：序列包含重复数字，按任意顺序返回所有不重复的全排列。 123456789101112131415161718192021222324vector&lt;int&gt; vis, tmp;vector&lt;vector&lt;int&gt;&gt; ans;vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; vis.assign(nums.size(), 0); sort(nums.begin(), nums.end()); fun(nums); return ans;&#125;void fun(vector&lt;int&gt;&amp; nums) &#123; if (tmp.size() == nums.size()) &#123; ans.push_back(tmp); return; &#125; for (int i = 0; i &lt; nums.size(); ++i) &#123; if (vis[i] || i &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; vis[i - 1]) &#123; continue; &#125; tmp.push_back(nums[i]); vis[i] = 1; fun(nums); vis[i] = 0; tmp.pop_back(); &#125;&#125; N 皇后：如何将 n 个皇后放置在 n×n 的棋盘上，使得横竖斜直线上均仅一个皇后 题解：实质从0到n-1行依次选择一个位置（一维搜索），选择前修改矩阵，退出dfs后恢复修改。另需设置set集合记录哪些行列已存在皇后。 12345678910111213141516171819202122vector&lt;string&gt; cur;vector&lt;vector&lt;string&gt;&gt; ans;set&lt;int&gt; row, bias1, bias2;void dfs(int i, int n)&#123; if(i &gt;= n)&#123; ans.push_back(cur); return; &#125; for(int j = 0; j &lt; n; ++j)&#123; if(!row.count(j) &amp;&amp; !bias1.count(j - i) &amp;&amp; !bias2.count(j + i))&#123; cur[i][j] = &#x27;Q&#x27;; row.insert(j); bias1.insert(j - i); bias2.insert(j + i); dfs(i + 1, n); cur[i][j] = &#x27;.&#x27;; row.erase(j); bias1.erase(j - i); bias2.erase(j + i); &#125; &#125;&#125;vector&lt;vector&lt;string&gt;&gt; solveNQueens(int n) &#123; cur = vector&lt;string&gt;(n, string(n, &#x27;.&#x27;)); dfs(0, n); return ans;&#125; 二维解数独：数字 1-9 在每行、每列、每个粗实线分隔的 3x3 宫内只能出现一次，矩阵由数字和空白 &#39;.&#39; 表示 123456789101112131415161718192021222324252627bool check(vector&lt;vector&lt;char&gt;&gt;&amp; a, int i, int j, char x)&#123; for(int k = 0; k &lt; 9; ++k)&#123; if(a[i][k] == x) return false; if(a[k][j] == x) return false; if(a[i / 3 * 3 + k / 3][j / 3 * 3 + k % 3] == x) &#123; return false; &#125; &#125; return true;&#125;int dfs(vector&lt;vector&lt;char&gt;&gt;&amp; a,int i,int j)&#123; if(j == 9) j = 0, i++; if(i == 9) return true; if(a[i][j] != &#x27;.&#x27;) return dfs(a, i, j + 1); for(char x = &#x27;1&#x27;; x &lt;= &#x27;9&#x27;; ++x)&#123; if(check(a, i, j, x))&#123; a[i][j] = x; if(dfs(a, i, j + 1)) return true; a[i][j] = &#x27;.&#x27;; &#125; &#125; return false;&#125;void solveSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; a) &#123; dfs(a, 0, 0);&#125; 记忆化搜索最长递增路径：求矩阵中最长递增路径长度（上下左右移动） 12345678910111213141516171819202122232425int m, n, ans;vector&lt;int&gt; d&#123;-1, 0, 1, 0, -1&#125;;vector&lt;vector&lt;int&gt;&gt; dp;int longestIncreasingPath(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; m = matrix.size(), n = matrix[0].size(); dp.assign(m, vector&lt;int&gt;(n, -1)); // cache, 仅增加了注释的三行代码 for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; ans = max(ans, fun(matrix, i, j, INT_MAX + 1l)); &#125; &#125; return ans;&#125;int fun(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int i, int j, long value) &#123; if (i &lt; 0 || j &lt; 0 || i == m || j == n || (long)matrix[i][j] &gt;= value) &#123; return 0; &#125; if (dp[i][j] != -1) return dp[i][j]; // load int len = 0; for (int k = 0; k &lt; 4; ++k) &#123; len = max(len, fun(matrix, i + d[k], j + d[k + 1], matrix[i][j])); &#125; dp[i][j] = len + 1; // save return len + 1;&#125; 动态规划子序列问题最长递增子序列（贪心+二分）：返回最长递增子序列（字典序） 123456789101112131415161718192021222324252627// 返回字典序最小的序列vector&lt;int&gt; lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; d; // d[i] 维护当前长度为 len 的 LIS vector&lt;int&gt; pos(n); // pos[i]: nums[i] 在 d 中的下标 d.push_back(nums[0]); for (int i = 1; i &lt; n; ++i) &#123; if (nums[i] &gt; d.back()) &#123; d.push_back(nums[i]); pos[i] = d.size(); &#125; else &#123; auto it = lower_bound(d.begin(), d.end(), nums[i]); *it = nums[i]; pos[i] = it - d.begin() + 1; &#125; &#125; int len = d.size(); // 长度 vector&lt;int&gt; lis; for (int i = n - 1; i &gt;= 0 &amp;&amp; len; --i) &#123; if (pos[i] == len) &#123; lis.push_back(nums[i]); len--; &#125; &#125; reverse(lis.begin(), lis.end()); return lis;&#125; 最长公共子序列：返回两个字符串的最长公共序列 方案一：二维DP空间 + 输出全部LCS路径 123456789101112131415161718192021222324252627282930313233343536int longestCommonSubsequence(string text1, string text2) &#123; int m = text1.size(), n = text2.size(); vector&lt;vector&lt;int&gt;&gt; dp(m + 1, vector&lt;int&gt;(n + 1)); for (int i = 1; i &lt;= m; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; if (text1[i - 1] == text2[j - 1]) dp[i][j] = dp[i - 1][j - 1] + 1; else dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]); &#125; &#125; int len = dp[m][n]; vector&lt;string&gt; paths; // 保存LCS序列 function&lt;void(int, int, string)&gt; fun = [&amp;](int i, int j, string lcs) &#123; while (i &gt; 0 &amp;&amp; j &gt; 0) &#123; if (text1[i - 1] == text2[j - 1]) &#123; lcs += text1[i - 1]; i--; j--; &#125; else &#123; if (dp[i - 1][j] &gt; dp[i][j - 1]) i--; else if (dp[i - 1][j] &lt; dp[i][j - 1]) j--; else &#123; fun(i - 1, j, lcs); fun(i, j - 1, lcs); break; &#125; &#125; &#125; if (lcs.size() == len) &#123; reverse(lcs.begin(), lcs.end()); paths.push_back(lcs); &#125; &#125;; fun(m, n, &quot;&quot;); return len;&#125; 方案二：一维DP空间，用 leftup 变量保存 dp[i - 1][j - 1] 1234567891011121314int longestCommonSubsequence1(string text1, string text2) &#123; int m = text1.size(), n = text2.size(); vector&lt;int&gt; dp(n + 1); for (int i = 1; i &lt;= m; ++i) &#123; int leftup = dp[0]; for (int j = 1; j &lt;= n; ++j) &#123; int tmp = dp[j]; if (text1[i - 1] == text2[j - 1]) dp[j] = leftup + 1; else dp[j] = max(dp[j], dp[j - 1]); leftup = tmp; &#125; &#125; return dp[n];&#125; 字符串问题交错字符串：问s1和s2交错拼接能否组成s3 单词拆分：字符串 s 能否由 wordDict 中的字符串列表拼接出来 记忆化回溯：定义 bool fun(i) 为下标 i 之前的 s 可否被拼接出来，从 fun(n) 缩小问题到 fun(0)，同时记录 fun(i) 的结果防止重复子问题 DP解法：正向求 dp[i] 表示前 i 能否被拼接出，从 0 ~ n 遍历求解 1234567891011121314151617181920bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) &#123; int n = s.size(), max_len = 0; vector&lt;int&gt; dp(n); unordered_set&lt;string&gt; st; for (auto&amp; w : wordDict) &#123; max_len = max(max_len, (int)w.size()); st.insert(w); &#125; for (int i = 0; i &lt; n; ++i) &#123; for (int j = max(0, i - max_len + 1); j &lt;= i; ++j) &#123; string cur = s.substr(j, i - j + 1); if (!st.count(cur)) continue; if (j == 0 || dp[j - 1] &gt; 0) &#123; dp[i] = 1; break; &#125; &#125; &#125; return dp.back();&#125; 不同的子序列：返回在 s 的子序列中 t 出现的个数 dp[i][j] 为 s 的前 i 个字符与 t 的前 j 个匹配，初始化 dp[i][0] = 1 若 s[i-1] == t[j-1]，dp[i][j] = dp[i-1][j-1] + dp[i-1][j] 若 s[i-1] != t[j-1]，dp[i][j] = dp[i-1][j] 编辑距离：求将 word1 转换成 word2 所使用的最少操作数，可以任意位置删除、替换、插入 两个字符串的删除操作：编辑距离的简化版，仅删除操作 题解： 定义dp[i][j]为使两单词前i j部分相同的最少操作数 状态转移方程 若word1[i]=word2[j]：dp[i][j]=dp[i-1][j-1] 若word1[i]≠word2[j]： 在i后插入&#x2F;j处删除：dp[i][j]=dp[i][j-1]+1 在j后插入&#x2F;i处删除：dp[i][j]=dp[i-1][j]+1 在i&#x2F;j处修改：dp[i][j]=dp[i-1][j-1]+1 考虑初值i=0或j=0的情况：i=0时，word1为空，只能删除&#x2F;插入j次；j=0时同理 dp[0][j]=j, dp[i][0]=i 优化空间 正序遍历 j 会丢失 dp[i-1][j-1]，倒序遍历又不知道 dp[i][j-1] 的结果 因此选择正序遍历，并用 leftup 保存 dp[i-1][j-1] 初值 dp[0][j] = j，仅在第一轮遍历中用到 -&gt; dp[j] = j 初值 dp[i][0] = i，每轮遍历中用到 -&gt; 每轮循环中 dp[0] = i Folding 123456789101112131415161718192021222324252627282930int minDistance(string word1, string word2) &#123; int m = word1.size(), n = word2.size(); vector&lt;vector&lt;int&gt;&gt; dp(m + 1, vector&lt;int&gt;(n + 1, 0)); for (int j = 1; j &lt;= n; ++j) dp[0][j] = j; for (int i = 1; i &lt;= m; ++i) dp[i][0] = i; for (int i = 1; i &lt;= m; ++i) &#123; for (int j = 1; j &lt;= n; ++j) &#123; if (word1[i - 1] == word2[j - 1]) dp[i][j] = dp[i - 1][j - 1]; else dp[i][j] = 1 + min(&#123;dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1]&#125;); &#125; &#125; return dp[m][n];&#125;// 优化空间复杂度int minDistance(string word1, string word2) &#123; int m = word1.size(), n = word2.size(); vector&lt;int&gt; dp(n + 1, 0); for (int j = 1; j &lt;= n; ++j) dp[j] = j; for (int i = 1; i &lt;= m; ++i) &#123; int leftup = dp[0]; dp[0] = i; for (int j = 1; j &lt;= n; ++j) &#123; int tmp = dp[j]; if (word1[i - 1] == word2[j - 1]) dp[j] = leftup; else dp[j] = min(&#123;dp[j], dp[j - 1], leftup&#125;) + 1; leftup = tmp; &#125; &#125; return dp[n];&#125; 正则表达式：字符串 s 能否被 p 匹配：. 匹配任意单个字符，* 匹配任意个前一个元素 Folding 1234567891011121314151617181920212223bool articleMatch(string s, string p) &#123; int m = s.size(), n = p.size(); vector&lt;vector&lt;int&gt;&gt; dp(m + 1, vector&lt;int&gt;(n + 1, 0)); auto check = [&amp;] (int i, int j) &#123; if (!i || !j) return false; if (p[j - 1] == &#x27;.&#x27;) return true; return p[j - 1] == s[i - 1]; &#125;; dp[0][0] = 1; for (int i = 0; i &lt;= m; ++i) &#123; // &quot;&quot; match &quot;A**&quot; for (int j = 1; j &lt;= n; ++j) &#123; if (p[j - 1] != &#x27;*&#x27;) &#123; dp[i][j] |= check(i, j) &amp;&amp; dp[i - 1][j - 1]; &#125; else &#123; // *匹配 0 个 dp[i][j] |= dp[i][j - 2]; // s[i-1] = p[j-2], 各抵消一个字符a后，S对应前i-1，而P的a*是无限个，j不减 dp[i][j] |= check(i, j - 1) &amp;&amp; dp[i - 1][j]; &#125; &#125; &#125; return dp[m][n];&#125; 分割回文串：求s的任意子串是否回文 1234567vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(n));for (int i = n - 1; i &gt;= 0; --i) &#123; for (int j = i; j &lt; n; ++j) &#123; if (i + 1 &gt;= j - 1) dp[i][j] = s[i] == s[j]; else dp[i][j] = dp[i + 1][j - 1] &amp;&amp; s[i] == s[j]; &#125;&#125; 最长有效括号：从含 &#39;(&#39; 和 &#39;)&#39; 的字符串中找出最长有效括号子串的长度 背包问题递推公式问能否装满背包（或最多装多少）：dp[j] |= dp[j - nums[i]] 本质是 dp[j] = max(dp[j], dp[j - nums[i]] + nums[i]) 分割等和子集 能否装满SUM的一半 最后一块石头的重量 II：不断取任意两数相减，最终最小值？ 设最多装满SUM&#x2F;2中的大小为 A，则最小值为 (SUM - A) - A，转化为求 A 最大多少 问装满背包有几种方法：dp[j] += dp[j - nums[i]] 目标和：给数组每个数用+或-串联计算出结果，求结果为target的方式数 0-1背包，倒着遍历空间。令+的部分和为 A，-的部分和为 B，则 A + B = SUM, A - B = target，即 A = (SUM + target) / 2，求装满 A 的方法数 零钱兑换II：给定不同面额的硬币（无限个），求凑成某总金额的硬币组合数 完全背包，正向遍历空间。注意是求装满空间的组合数，要外层循环物品(硬币)、内层循环空间(金额)，这样挑物品不会重复。否则，对于金额 6 会出现 {1, 5}, {5, 1} 这两个重复组合 组合总和 Ⅳ：从 nums 中找出总和为 target 的元素组合的个数（顺序不同的序列视作不同组合） 完全背包，正向遍历空间。注意是求装满空间的排列数，要外层循环空间(target)、内层循环物品(nums)，这样对于 target &#x3D; 3 时 {1, 2} 和 {2, 1} 两种均有效 问背包装满最大价值：dp[j] = max(dp[j], dp[j - weight[i]] + value[i]) 一和零：strs 是仅含 0&#x2F;1 的字符串数组，找出 strs 的最大子集的长度，该子集中最多有 m 个 0 和 n 个 1 空间限制变成了二维，多加一重循环即可 1234567for (auto&amp; str : strs) &#123; for (int i = m; i &gt;= zero; --i) &#123; for (int j = n; j &gt;= one; --j) &#123; dp[i][j] = max(dp[i][j], dp[i - zero][j - one] + 1); &#125; &#125;&#125; 问装满背包所有物品的最小个数：dp[j] = min(dp[j], dp[j - coins[i]] + 1) 零钱兑换：硬币面额 coins，总金额 amount，求凑成总金额的最少的硬币个数 完全平方数：求和为 n 的完全平方数的最少数量 遍历顺序(一) 01背包 123456789int knapsack(vector&lt;int&gt; weights, vector&lt;int&gt; values, int space) &#123; vector&lt;int&gt; dp(space + 1, 0); for (int i = 1; i &lt;= N; ++i) &#123; int w = weights[i - 1], v = values[i - 1]; for (int j = space; j &gt;= w; --j) dp[j] = max(dp[j], dp[j - w] + v); &#125; return dp[space];&#125; 二维DP 12345678910111213// 二维 dp 先遍历物品或背包都行int knapsack(vector&lt;int&gt; weights, vector&lt;int&gt; values, int N, int W) &#123; vector&lt;vector&lt;int&gt;&gt; dp(N + 1, vector&lt;int&gt;(W + 1, 0)); for (int i = 1; i &lt;= N; ++i) &#123; int w = weights[i-1], v = values[i-1]; for (int j = 1; j &lt;= W; ++j) if (j &gt;= w) dp[i][j] = max(dp[i-1][j], dp[i-1][j-w] + v); else dp[i][j] = dp[i-1][j]; &#125; return dp[N][W];&#125; (二) 完全背包 纯完全背包的一维dp数组实现，先遍历物品或背包都行，且第二层循环从小到大遍历。 但是要注意特殊情况： 如果求组合数就是外层遍历物品，内层遍历背包：零钱兑换II 如果求排列数就是外层遍历背包，内层遍历物品：组合总和 Ⅳ 如果求最小数，那么循环的先后顺序无关：零钱兑换, 完全平方数 123456789int knapsack(vector&lt;int&gt; weights, vector&lt;int&gt; values, int space) &#123; vector&lt;int&gt; dp(space + 1, 0); for (int i = 1; i &lt;= N; ++i) &#123; int w = weights[i - 1], v = values[i - 1]; for (int j = w; j &lt;= space; ++j) dp[j] = max(dp[j], dp[j - w] + v); &#125; return dp[W];&#125; 二维DP 123456789101112int knapsack(vector&lt;int&gt; weights, vector&lt;int&gt; values, int N, int W) &#123; vector&lt;vector&lt;int&gt;&gt; dp(N + 1, vector&lt;int&gt;(W + 1, 0)); for (int i = 1; i &lt;= N; ++i) &#123; int w = weights[i-1], v = values[i-1]; for (int j = 1; j &lt;= W; ++j) if (j &gt;= w) dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v); else dp[i][j] = dp[i-1][j]; &#125; return dp[N][W];&#125; 股票问题买卖股票的最佳时机 IV：给定price[i]共可交易k次，求最大利润 状态定义： dp[i][j][0]表示第 i 天共交易 j 次且当前不持有股票，跟在dp[i-1][j][1]之后（买入后才进入新的交易次数） dp[i][j][1]表示第 i 天共交易 j 次且当前持有股票，跟在dp[i-1][j-1][0]之后 状态转移 dp[i][j][0] = max&#123; dp[i-1][j][0],dp[i-1][j][1]+price[i] &#125; dp[i][j][1] = max&#123; dp[i-1][j][1],dp[i-1][j-1][0]-price[i] &#125; 初始化 dp[0][0][0]=0：第一天没交易过没股票 dp[0][1][1]=-price[0]：第一天第一次交易买了股票 其他均不合法情况，设置为INI_MIN 执行结果 最后一天、不持有股票、交易0～k次中的最大值，即 max&#123;dp[n-1][i][0]&#125;, 0&lt;=i&lt;=k 代码 12345678910111213141516171819202122int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(), ans = 0; if(!k || !n) return 0; vector&lt;vector&lt;int&gt;&gt; tmp(k + 1, vector&lt;int&gt;(2)); vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(n, tmp); for(int i = 0; i &lt;= k; ++i) dp[0][i][0]=dp[0][i][1] = INT_MIN / 2; dp[0][0][0] = 0; dp[0][1][1] = -prices[0]; for(int i = 1; i &lt; n; ++i)&#123; for(int j = 1; j &lt;= k; ++j)&#123; dp[i][j][0] = max(dp[i - 1][j][0], dp[i - 1][j][1] + prices[i]); dp[i][j][1] = max(dp[i - 1][j][1], dp[i - 1][j - 1][0] - prices[i]); &#125; &#125; for(int i = 1; i &lt;= k; ++i) if(ans &lt; dp[n - 1][i][0]) ans = dp[n - 1][i][0]; return ans;&#125; 以下几种情况均不强调制定交易次数，可省略k维度 买卖股票的最佳时机：限定交易次数 k&#x3D;1 123dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i])// k=0时没有交易次数，dp[i-1][0][0]必为0dp[i][1] = max(dp[i - 1][1], -prices[i]) 买卖股票的最佳时机 II：交易次数无限制 k &#x3D; +infinity 123dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i])// 前一天持有 or 前一天不持有然后买入dp[i][1] = max(dp[i - 1][1], dp[i - 1][0] - prices[i]) 最佳买卖股票时机含冷冻期：卖出后至少隔1天才能买 123dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i])//冷却时间1天，所以要从 i-2 天转移状态dp[i][1] = max(dp[i - 1][1], dp[i - 2][0] - prices[i]) 买卖股票的最佳时机含手续费：每次交易含手续费 123//定义在卖出的时候扣手续费dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i] - fee)dp[i][1] = max(dp[i - 1][1], dp[i - 1][0] - prices[i]) 树状DP打家劫舍 III：从树中挑选部分节点，要求两两不连续，求最大值 节点 A 可选偷或不偷，截止到 A 的最大值依赖于 A-&gt;left 偷/不偷、A-&gt;right 偷/不偷 这四个情况，即当前状态是由前面多个状态推导出的，只能采用 DFS （记忆化回溯）的方式 1234567891011pair&lt;int, int&gt; dfs(TreeNode* t) &#123; if (!t) return &#123;0, 0&#125;; pair&lt;int, int&gt; l = dfs(t-&gt;left), r = dfs(t-&gt;right); int stole = t-&gt;val + l.first + r.first; int unstole = max(l.first, l.second) + max(r.first, r.second); return &#123;unstole, stole&#125;;&#125;int rob(TreeNode* root) &#123; auto pair = dfs(root); return max(pair.first, pair.second);&#125; 数位DP1～n 整数中 1 出现的次数：无须考虑前导零 将n转换成字符串 s，定义 f(i,cnt,isLimit) 表示构造从左往右第i位及其之后数位中 1 的个数 cnt：表示前面填了多少个 1。 isLimit：表示当前是否受到了 n 的约束。若为真，则第 i 位填入的数字至多为 s[i]，否则可以是 9。如果在受到约束的情况下填了 s[i]，那么后续填入的数字仍会受到 n 的约束。 Folding 12345678910111213141516int numberOf1sInRange(int n) &#123; string s=to_string(n); int m=s.size(); vector&lt;vector&lt;int&gt;&gt; dp(m,vector&lt;int&gt;(m,-1)); function&lt;int(int,int,bool)&gt; f = [&amp;](int i,int cnt,bool limit)-&gt;int&#123; if(i==m) return cnt; if(!limit &amp;&amp; dp[i][cnt]&gt;=0) return dp[i][cnt]; int res=0; for(int d=0,up=limit?s[i]-&#x27;0&#x27;:9;d&lt;=up;++d)&#123; res += f(i+1,cnt+(d==1),limit&amp;&amp;d==up); &#125; if(!limit) dp[i][cnt]=res; return res; &#125;; return f(0,0,true);&#125; 1～n 中特殊整数的次数(每个数位互不相同)：须考虑前导零 f(i,mask,isLimit,isNum) 表示构造从左往右第 i 位及其之后数位的合法方案数： mask：表示前面选过的数字集合，即第 i 位要选的数字不能在 mask 中。 isNum：表示 i 前面的数位是否填了数字。若为假，则当前位可以跳过（不填数字），或者要填入的数字至少为 1；若为真，则必须填数字，且要填入的数字可以从 0 开始。 Folding 1234567891011121314151617int countSpecialNumbers(int n) &#123; auto s = to_string(n); int m = s.length(), dp[m][1 &lt;&lt; 10]; memset(dp, -1, sizeof(dp)); function&lt;int(int,int,bool,bool)&gt;f=[&amp;](int i,int mask,bool is_limit,bool is_num)-&gt;int&#123; if (i==m) return is_num; if (!is_limit &amp;&amp; is_num &amp;&amp; dp[i][mask]&gt;=0) return dp[i][mask]; int res = 0; if (!is_num) res = f(i+1, mask, false, false); // 可以跳过当前数位 for (int d=1-is_num, up=is_limit?s[i]-&#x27;0&#x27;:9; d&lt;=up; ++d) // 枚举要填入的数字d if ((mask&gt;&gt;d &amp; 1) == 0) // d不在mask中 res += f(i+1, mask|(1&lt;&lt;d), is_limit &amp;&amp; d==up, true); if (!is_limit &amp;&amp; is_num) dp[i][mask] = res; return res; &#125;; return f(0, 0, true, false);&#125; 二分法 参考链接: 二分法题单 Lower_bound12345678910// 返回首个≥target的元素下标int Bsearch(vector&lt;int&gt;&amp; nums,int target)&#123; int l = 0,r = nums.size() - 1; while(l &lt; r)&#123; int m = l + r &gt;&gt; 1; if(nums[m] &lt; target) l = m + 1; else r = m; &#125; return nums[l] == target ? l : -1;&#125; 常见模板 l = mid可能导致相邻两元素时陷入死循环：区间 [l, r] 落入 [mid, r] 后实际没变 123456789101112131415161718// 升序 从左向右找while(l &lt; r) &#123; int mid = l + r &gt;&gt; 1; if(flag) l = mid + 1; else r = m;&#125;// 升序 从右向左找while(l &lt; r) &#123; int mid = l + r + 1 &gt;&gt; 1; if(flag) r = mid - 1; else l = mid;&#125;while(l &lt;= r)&#123; int mid = l + r &gt;&gt; 1; if(flag) ans = mid, l = mid + 1; // 需记录答案 else r = mid - 1;&#125; 旋转数组面试题 10.03. 搜索旋转数组：查找值（有重复，返回最小索引） 12345678910111213141516171819202122int search(vector&lt;int&gt;&amp; arr, int target) &#123; int n = arr.size(), l = 0, r = n - 1; while (l &lt;= r) &#123; int m = l + r &gt;&gt; 1; if (arr[m] == target) &#123; // 重复选首个下标 while (m &amp;&amp; arr[m - 1] == arr[m]) m--; return m; &#125; if (arr[l] &lt; arr[m]) &#123; // 左侧有序 if (arr[l] &lt;= target &amp;&amp; arr[m] &gt; target) r = m - 1; else l = m + 1; &#125; else if (arr[l] &gt; arr[m]) &#123; // 右侧有序 if (arr[m] &lt; target &amp;&amp; arr[r] &gt;= target) l = m + 1; else r = m - 1; &#125; else &#123; l++; &#125; &#125; return -1;&#125; 寻找旋转排序数组中的最小值 II：找最小值（有重复） 1234567891011int findMin(vector&lt;int&gt;&amp; nums) &#123; int l = 0, r = nums.size() - 1; while (l &lt; r) &#123; if (nums[l] &lt; nums[r]) break; // 特判 case: [1,2,3 ...] int m = l + r &gt;&gt; 1; if (nums[m] &lt; nums[l]) r = m; else if (nums[m] &gt; nums[l]) l = m + 1; else l++; &#125; return nums[l];&#125; 数学问题FindK找第K小的元素 123456789101112131415161718192021int FindK(vector&lt;int&gt;&amp; a, int k)&#123; int l = 0, r = a.size() - 1; while(l &lt;= r)&#123; int pivot = Part(a, l, r); if (pivot == k) return a[k]; else if (pivot &gt; k) r = pivot - 1; else l = pivot + 1; &#125; return -1;&#125;int Part(vector&lt;int&gt;&amp; a, int l, int r)&#123; int pivot = a[l]; while(l &lt; r ) &#123; while(l &lt; r &amp;&amp; a[r] &gt;= pivot) r--; a[l] = a[r]; while(l &lt; r &amp;&amp; a[l] &lt;= pivot) l++; a[r] = a[l]; &#125; a[l] = pivot; return l;&#125; 找两个有序数组中第K大 Folding 12345678910111213141516171819int findK(vector&lt;int&gt;&amp; a, vector&lt;int&gt;&amp; b, int k)&#123; int m = a.size(), n = b.size(); int i = 0, j = 0; while(true) &#123; if(i == m) return b[j + k - 1]; if(j == n) return a[i + k - 1]; if(k == 1) return min(a[i], b[j]); int ir = min(m - 1, i + k / 2 - 1); int jr = min(n - 1, j + k / 2 - 1); if (a[ir] &lt;= b[jr]) &#123; k -= ir + 1 - i; i = ir + 1; &#125; else &#123; k -= jr + 1 - j; j = jr + 1; &#125; &#125;&#125; 找[1,n]中字典序第K大 Folding 1234567891011121314151617181920212223242526272829// 前缀为 prefix 且不超过 n 的数long get_count(long prefix, long n) &#123; long cnt = 0; long a = prefix, b = prefix + 1; // example : prefix = 1, n = 123: // cnt += 2 - 1 // cnt += 20 - 10 // cnt += 124 - 100 while (a &lt;= n) &#123; cnt += min(n + 1, b) - a; a *= 10; b *= 10; &#125; return cnt;&#125;int findKthNumber(int n, int k) &#123; int prefix = 1, p = 1; // 字典序前缀 prefix, 当前为第 p 个数 while (p &lt; k) &#123; int cnt = get_count(prefix, n); if (p + cnt &gt; k) &#123; // step in tree&#x27;s next level prefix *= 10; p++; &#125; else &#123; // step to other node in same level prefix++; p += cnt; &#125; &#125; return prefix;&#125; 快慢指针环形链表 II：输入一个链表，输出环的入节点，否则返回空指针 题解：实质为链表找环路问题：Floyed判圈法。从head开始，指针fast和slow每次前进2、1步，若无环则能走到尽头，否则两者会相遇。第一次相遇时，令fast&#x3D;head，此后fast和slow每次均前进一步，第二次相遇时节点即为入环节点。 123456789101112131415ListNode* detectCycle(ListNode* head) &#123; ListNode *fast = head, *slow = head; while (fast-&gt;next &amp;&amp; fast-&gt;next-&gt;next) &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if (slow == fast) break; &#125; if (!fast-&gt;next || !fast-&gt;next-&gt;next) return nullptr; fast = head; while (fast != slow) &#123; slow = slow-&gt;next; fast = fast-&gt;next; &#125; return fast;&#125; 快乐数：判断正整数 n 是不是快乐数，其定义为： 每次将该数替换为其各位数字的平方和 无限循环这个过程，若最终变为 1 就是快乐数，否则不是 题解：N1-&gt;N2-&gt;...-&gt;Ni的过程可以看作链表，且一定有环，分为两种情况 a-&gt;b-&gt;c-&gt;b-&gt;c...不合法 a-&gt;b-&gt;c-&gt;1-&gt;1...合法，即快慢指针的值相等时为1 快速幂123456789double quickMul(double x, int N)&#123; double ans = 1.0; while(N) &#123; if(N &amp; 1) ans *= x; x *= x; N &gt;&gt;= 1; &#125; return ans;&#125; 因数&#x2F;倍数&#x2F;质数1234567891011121314151617181920// 最大公因数int gcd(int a, int b) &#123; return b == 0 ? a : gcd(b, a % b);&#125;// 最小公倍数int lcm(int a, int b) &#123; return a * b / gcd(a, b);&#125;// 质数（小于n）vector&lt;bool&gt; primes(int n) &#123; vector&lt;bool&gt; prime(n, true); prime[0] = prime[1] = false; for(int i = 2; i &lt; n; ++i)&#123; if(!prime[i]) continue; for(int j = 2 * i; j &lt; n; j += i) &#123; prime[j] = false; &#125; &#125; return prime;&#125; 位运算与 (处理某位) 取低位第k位：1&amp;(num&gt;&gt;k) 将最低位的1变为0：n&amp;(n-1)，如110100-&gt;110000 保留最低位1其他清0：n&amp;(-n)，如110100-&gt;000100 异或 (找缺失数、出现一次数) 第k位取反：num^(1&lt;&lt;k) x ^ 000 &#x3D; x x ^ 111 &#x3D; ~x x ^ x &#x3D; 0 1. 只出现一次的数字：数组中每个数都出现两次，找出仅有出现一次的 题解：遍历全部异或一遍，x^x&#x3D;0, x^0&#x3D;x，最后结果就是仅出现一次的 2. 丢失的数字：找出范围0～n的数组中缺少的一个数 题解：先将0～n异或一遍，再异或该数组，这样缺失值即仅出现一次 摩尔投票法 一次遍历，统计次数超过 n/k 的数，可知这样的数最多 k-1个 假设当前遍历到的元素为 x ： 如果 x 本身是候选者，票数加一 如果 x 不是候选者，检查是否有候选者票数为 0 若有，则让 x 代替其成为候选者，记录票数为 1 若无，则让所有候选者票数减一 最后二次遍历，将票数符合要求的候选者加到答案 Folding 123456789101112131415161718192021222324252627282930313233343536vector&lt;int&gt; majorityElement(vector&lt;int&gt;&amp; nums) &#123; vector&lt;int&gt; ans; const int m=2; //adjust vector&lt;int&gt; elem(m),vote(m); for(auto x:nums)&#123; bool flag=false; // x是候选者，票+1 for(int i=0;i&lt;m;++i) if(vote[i]&gt;0 &amp;&amp; elem[i]==x)&#123; vote[i]++; flag = true; break; &#125; if(flag) continue; flag = false; // x非候选者，且有空闲候选位 for(int i=0;i&lt;m;++i) if(vote[i]==0)&#123; elem[i]=x; vote[i]++; flag = true; break; &#125; if(flag) continue; for(int i=0;i&lt;m;++i) // x非候选者，且无空闲候选位 vote[i]--; &#125; vector&lt;int&gt; cnts(m); for(auto x:nums)&#123; for(int i=0;i&lt;m;++i) if(x==elem[i] &amp;&amp; vote[i]&gt;0) cnts[i]++; &#125; for(int i=0;i&lt;m;++i)&#123; if(vote[i]&gt;0 &amp;&amp; cnts[i]&gt;nums.size()/3) ans.push_back(elem[i]); &#125; return ans;&#125; 约瑟夫环123456int lastRemaining(int n, int m) &#123; int ans=0; for(int i = 2;i &lt;= n; ++i) ans = (ans + m) % i; return ans;&#125; 随机化1.随机数生成 1234random_device rd;mt19937 gen(rd());uniform_int_distribution&lt;&gt; dis(1, 10);cout &lt;&lt; dis(gen) &lt;&lt; endl; 2.已知小范围随机数，得到一个大范围随机数 对于 randN = [1,n]，通过(randN-1) * N + randN 得到 [1,n*n] 范围的等概率随机数 3.已知小范围随机数，得到一个确定范围的随机数 先采用 1 得到更大范围的随机数 randK，然后对超过确定范围数进行拒绝 4.已知大范围随机数，得到一个小范围随机数 如果 N 是 K 的整数倍，可以通过 randN 一步得到 randK：randK = (randN % K) + 1; 单调栈 寻找下一个最&#x2F;更大值 柱状图中最大的矩形: 给定 n 个柱子的高度（宽度为 1），求能勾勒矩形的最大面积 题解：遍历每个高度，以当前高度为基准，寻找最大的宽度组成最大的矩形面积，也就是分别找左边&#x2F;右边首个小于当前高度的下标left、right。用递增的单调栈来确定这两个边界：right 为当前遍历的下标 i，left 为单调栈中保存的前一个下标（高度更低）。 12345678910111213141516int largestRectangleArea(vector&lt;int&gt;&amp; heights) &#123; vector&lt;int&gt; h&#123;0, 0&#125;; h.insert(h.begin() + 1, heights.begin(), heights.end()); int ans = 0; stack&lt;int&gt; st; for (int i = 0; i &lt; h.size(); ++i) &#123; while (!st.empty() &amp;&amp; h[i] &lt; h[st.top()]) &#123; // &lt;=也可以 int height = h[st.top()]; st.pop(); if (st.empty()) continue; int width = i - st.top() - 1; ans = max(ans, height * width); &#125; st.push(i); &#125; return ans;&#125; 滑动窗口最大值：求数组中每个长度为K的区间内的最大值 在窗口内，若 nums[j] &lt; nums[j+1] 则 nums[j] 没用了可以扔掉，因为有更大的值后出窗口 因此用一个单调递减队列（deque）维护窗口内有意义的元素，直接 deque.front() 获得最大值 用 l, i 维护窗口左右边界，从队列中 pop 的条件是窗口大小固定为 k，即 i - l == k 并查集12345678910111213141516171819202122232425int n = 1005; // n根据题目中节点数量而定vector&lt;int&gt; father = vector&lt;int&gt;(n);void init() &#123; for (int i = 0; i &lt; n; ++i) &#123; father[i] = i; &#125;&#125;// 并查集里寻根的过程int find(int u) &#123; return u == father[u] ? u : father[u] = find(father[u]); // 路径压缩&#125;// 判断 u 和 v是否找到同一个根bool isSame(int u, int v) &#123; u = find(u); v = find(v); return u == v;&#125;// 将v-&gt;u 这条边加入并查集void join(int u, int v) &#123; u = find(u); v = find(v); if (u == v) return; father[v] = u;&#125; 字典树 剑指Offer II ：62-67 12345678910111213141516class Trie &#123;public: bool isWord; vector&lt;Trie*&gt; child; Trie(): isWord(false), child(26, nullptr) &#123;&#125; void insert(string&amp; s) &#123; Trie* p = this; for(auto c: s) &#123; if(p-&gt;child[c - &#x27;a&#x27;] == nullptr) p-&gt;child[c - &#x27;a&#x27;] = new Trie(); p = p-&gt;child[c - &#x27;a&#x27;]; &#125; p-&gt;isWord = true; &#125;&#125;; 添加与搜索单词：将一些 word 添加到 dict 中，用来判断能否与后续字符串匹配（含 ‘.’ 匹配符） Folding 1234567891011121314151617181920212223242526272829303132333435class WordDictionary &#123;public: bool end&#123;false&#125;; vector&lt;WordDictionary*&gt; childs; WordDictionary(): childs(26, nullptr) &#123;&#125; void addWord(string word) &#123; WordDictionary *w = this; for (auto c : word) &#123; if (!w-&gt;childs[c - &#x27;a&#x27;]) &#123; w-&gt;childs[c - &#x27;a&#x27;] = new WordDictionary(); &#125; w = w-&gt;childs[c - &#x27;a&#x27;]; &#125; w-&gt;end = true; &#125; bool search(string word) &#123; return find(word, 0, this); &#125; bool find(string&amp; word, int i, WordDictionary* w) &#123; if (i == word.size()) return w-&gt;end; if (isalpha(word[i])) &#123; // 单路径 return w-&gt;childs[word[i]-&#x27;a&#x27;] &amp;&amp; find(word, i + 1, w-&gt;childs[word[i] - &#x27;a&#x27;]); &#125; else &#123; // 通配符，需遍历多个分支，其一满足即可 for (auto c : w-&gt;childs) &#123; if (c &amp;&amp; find(word, i + 1, c)) return true; &#125; &#125; // 都走不通 return false; &#125;&#125;; 多路归并 查找和最小的 K 对数字 超级丑数：给定质数primes数组，丑数由其中任意质数累乘得到，求第k个丑数 DP-先求再存 求第k个丑数，需要遍历每个prime[i]与以有丑数dp[j]相乘的最小值，遍历prime复杂度O(n)，遍历已有丑数同为O(n)，对于后者可以考虑优化 直观上，prime[i]*dp[0]为最小，但为了防止重复乘dp[0]、dp[1]...，需要用next[i]记录prime[i]已经乘过了前几个丑数，即下次该从下一个（next[i]）丑数开始乘 具体流程，每求下一个丑数时，遍历prime[i]*dp[next[i]]找到最小值，对于每个最小令next[i]++ 123456789101112131415161718int nthSuperUglyNumber(int n, vector&lt;int&gt;&amp; primes) &#123; vector&lt;int&gt; next(primes.size(), 0), dp&#123;1&#125;; while (dp.size() &lt; n) &#123; int pid = -1, ugly = INT_MAX; for (int i = 0; i &lt; primes.size(); ++i) &#123; long tmp = (long)primes[i] * dp[next[i]]; if (tmp &lt; ugly) &#123; ugly = tmp; pid = i; &#125; &#125; next[pid]++; if (dp.back() &lt; ugly) &#123; // 去重 dp.push_back(ugly); &#125; &#125; return dp.back();&#125; 优先队列-先存再求12345678910111213141516171819// 时间复杂度高，可能乘法溢出int nthSuperUglyNumber(int n, vector&lt;int&gt;&amp; primes) &#123; priority_queue &lt;double, vector&lt;double&gt;, greater&lt;double&gt;&gt; q; unordered_set&lt;int&gt; s; s.insert(1); // 去重 int answer = 1; for (int i = 1; i &lt; n; ++i)&#123; for (int j: primes) &#123; int multi = answer * j; if(!s.count(multi))&#123; q.push(multi); s.insert(multi); &#125; &#125; answer = q.top(); q.pop(); &#125; return answer;&#125; 区间相关滑动窗口最小覆盖子串：返回 s 中涵盖 t 所有字符的最小子串 题解：每轮遍历窗口右扩 1，更新有效字符数 valid；valid 等于 t 长度时，保存结果，不断尝试收缩左窗口； 1234567891011121314151617181920212223string minWindow(string s, string t) &#123; int valid = 0, ans_idx = -1, ans_len = INT_MAX; unordered_map&lt;char, int&gt; mp; for (auto c: t) mp[c]++; for (int i = 0, l = 0; i &lt; s.size(); ++i) &#123; char c = s[i]; if (mp.count(c)) &#123; if (--mp[c] &gt;= 0) valid++; &#125; while (valid &gt;= t.size()) &#123; if (i - l + 1 &lt; ans_len) &#123; ans_len = i - l + 1; ans_idx = l; &#125; char d = s[l]; if (mp.count(d)) &#123; if (++mp[d] &gt; 0) valid--; &#125; l++; &#125; &#125; return ans_idx &lt; 0 ? &quot;&quot; : s.substr(ans_idx, ans_len);&#125; 字符串的排列：判断 s1 的排列之一是否为 s2 的子串 题解：每轮遍历窗口右扩 1，更新合法字符数 valid ；窗口大于 s1 长度时，收缩左窗口 1 并更新；期间 valid==s1.size() 时返回 true 1234567891011121314151617181920bool checkInclusion(string s1, string s2) &#123; int valid = 0; unordered_map&lt;char, int&gt; mp; for (auto c: s1) mp[c]++; for (int i = 0, l = 0; i &lt; s2.size(); ++i) &#123; char c = s2[i]; if (mp.count(c)) &#123; if (--mp[c] &gt;= 0) valid++; &#125; if (i - l == s1.size()) &#123; char d = s2[l]; if (mp.count(d)) &#123; if (++mp[d] &gt; 0) valid--; &#125; l++; &#125; if (valid == s1.size()) return true; &#125; return false;&#125; 前缀和 前缀与后缀和的统一写法，但需要特殊处理 0 个元素的前缀&#x2F;后缀和 12345678910vector&lt;int&gt; nums&#123;1,0,2,4,2,3,1&#125;;// pre_sum[i] 为 [0, ..., i]，suf_num[i] 为 [i, ..., n-1]vector&lt;int&gt; pre_sum(nums.size()), suf_sum(nums.size());pre_sum[0] = nums[0];for (int i = 1; i &lt; nums.size(); i++) pre_sum[i] = pre_sum[i - 1] + nums[i];suf_sum.back() = nums.back();for (int i = nums.size() - 2; i &gt;= 0; --i) suf_sum[i] = suf_sum[i + 1] + nums[i]; 差分 区间修改（同增同减）- 求修改后的数组 原数组为a，差分数组为b 12b[0] = a[0]b[i] = a[i] - a[i - 1] 对区间 [x1, x2] 所有值加 y 12b[x1] += yb[x2 + 1] -= y // x2 + 1 &lt; n 根据差分数组求原数组 12a[0] = b[0]a[i] = a[i - 1] + b[i] 树状数组 单点修改 - 区间查询、单点查询 区域和检索 - 数组可修改：求区间和且会更新数组元素 1234567891011121314151617181920212223242526272829vector&lt;int&gt; tree; // tree[i] 为前 i-1 前缀和vector&lt;int&gt; nums; // 原数组int lowBit(int x) &#123; return x &amp; -x;&#125;// 把序列第 index 个数增加 val，O(nlgn)void add(int index, int val) &#123; while (index &lt; tree.size()) &#123; tree[index] += val; index += lowBit(index); &#125;&#125;// 查询前 index 个元素的前缀和，O(nlgn)int preSum(int index) &#123; int sum = 0; while (index &gt; 0) &#123; sum += tree[index]; index -= lowBit(index); &#125; return sum;&#125;int main()&#123; // input nums tree.assign(nums.size() + 1, 0); for(int i = 0; i &lt; nums.size(); ++i)&#123; add(i + 1, nums[i]); &#125;&#125; 线段树 区间修改 - 区间查询、单点查询 一些笔试题目对称飞行器 如果没有对称飞行器，就是一道普通广搜题。但是加了飞行器，如果飞行次数没有限制，也是一道普通广搜题只是除了四个direction多了一个分支。可是飞行器有次数限制。那么如果用(x,y)点的状态应该再加一个维度：飞行次数z。因为当z1不等于z2时，P(x,y,z1)和Q(x,y,z2)是两种不同的状态。 假设z1 &lt; z2，即P和Q在相同的横纵坐标，但是P剩余的飞行次数更多。如果从(x,y,z2)走到终点的最优解是n步，则从(x,y,z1)一定可以走n步到达终点。此时P状态走到最优点的步数更少。所以在层次遍历的最优解中不该包含z2. 也就是说在向z增加转移的过程中，我们应该看 matrix[x][y][0]...matrix[x][y][z] 中是否已经有为1的点，如果有就不必再在第z层再走x，y。 Folding 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869struct Node &#123; int x, y; int fly; Node() = default; Node(int x_, int y_, int f_): x(x_), y(y_), fly(f_) &#123;&#125;&#125;;int n, m;queue&lt;Node&gt; q;vector&lt;vector&lt;int&gt;&gt; vis;vector&lt;vector&lt;char&gt;&gt; board;vector&lt;int&gt; delta&#123;-1, 0, 1, 0, -1&#125;;bool check(Node&amp; node) &#123; return node.x &gt;= 0 &amp;&amp; node.x &lt; n &amp;&amp; node.y &gt;= 0 &amp;&amp; node.y &lt; m &amp;&amp; board[node.x][node.y] != &#x27;#&#x27; &amp;&amp; !vis[node.x][node.y]; &#125;int bfs(int i, int j) &#123; q.emplace(i, j, 5); vis[i][j] = 1; int level = 0; while (!q.empty()) &#123; int size = q.size(); while (size--) &#123; Node cur = q.front(); q.pop(); if (board[cur.x][cur.y] == &#x27;E&#x27;) &#123; return level; &#125; for (int i = 0; i &lt;= 4; ++i) &#123; Node tmp; if (i == 4) &#123; // fly if (cur.fly &gt; 0) &#123; tmp.x = n - 1 - cur.x; tmp.y = m - 1 - cur.y; tmp.fly = cur.fly - 1; &#125; &#125; else &#123; tmp.x = cur.x + delta[i]; tmp.y = cur.y + delta[i + 1]; tmp.fly = cur.fly; &#125; if (check(tmp)) &#123; vis[tmp.x][tmp.y] = 1; q.push(tmp); &#125; &#125; &#125; level++; &#125; return -1;&#125;int main() &#123; cin &gt;&gt; n &gt;&gt; m; board.assign(n, vector&lt;char&gt;(m, 0)); vis.assign(n, vector&lt;int&gt;(m, 0)); for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; m; ++j) &#123; cin &gt;&gt; board[i][j]; &#125; &#125; for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; m; ++j) &#123; if (board[i][j] == &#x27;S&#x27;) &#123; cout &lt;&lt; bfs(i, j) &lt;&lt; endl; return 0; &#125; &#125; &#125;&#125; 自定义类型的map/set需要重载hash、&lt;和= 123456789101112131415161718struct Node &#123; int a, b; bool operator&lt;(const Node&amp; other) const &#123; return a == other.a &amp;&amp; b == other.b; &#125;; bool operator==(const Node&amp; other) const &#123; return a == other.a &amp;&amp; b == other.b; &#125;;&#125;;template&lt;&gt;struct hash&lt;Node&gt; &#123; size_t operator()(const Node&amp; node) const &#123; return hash&lt;int&gt;()(node.a) &amp; hash&lt;int&gt;()(node.b); &#125;&#125;;unordered_map&lt;Node, int&gt; mp;unordered_set&lt;Node&gt; st;","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"STL","slug":"CPP/STL","date":"2023-02-01T08:39:04.000Z","updated":"2025-03-06T09:01:58.037Z","comments":true,"path":"2023/02/01/CPP/STL/","permalink":"http://example.com/2023/02/01/CPP/STL/","excerpt":"","text":"STL函数1234567891011121314151617/* 非修改式 */find(i,j,t) //区间内首个值t的迭代器search(i,j,p,q)//区间[i,j)中首个与[p,q)相同的迭代器count(i,j,t) //区间内值t个数equal(i,j,p,q) //两区间内值是否相同/* 修改式 */reverse(i,j)fill(i,j,t) //区间内值设置为tremove(i,j,t) //删除区间内t值unique(i,j) //去连续重/* 排序相关 */sort(i,j,comp)stable_sort(i,j,comp)lower/upper_bound(i,j,t,comp)min/max_element(i,j,comp) //返回最值迭代器 VectorEmplace vs Push1. push 和 emplace 考虑向vector插入字符串的场景，vector的push_back被按左值和右值分别重载： 12345678template &lt;class T, class Allocator = allocator&lt;T&gt;&gt;class vector &#123;public: … void push_back(const T&amp; x); //插入左值 void push_back(T&amp;&amp; x); //插入右值 …&#125;; 在调用 vec.push_back(&quot;xyzzy&quot;) 时发生如下过程： 第一次构造函数，从 const char[6] 的 xyzzy 创建一个 string 临时对象，这个对象是右值 临时对象被传递给 push_back 的右值重载函数，绑定到右值引用形参 x。第二次移动构造函数将 x 副本拷贝到 vector 内部，因为 x 在它被拷贝前被转换为一个右值，成为右值引用 在 push_back 返回之后，string 临时对象被销毁，发生一次析构 相比之下，emplace_back 使用完美转发，使用传递的实参直接在 vector 内部构造一个 string，仅用了一次构造函数 2. 何时 emplace 优于 push 值被构造到容器中，而不是直接赋值 传入的类型与容器的元素类型不一致 容器不拒绝已经存在的重复值：emplace 会创建新值的节点，以便将该节点与容器中节点的值比较。如果值已经存在，置入操作取消，创建的节点被销毁，意味着构造和析构时的开销被浪费了，如 map, unordered_map 3. 为什么用 emplace_back 时报错缺失拷贝构造函数 直观上，emplace_back() 原地构造，不会发生拷贝&#x2F;移动构造。但如果 vector 没有预先 reserve 空间，在空间扩张过程中就会发生拷贝。 [TODO] 默认调用拷贝构造函数，将其 delete 标记后，变成了调用移动构造函数，具体机制是啥？另外虽然 reserve 预分配空间能实现 真·原地构造，全程不需要拷贝&#x2F;移动构造函数，但如果 delete 掉这俩函数就过不了编译，那么能推出编译层面是硬性要求？ 线程安全core dump的情况单线程写入，但是并发读的时候，由于潜在的内存重新申请和对象复制问题，会导致读方的迭代器失效多个写方并发的push_back() 解法一：加锁 互斥锁性能较差 lock_guard&lt;mutex&gt;读写锁（共享独占锁）适合读多写少，shared_lock&lt;shared_mutex&gt; 与 unique_lock&lt;shared_mutex&gt; 解法二：lock-free 固定vector的大小，避免动态扩容（无push_back），但同时对一个下标读写还是有问题 初始化 resize 好 N 个对象（预留内存+构造函数），可以改成环形队列缓解压力 多线程读写都通过容器的下标访问元素，不要 push_back新元素 把队列头的下标定义成原子变量 std::atomic vector::operator[] 可返回除了 bool 以外的任何类型 布尔数组vector&lt;bool&gt; 使用打包形式（packed form）表示它的bool，用 unsigned long 作为存储 bool 的基本类型，每个bool占一个bit。 这给 vector::operator[] 带来了问题，因为 vector&lt;T&gt;::operator[] 应当返回一个 T&amp;，但是C++禁止对bits的引用，无法返回 bool&amp;，所以 vector&lt;bool&gt;::operator[] 返回一个行为类似于 bool&amp; 的对象 vector&lt;bool&gt;::reference vector&lt;bool&gt;::reference 为了能模拟 bool&amp; 的行为，可以向 bool 隐式转化（而非&amp;bool），但这在某些情况会有问题： 123vector&lt;bool&gt; bits&#123;true, true, false&#125;;bool b1 = bits[2]; // boolauto b2 = bits[2]; // vector&lt;bool&gt;::reference 可能未定义行为 b1：operator[] 返回 vector&lt;bool&gt;::reference 对象，通过隐式转换赋值给 bool 变量 b1，表示第五个bit的值符合预期 b2：operator[] 返回 vector&lt;bool&gt;::reference 对象，auto推导 b2 的类型为 vector&lt;bool&gt;::reference，但此对象没有第五bit的值，具体取决于实现 自定义比较1.Lamda12345auto cmp=[&amp;](const node&amp; a, const node&amp; b) &#123; return a.y &lt; b.y || a.y == b.y &amp;&amp; a.x &lt; b.x;&#125;;sort(a.begin(), a.end(), cmp);set&lt;node,decltype(cmp)&gt; st(cmp); 2.仿函数 广泛适用于 STL：sort, set, map, priority_queue, lower_bound, merge 缺点：不能访问外部对象 123456789struct cmp&#123; bool operator()(const node&amp; a, const node&amp; b) const &#123; return a.y &lt; b.y || a.y == b.y &amp;&amp; a.x &lt; b.x; &#125;&#125;;sort(a.begin(), a.end(), cmp);set&lt;node,cmp&gt; st;map&lt;node,int,cmp&gt; m;priority_queue&lt;node,vector&lt;node&gt;, cmp&gt; p; 3.比较符重载1.结构体内部运算符重载 12345678struct node&#123; int x,y; bool operator&lt;(const node &amp;b) const &#123; if(x == b.x) return y &lt; b.y; return x &lt; b.x; &#125;&#125; 2.外部运算符重载 12345bool operator&lt; (const node &amp;a, const node &amp;b) &#123; if(a.x == b.x) return a.y &gt; b.y; return a.x &gt; b.x;&#125; STL原理空间配置器new 和 delete 都包含两阶段操作： 对于 new 来说，先调⽤ ::operator new 分配内存，然后构造对象。 对于 delete 来说，先析构对象，然后调⽤ ::operator delete 释放空间。 STL allocator 将这两个阶段操作区分开来： 对象构造由 ::construct() 负责；对象释放由 ::destroy() 负责。 内存配置由 alloc::allocate() 负责；内存释放由 alloc::deallocate() 负责； alloc ⼀级配置器 第⼀级配置器以 malloc(), free(), realloc() 执⾏实际的内存配置、释放和重配置操作，并实现类似C++ new-handler 的机制（自定义异常处理、尝试释放内存、abort等）。 第⼀级配置器的 allocate() 和 reallocate() 在调⽤malloc() 和 realloc() 不成功后，改调⽤oom_malloc() 和oom_realloc()。 oom_malloc() 和 oom_realloc() 都有内循环，不断调⽤“内存不⾜处理例程”，期望某次调⽤后，获得⾜够的内存⽽完成任务。如果⽤户并没有指定“内存不⾜处理程序”，STL 便抛出异常或调⽤exit(1)。 alloc ⼆级配置器内存池原理：每次配置一大块内存，进行切分小区块，二级配置器将这些不同大小的区块用16个自由链表维护，并将小额内存需求量上调至8的倍数，这些内存空间是cookie free的 1. 空间申请 2. 空间释放 3. 重新填充 free_lists 当发现 free_list 中没有可⽤区块时，就会调⽤ refill() 为free_list 重新填充空间； 新的空间将取⾃内存池，用 chunk_alloc() 分配； 默认分配20个新区块，若内存池空间不足也可能⼩于 20。 4. 内存池 从内存池中取空间“切分”出free-list，是chunk_alloc()在工作： 若内存池还有余额空间 水量&#x3D;0：调用malloc()从heap中配置内存（2倍需求量） 水量&gt;0：调出最多20区块给free-list 系统堆内存空间不足，malloc()失败 从free-list中向上空间更大且未用的区块 若没找到则调用一级配置器，再失败则bad_alloc() Vector与array的区别 创建方式上不同：vector无需指定大小只需指定类型，array需要同时指定类型和大小 内存使用上不同：vector需要占据比array更多的内存，因为其内存空间大小是动态可变的 效率上不同：vector效率偏低，空间扩容时可能整个位置发生改变，需要将原来空间里的数据拷贝过去 下标类型不同：vector为vector::size_type，数组下标则是 size_t swap操作不同：vector是将引用进行交换，效率高；array是进行值的交换，效率低 注意：size_t表示元素个数，能表示的范围和系统位数有关，因为int、long是固定的可能不够用；vector::size_type和size_t同理，但其是容器概念 Traits增加⼀层中间的模板 iterator_traits ，以获取迭代器的型别，其原理为： 模板参数推导机制：获取迭代器型别 内嵌类型定义机制：推导函数返回值类型 偏特化机制：处理原⽣指针和const指针 iterator_traits：特性萃取机，负责萃取迭代器的特性，有以下五种： 12345value_type //迭代器所指对象的型别difference_type //两个迭代器之间的距离pointer //指针所指向的型别reference //迭代器所引用的型别iterator_category //迭代器类别input,output,forward,bidirectional,random access type_traits：负责萃取型别的特性。可以针对不同的型别，在编译期间完成函数派送决定。例如，当容器内的元素类型拥有非平凡拷贝赋值函数时，应该多次调用拷贝赋值函数进行拷贝，但如果拥有平凡拷贝赋值函数，直接 memcpy() 或 memmove() 对元素进行内存拷贝就行了。 12345has_trivial_default_constructorhas_trivial_copy_constructorhas_trivial_assignment_operatorhas_trivial_destructoris_POD_type Traits编程 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;template &lt;class T&gt;struct MyIter &#123; typedef T value_type; // 内嵌型别声明 T* ptr; MyIter(T* p = 0) : ptr(p) &#123;&#125; T&amp; operator*() const &#123; return *ptr; &#125;&#125;;// class typetemplate &lt;class T&gt;struct my_iterator_traits &#123; typedef typename T::value_type value_type;&#125;;// 指针偏特化template &lt;class T&gt;struct my_iterator_traits&lt;T*&gt; &#123; typedef T value_type;&#125;;// const偏特化template &lt;class T&gt;struct my_iterator_traits&lt;const T*&gt; &#123; typedef T value_type;&#125;;// 使用例：类型询问 iterator_traits&lt;I&gt;::value_type// 如果是指针则特化版本直接回答，否则询问 T::value_type.template &lt;class I&gt;typename my_iterator_traits&lt;I&gt;::value_type Func(I ite) &#123; std::cout &lt;&lt; &quot;normal version&quot; &lt;&lt; std::endl; return *ite;&#125;int main(int argc, const char *argv[]) &#123; MyIter&lt;int&gt; ite(new int(6)); std::cout&lt;&lt;Func(ite)&lt;&lt;std::endl;//print=&gt; 6 int *p = new int(7); std::cout&lt;&lt;Func(p)&lt;&lt;std::endl;//print=&gt; 7 const int k = 8; std::cout&lt;&lt;Func(&amp;k)&lt;&lt;std::endl;//print=&gt; 8&#125; DequeDeque是双向开口的连续线性空间，实际是由动态的以分段空间组合而成。能在常数时间进行头尾操作，提供随机访问迭代器。 Deque 采⽤⼀块所谓的 map 作为中控器，⼀⼩块连续空间中的每个元素都是指针，指向另外⼀段较⼤的连续线性空间，称之为缓冲区。 迭代器：Deque用 start 和 finish 两个迭代器指向首尾两端的连续空间。每个迭代器包含4个指针：first、cur、last指向缓冲区中，node二级指针是map中指向当前缓冲区指针的指针 扩容：首尾端的节点备⽤空间不⾜时，配置⼀个新的map，申请更⼤的空间，拷⻉元素过去，修改 map 和 start，finish 的指向。 删除：判断删除的位置是中间偏后还是中间偏前来进⾏移动。 Hashtable 冲突：用链地址法解决hash冲突（开放定址：线性探测、二次探测，再散列法） 构成：buckets用vector存储，迭代器只能向前，bucket维护的链表是自定义数据结构组成的linked-list 容量：hashtable的容量选择≥元素个数的质数（28个中）。当负载因子 loadFactor&lt;&#x3D;1时，hash表查找的期望复杂度为O(1)。当Hash表中每次发现loadFactor &#x3D;1时，就开辟一个原来桶数组的两倍空间，然后把原来的桶数组中元素全部重新哈希到新的桶数组中。 Set (红黑树)插入：按二叉搜索树插入z后涂红，可能违反红红性质，当z.p为左节点时分为三种情况： z红叔：将父叔爷结点染反色，视角移到爷结点迭代判断 z黑叔，且为右子节点：父节点左旋变为3 z黑叔，且为左子节点：爷节点右旋，并把父爷结点染色 2,3调整完毕，1不断向上迭代，最多旋转两次 删除：z为子节点直接删，有一个子节点则让子节点取代，两个子节点则用中序后继节点y取代自己（右子树最左的结点y，覆盖z的值），此时实际转为删除y，让y的右子节点x取代y 如果被删的y是黑色则需要调整，想象将y的黑色涂到x上弥补黑高 如果x是根，直接结束，相当于整体黑高减一 如果x为红，直接染黑结束 否则x为黑，则此时为双黑，需要变色、旋转把多余一层黑色向上传播，直到某个红结点或根 考虑x为左子节点时，兄弟结点w，分为四种情况： w红：将w染黑，父结点左旋变成情况2,3,4 w黑且子双黑：将w变红，视角移到上一层迭代判断 w黑且子右黑左红：将w右旋并染色，变成情况4 w黑且子右红：将父节点左旋并染色 1-&gt;2,3,4，2向上层迭代，3,4结束，最多旋转3次","categories":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/categories/CPP/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://example.com/tags/CPP/"}]},{"title":"Kafka","slug":"Storage/Kafka","date":"2023-01-22T16:07:08.000Z","updated":"2025-03-06T09:01:58.039Z","comments":true,"path":"2023/01/22/Storage/Kafka/","permalink":"http://example.com/2023/01/22/Storage/Kafka/","excerpt":"","text":"补充参考链接 kafka的使用场景为什么要使用 Kafka 消息队列解耦、削峰：传统的方式上游发送数据下游需要实时接收，如果上游在某些业务场景：例如上午十点会流量激增至顶峰，那么下游资源可能会扛不住压力。但如果使用消息队列，就可以将消息暂存在消息管道中，下游可以按照自己的速度逐步处理； 可扩展：通过横向扩展生产者、消费者和broker, Kafka可以轻松处理巨大的消息流； 高吞吐、低延迟：在一台普通的服务器上既可以达到10W&#x2F;s的吞吐速率； 容灾性：kafka通过副本replication的设置和leader／follower的容灾机制保障了消息的安全性。 kafka的高吞吐、低延迟是如何实现的1.顺序读写 Kafka使用磁盘顺序读写来提升性能。Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得Kafka写入吞吐量得到了显著提升 。每一个Partition其实都是一个文件 ，收到消息后Kafka会把数据插入到文件末尾。 2.页缓存（pageCache） PageCache是系统级别的缓存，它把尽可能多的空闲内存当作磁盘缓存使用来进一步提高IO效率； PageCache同时可以避免在JVM内部缓存数据，避免不必要的GC、以及内存空间占用。对于In-Process Cache，如果Kafka重启，它会失效，而操作系统管理的PageCache依然可以继续使用。 producer把消息发到broker后，数据并不是直接落入磁盘的，而是先进入PageCache。PageCache中的数据会被内核中的处理线程采用同步或异步的方式定期刷盘至磁盘。 Consumer消费消息时，会先从PageCache获取消息，获取不到才回去磁盘读取，并且会预读出一些相邻的块放入PageCache，以方便下一次读取。 如果Kafka producer的生产速率与consumer的消费速率相差不大，那么几乎只靠对broker PageCache的读写就能完成整个生产和消费过程，磁盘访问非常少 3.零拷贝 正常过程： 操作系统将数据从磁盘上读入到内核空间的读缓冲区中 应用程序（也就是Kafka）从内核空间的读缓冲区将数据拷贝到用户空间的缓冲区中 应用程序将数据从用户空间的缓冲区再写回到内核空间的socket缓冲区中 操作系统将socket缓冲区中的数据拷贝到NIC缓冲区中，然后通过网络发送给客户端 在这个过程中，可以发现， 数据从磁盘到最终发出去，要经历4次拷贝，而在这四次拷贝过程中， 有两次拷贝是浪费的。 从内核空间拷贝到用户空间； 从用户空间再次拷贝到内核空间； 除此之外，由于用户空间和内核空间的切换，会带来Cpu上下文切换，对于Cpu的性能也会造成影响；零拷贝省略了数据在内核空间和用户空间之间的重复穿梭；用户态和内核态切换时产生中断，耗时； 4.分区分段索引 Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。符合分布式系统分区分桶的设计思想。 通过这种分区分段的设计，Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操作的segment。为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。 5.批量处理 kafka发送消息不是一条一条发送的，而是批量发送，很大的提高了发送消息的吞吐量。 假设发送一条消息的时间是1ms，而此时的吞吐量就是1000TPS。但是假如我们将消息批量发送，1000条消息需要10ms，而此时的吞吐量就达到了1000*100TPS。而且这样也很大程度的减少了请求Broker的次数，提升了总体的效率。 Kafka架构基本概念 名词 概念 Producer 生产者（发送消息） Consumer 消费者（接收消息） ConsumerGroup 消费者组，可以并行消费同一topic中的消息 Broker 一个独立的kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求作出相应，返回已经提交到磁盘上的消息。可起到负载均衡、容错的作用。 Topic 主题，一个队列，可理解为按照消息的逻辑分类将消息划分为不同的topic Partition topic的物理分组，一个topic可以分为多个partition，每个partition是一个有序队列。可起到提高可扩展性，应对高并发场景的作用。 replica 副本，为保证集群的高可用性，kafka提供副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower leader 每个分区多个副本的主节点，生产者发送数据的对象，以及消费者消费数据的对象都是leader offset 对于Kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。 架构图Q1：Topic的分区及副本在broker上是如何分配的呢？ 这里涉及到两个参数： startIndex：第一个分区的第一个副本放置位置（P0-R0） nextReplicaShift：其他分区的副本的放置是依次后移的，间隔距离就是 nextReplicaShift 值。 Q2：Kafka的架构是基于什么设计思想呢？ 分治思想： topic分治：对于kafka的topic，我们在创建之初可以设置多个partition来存放数据，对于同一个topic的数据，每条数据的key通过哈希取模被路由到不同的partition中（如果没有设置key，则根据消息本身取模），以此达到分治的目的。 partition分治：为了方便数据的消费，kafka将原始的数据转化为”索引+数据“的形式进行分治，将一个partition对应一个文件转变为一个partition对应多个人不同类型的文件，分别为： .index文件：索引文件，用来记录log文件中真实消息的相对偏移量和物理位置，为了减少索引文件的大小，使用了稀疏索引 .log文件：用来记录producer写入的真实消息，即消息体本身； .timeindex文件：时间索引文件，类比.index文件，用来记录log文件中真实消息写入的时间情况，跟offset索引文件功能一样，只不过这个以时间作为索引，用来快速定位目标时间点的数据； 底层文件分治：不能将partition全部文件都放入一套 ”.index+.log+.timeindex“ 文件中，因此需要对文件进行拆分。kafka对单个.index文件、.timeindex文件、.log文件的大小都有限定（通过不同参数配置），且这3个文件互为一组。当.log文件的大小达到阈值则会自动拆分形成一组新的文件，这种将数据拆分成多个的小文件叫做segment，一个log文件代表一个segment。 Kafka工作流程生产流程 先从zk获取对应分区的leader在哪个broker broker进程上的leader将消息写入到本地log中 follower从leader上拉取消息，写入到本地log，并向leader发送ACK leader接收到所有的ISR中的Replica的ACK后，并向生产者返回ACK 消费流程 每个consumer都可以根据分配策略，获得要消费的分区 获取到consumer对应的leader处于哪个broker以及offset 拉取数据 消费者提交offset 分区策略生产者分区策略生产者写入消息到topic，Kafka将依据不同的策略将数据分配到不同的分区中： 轮询分区策略：按消息顺序进行分区顺序分配，是默认的策略，分配最平均 按key分区分配策略：按 key 取模，有可能会造成数据倾斜 随机分区策略 自定义分区策略 乱序问题：Partition 内部有序，跨 Partition 无序 消费者分区策略同一时刻，一条消息只能被组中的一个消费者实例消费： 消费者数&#x3D;分区数：一个分区对应一个消费者 消费者数&lt;分区数：一个消费者对应多个分区 消费者数&gt;分区数：多出来的消费者将不会消费任何消息 Range分配策略（范围分配策略）：Kafka默认的分配策略计算公式：n&#x3D;分区数量&#x2F;消费者数量m&#x3D;分区数量%消费者数量前m个消费者消费n+1个，剩余消费者消费n个以上图为例：n&#x3D;8&#x2F;3&#x3D;2 m&#x3D;8%3&#x3D;2 因此前2个消费者消费2+1&#x3D;3个分区，剩下1个消费者消费2个分区 RoundRobin分配策略（轮询分配策略）消费者挨个分配消费的分区：如下图，3个消费者共同消费8个分区第一轮：Consumer0–&gt;A-Partition0；Consumer1–&gt;A-Partition1；Consumer2–&gt;A-Partition2第二轮：Consumer0–&gt;A-Partition3；Consumer1–&gt;B-Partition0；Consumer2–&gt;B-Partition1第三轮：Consumer0–&gt;B-Partition2；Consumer1–&gt;B-Partition3 Striky粘性分配策略在没有发生rebalance跟轮询分配策略是一致的发生了rebalance（例如Consumer2故障宕机），轮询分配策略，重新走一遍轮询分配的过程。而粘性会保证跟上一次的尽量一致，只是将新的需要分配的分区，均匀的分配到现有可用的消费者中即可，这样就减少了上下文的切换 副本的ACK机制acks &#x3D; 0：生产者只管写入，不管是否写入成功，可能会数据丢失。性能是最好的acks &#x3D; 1：生产者会等到leader分区写入成功后，返回成功，接着发送下一条acks &#x3D; -1&#x2F;all：确保消息写入到leader分区、还确保消息写入到对应副本都成功后，接着发送下一条，性能是最差的分区中是有leader和follower的概念，为了确保消费者消费的数据是一致的，只能从分区leader去读写消息，follower做的事情就是同步数据。 Q&amp;Aoffset存在哪里？0.9版本前默认存在zk，但是由于频繁访问zk，zk需要一个一个节点更新offset，不能批量或分组更新，导致offset更新成了瓶颈。 新版 Kafka 消费的 offset 都会默认存放在 Kafka 集群中的一个叫 __consumer_offsets 的topic中。offset以消息形式发送到该topic并保存在broker中。这样consumer提交offset时，只需连接到broker，不用访问zk，避免了zk节点更新瓶颈。 leader选举策略2种leader：①broker的leader即controller leader ② partition的leader Controller leader当broker启动的时候，都会创建KafkaController对象，但是集群中只能有一个leader对外提供服务，这些每个节点上的KafkaController会在指定的zookeeper路径下创建临时节点，只有第一个成功创建的节点的KafkaController才可以成为leader，其余的都是follower。当leader故障后，所有的follower会收到通知，再次竞争在该路径下创建节点从而选举新的leader Partition leader由controller leader执行 从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合 调用配置的分区选择算法选择分区的leader 如何处理所有Replica都不工作？在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：等待ISR中的任一个Replica“活”过来，并且选它作为Leader选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader这就需要在可用性和一致性当中作出一个简单的折衷。如果一定要等待ISR中的Replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用。选择第一个“活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为Leader而作为consumer的数据源（前文有说明，所有读写都由Leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。 分区越多越好吗分区并不是越多越好，分区过多存在着以下弊端： producer内存成本增大、consumer线程开销增大 partition是kafka管理数据的基本逻辑组织单元，越多的partition意味着越多的数据存储文件（一个partition对应至少3个数据文件） 分区增多数据连续性下降 可用性降低 与数据库相比kafka的优势业务场景不同，底层数据结构不同，kafka数据存储对于功能要求较少，因此读写更快kafka存储数据（消息本身）的文件的数据结构是数组，数据间位置连续，顺序读取 or 追加写入的时间复杂度为O(1) 消费偏移的更新方式1.自动提交（默认方式） 以一定频率向 Kafka 自带的 topic(__consumer_offsets)进行偏移量提交这种方式也被称为 at most once，fetch到消息后就可以更新offset，无论是否消费成功。 2.手动提交 手动提交能对偏移量更加灵活精准地控制，以保证消息不被重复消费以及消息不被丢失。 对于手动提交offset主要有3种方式： 同步提交：提交失败的时候一直尝试提交，消费者线程会被阻塞，直到偏移量提交成功 or 提交过程中发生异常。限制了消息的吞吐量 异步提交：异步提交offset时不会阻塞，即使提交失败也不会重试，可以配合回调函数记录错误信息。当消费者异常关闭或者触发了再均衡前，如果偏移量还未提交就会造成偏移量丢失 异步+同步：对消费者进行异步批次提交并且在关闭时同步提交，这样即使上一次的异步提交失败，通过同步提交还能够进行补救，同步会一直重试直到成功。 一个消费者订阅数据 生产者将数据发送到指定topic中 Kafka将数据以partition的方式存储到broker上。Kafka支持数据均衡，例如生产者生成了两条消息，topic有两个partition，那么Kafka将在两个partition上分别存储一条消息 消费者订阅指定topic的数据，Kafka将当前的offset发给消费者，同时将offset写入consumer_offset topic中 消费者以特定的间隔（如100ms）向Kafka请求数据 当Kafka接收到生产者发送的数据时，Kafka将这些数据推送给消费者进行处理 当消费者处理完该条消息后，向Kafka broker发送已被消费的反馈，Kafka更新offset。 以上过程一直重复，直到消费者停止请求数据 消费者可以重置offset，从而可以灵活消费存储在Kafka上的数据 消费者组数据消费流程Kafka支持消费者组内的多个消费者同时消费一个topic，一个消费者组由具有同一个Group ID的多个消费者组成。具体流程如下： 生产者发送数据到指定的topic Kafka将数据存储到broker上的partition中 假设现在有一个消费者订阅了一个topic，topic名字为“test”，消费者的Group ID为“Group1” 此时Kafka的处理方式与只有一个消费者的情况一样 当Kafka接收到一个同样Group ID为“Group1”、消费的topic同样为“test”的消费者的请求时，Kafka把数据操作模式切换为分享模式，此时数据将在两个消费者上共享。 当消费者的数目超过topic的partition数目时，后来的消费者将消费不到Kafka中的数据。因为在Kafka给每一个消费者至少分配一个partition，一旦partition都被指派给消费者了，新来的消费者将不会再分配partition。即一个partition只能分配给一个消费者，一个消费者可以消费多个partition。","categories":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/categories/Storage/"}],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/tags/Storage/"}]},{"title":"Cpp trivial","slug":"Archive/Cpp trivial","date":"2022-11-01T11:39:04.000Z","updated":"2025-03-06T09:01:58.040Z","comments":true,"path":"2022/11/01/Archive/Cpp trivial/","permalink":"http://example.com/2022/11/01/Archive/Cpp%20trivial/","excerpt":"","text":"运算符优先级 优先级 类型 运算符 0 一元后缀运算符 () [] ++ – -&gt; . 1 一元前缀运算符 ++ – + - ! * &amp; (type) sizeof 2 算术运算符 * &#x2F; % &gt; ± 3 位运算符 &gt;&gt; &lt;&lt; 4 关系运算符 &gt;&#x3D; &gt; &lt; &lt;&#x3D; &gt; &#x3D;&#x3D; !&#x3D; 5 位逻辑运算符 &amp; &gt; ^ &gt; | 6 逻辑运算符 &amp;&amp; &gt; || 7 三元运算符 ? : 8 赋值运算符 &#x3D; +&#x3D; -&#x3D; *&#x3D; &#x2F;&#x3D; %&#x3D; … 9 逗号运算符 , 数组指针&amp;指针数组函数指针 &amp; 指针函数 123456/*** 函数指针 ***/void (*fun)(float) // 一个指针，指向参数float、返回值void的函数/*** 指针函数 ***/int* fun(float) // 一个函数，参数float、返回值为int*/**函数指针数组**/void (*s[5])(int) // s[5]说明是数组，数组的内容是void (*)(int)类型的函数指针 数组指针 &amp; 指针数组 12int (*a)[10] //一个指针，指向int[10]数组; 对应二级指针级别 int **a、int a[][]int *a[10] //一个数组，含10个int*变量 This 指向对象的首地址，只能在非静态成员函数中使用。当类的非静态成员函数访问非静态成员的时候，编译器会自动将对象本身的地址作为一个隐含参数 this 传递给函数，对各成员的访问均通过 this 进行。this 在成员函数的开始执行前构造，在成员的执行结束后清除。所以This不占用对象空间，会因编译器的不同放置到栈、寄存器、甚至全局变量中 用途：除了指向首地址，还能区分形参和成员变量名、返回类对象本身 Define 宏主要用于定义常量及书写复杂的内容，不同于typedef定义类型别名； 宏在预处理阶段完成替换，属于文本插入替换，比函数执行更快；而const、typedef在编译阶段。 宏不检查类型，对应函数没有返回值、没有参数类型； 宏不是语句，不在最后加分号。 Static 普通变量 可见性本文件，存储在静态存储区（默认初始化为0，全局生存期） 全局static变量在main()之前初始化，局部static在执行到声明处时才初始化 成员变量 属于类不占用对象空间，被所有对象共享，在类内定义时分配空间，必须在类定义外初始化 static成员变量可以被任意成员函数任意访问 成员函数 不具有this指针，不能被声明为const、虚函数 无法访问对象的非static成员变量&#x2F;函数 Const 普通变量 可见性本文件，存储在栈区(局部)、常量存储区(全局)或不分配内存在符号表（如基础数据类型const int a = 1） 成员变量 只在某个对象生命周期是常量，不同对象的const成员值可以不同 不能在类定义外部初始化，通过构造函数初始化列表初始化 成员函数 不能和static同时使用：static不能实例化和const矛盾 常量对象只能调用常量函数 想在const成员函数中修改类成员变量，可以用mutable修饰 与 Constexpr 对比 const可以通过const_cast类型转换（理解为只读变量），而常量表达式中的成员都是常量，常量表达式一旦确定将无法修改 const可以修饰编译期和运行期的常量，而constexpr只能修饰编译期的常量，必须在编译期就能计算出来，实现更多的编译期计算，但也会增加编译时间 在修饰成员函数时（尾部加const），const只能用于非静态成员函数，因为静态成员函数没有this指针，无法保证不修改对象成员信息；而constexpr可以和成员、非成员、构造函数一起使用，constexpr修饰自定义类时，需要提供常量构造函数 顶层与底层 const 顶层const：修饰的变量本身是一个常量，无法修改，指的是指针，顶层const不构成重载 底层const：修饰的变量所指向的对象是一个常量，指的是所指变量 Volatilevolatile 用在读取和写入不应被优化掉的内存上。是用来 处理特殊内存 的一个工具。跟多线程无关，不是一种同步手段。 最常见的“特殊”内存是用来做内存映射I&#x2F;O的内存。这种内存实际上是与外围设备（比如外部传感器或者显示器，打印机，网络端口）通信，而不是读写通常的RAM volatile 表示变量可以被某些编译器未知的因素（操作系统、硬件等）更改，告知编译器不应对这样的对象进行优化，否则可能打乱变量读写顺序、优化掉对变量的中间操作、两次读之间没修改就直接读上一次的备份。 顺序性：两个包含volatile变量的指令，编译后不可以乱序。但是在执行中还是可能会乱序，需要由内存屏障保证。 易变性：volatile告诉编译器，某个变量是易变的，当编译器遇到这个变量的时候，只能从变量的内存地址中读取这个变量，不可以从寄存器、或者其它任何地方读取。 Union联合（union）是一种节省空间的特殊的类，一个 union 可以有多个数据成员，但是在任意时刻只有一个数据成员可以有值。当某个成员被赋值后其他成员变为未定义状态。联合有如下特点： 默认访问控制符为 public 可以含有构造函数、析构函数 不能含有引用类型的成员 不能继承与被继承 不能含有虚函数 匿名 union 在定义所在作用域可直接访问 union 成员 匿名 union 不能包含 protected 成员或 private 成员 全局匿名联合必须是静态（static）的 Decltype返回表达式的类型而不计算 decltype(变量名)：可以获得变量精确类型 decltype(表达式)：（包括decltype((变量名))的情况）可以获得表达式引用类型；除非表达式的结果是纯右值，此时结果仍为值类型 Folding 123456789101112131415161718192021222324252627282930int i = 4;int arr[5] = &#123; 0 &#125;;int *ptr = arr;struct S&#123; double d; &#125;s ;void Overloaded(int);void Overloaded(char);//重载的函数int &amp;&amp; RvalRef();const bool Func(int);//规则一：推导为其类型decltype (arr) var1; //int[] 标记符表达式decltype (ptr) var2; //int* 标记符表达式decltype(s.d) var3; //doubel 成员访问表达式decltype(Overloaded) var4;//重载函数 编译错误。//规则二：将亡值，推导为类型的右值引用。decltype (RvalRef()) var5 = 1;//规则三：左值，推导为类型的引用。decltype ((i)) var6 = i; //int&amp;decltype (true?i:i) var7 = i;//int&amp; 条件表达式返回左值。decltype (++i) var8 = i; //int&amp; ++i返回i的左值。decltype(arr[5]) var9 = i;//int&amp;. []操作返回左值decltype(*ptr) var10 = i; //int&amp; *操作返回左值decltype(&quot;hello&quot;)var11 = &quot;hello&quot;; //const char(&amp;)[9] 字符串字面常量为左值，且为const左值。//规则四：以上都不是，则推导为本类型decltype(1) var12;//const intdecltype(Func(1)) var13=true;//const booldecltype(i++) var14 = i;//int i++返回右值 Bind函数std::bind 可以看作一个通用的函数适配器，将可调用对象与其参数一起进行绑定，生成一个新的可调用对象 std::function 保存 将可调用对象和其参数绑定成一个仿函数 只绑定部分参数，减少可调用对象传入的参数。 12345678void fun(int a, int b, int c, const int &amp;d) &#123; cout &lt;&lt; a &lt;&lt; b &lt;&lt; c &lt;&lt; d &lt;&lt; endl;&#125;int main() &#123; int n=7; auto g = bind(fun, placeholders::_2, placeholders::_1, n, cref(n)); g(1,2); // 2177&#125; 访控与继承 public成员对任何访问者可见 private成员只对类内可见 protected介于public和private之间，它对于类内与派生类可见。这为继承提供了便利，子类可以访问父类的protected成员。但是子类友元不能访问父类protected成员 堆和栈 堆 栈 空间大小 堆空间不连续，频繁分配产生碎片，但空间大（受限于有效的虚拟内存） 连续的一小块内存区域（1~8M），没有碎片 生长方向 堆向上，向高地址方向增长 栈向下，向低地址方向增长。 管理方式 程序员控制，都是动态分配 编译器自动管理，主要静态分配，也可以用alloca函数动态分配（自动释放） 内存管理机制 系统有一个记录空闲内存地址的链表，遍历该链表找到第一个空间满足的堆结点，从空闲结点链表中删除该结点，并将该结点空间分配给程序 只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报栈溢出异常。 分配效率 堆由C&#x2F;C++函数库提供，分配内存时需要寻找合适大小的内存，并且获取堆的内容需要两次访问（先获取地址，再访问内存），效率低 计算机在底层对栈提供支持，栈地址有专门寄存器存放，栈操作有专门指令 指针和引用从编译角度： 指针指向⼀块内存，指针的内容是所指向的内存的地址，在编译时将“指针变量名-指针变量的地址”添加到符号表中。所以指针内容可以改变，区分是否 const 。 引⽤是⼀块内存的别名，编译时将”引⽤变量名-引⽤对象的地址“添加到符号表中，符号表⼀经完成不能改变，所以引⽤必须⽽且只能在定义时被绑定到⼀块内存上，不能更改也不能为空，不区分 const。 从参数传递角度，引⽤传递和指针传递都是函数栈空间上的⼀个局部变量，但是： 指针参数传递本质是值传递，传递的是地址值。被调函数栈中存放的是传入实参变量的副本。形参指针变了，实参指针不会变。 传引⽤的实质是传地址，传递的是变量的地址。被调函数栈中存放的是传入实参变量的地址。对形参的任何操作都被处理成间接寻址，即通过别名（栈中存放的地址）访问主调函数中的本体，因此对形参的操作会影响实参变量。 多态用统一的接口处理不同类型的对象，使程序灵活可扩展、易维护。 静态多态：通过函数重载和模板，在编译期决定调用哪个函数 动态多态：子类重写父类的虚函数，通过父类指针调用子类成员函数，运行时根据对象的实际类型调用相应的函数 重载、覆盖、隐藏 重载 同一范围内定义了若干的函数名相同，但参数类型、个数、顺序的不同的函数。根据参数列表决定调⽤哪个函数，不关⼼函数的返回类型。 重写&#x2F;覆盖 派⽣类中重新定义⽗类中除了函数体外完全相同的虚函数。重写函数的访问修饰符是可以不同的，尽管 virtual 中是 private 的，派⽣类中重写可以改为 public。 重定义&#x2F;隐藏 派⽣类重新定义⽗类中同名的⾮虚函数，父类函数被隐藏。参数列表和返回类型都可以不同，只有父类中同名、同参的 virtual 函数（符合重写条件）才不会被派⽣类中的同名函数所隐藏。 声明、定义、初始化 声明分为引用型声明与定义型声明。 引用型声明：声明外部变量，如 extern int a，不会分配内存 定义型声明：声明一个新变量并分配内存，全局变量默认初始化0，局部变量仍然是垃圾值 定义为变量分配内存空间，等价于定义型声明。 静态绑定、动态绑定静态绑定，绑定的是在程序中声明的类型，发⽣在编译期间。如非虚函数。 动态绑定，绑定的是所指对象的实际类型，发⽣在运⾏期间，如虚函数。但是，缺省参数值也是静态绑定的，所以不能重新定义继承来的缺省参数，否则可能调用派生类的虚函数时，使用的是基类的缺省参数值。 多重继承菱形继承 虚继承虚基类解决了多继承（菱形继承）时命名冲突和冗余数据的问题，使派生类中只保留一份间接基类的成员，需要在继承方式前加上virtual关键字修饰 虚基类部分被放到对象内存的最后面，且B和C的对象中有隐藏的虚基类表指针(vbptr)指向虚基类表(vbtable) 虚基类表中存放了2个偏移量： vbptr 相对于虚函数表指针(vfptr)的偏移量（若没有定义虚函数，偏移量为0） vbptr 相对于虚基类(A)部分的偏移量 智能指针智能指针是一个类，用来存储指向动态分配对象的指针，负责自动释放动态分配的对象，防止堆内存泄漏。动态分配的资源，交给一个类对象去管理，当类对象声明周期结束时，自动调用析构函数释放资源 unique_ptr保证同⼀时间内只有⼀个智能指针可以指向该对象。转移一个unique_ptr将会把所有权从源指针转移给目标指针，源指针被置空。 unique_ptr不支持拷贝构造和赋值操作，但可以配合 move() 支持移动构造和移动赋值。拷贝操作有一个例外，可以从函数中返回unique_ptr。 可以通过reset()或者赋值nullptr释放管理对象 UniquePtr实现 123456789101112131415161718192021222324template&lt;typename T&gt;class UniquePtr &#123;public: UniquePtr(T* ptr = nullptr) : _ptr(ptr) &#123;&#125; ~UniquePtr() &#123; delete _ptr; &#125; UniquePtr(const UniquePtr&amp; u) = delete; UniquePtr&amp; operator=(const UniquePtr&amp; u) = delete; UniquePtr(UniquePtr&amp;&amp; u) noexcept &#123; _ptr = u._ptr; u._ptr = nullptr; &#125; UniquePtr&amp; operator=(UniquePtr&amp;&amp; u) noexcept &#123; _ptr = u._ptr; u._ptr = nullptr; return *this; &#125; T&amp; operator*() const &#123; return *_ptr; &#125; T* operator-&gt;() const &#123; return _ptr; &#125; operator bool() const &#123; return _ptr; &#125;private: T* _ptr;&#125;; shared_ptrshared_ptr 内部主要包含数据块指针和控制块指针。控制块中包含一个引用计数和其它一些数据。由于这个控制块需要在多个shared_ptr 之间共享，所以它也是存在于 heap 中的。shared_ptr对象本身是线程安全的，也就是说shared_ptr的引用计数增加和减少的操作都是原子的。 采用引用计数器的方法，允许多个智能指针指向同一个对象。引用计数器跟踪有多少个对象共享同一指针，引用计数保存在堆上，每当多&#x2F;少一个指针指向该对象时，智能指针内部的引用计数±1，当计数为0的时候会自动的释放动态分配的资源。 make_shared 更高效 因为 std::make_shared 参数是个 万能引用，防止数据拷贝 减少 new 操作次数，本来两个块需要分别调用 new 分配两次内存空间，现在只需要一次。防止中途异常导致的内存泄漏。 控制块和数据块分配的空间相邻，cache访存更高效，也减少内存碎片 线程安全性 如果多个执行线程在没有同步的情况下并发访问同一个 std::shared_ptr 对象，并且使用了 shared_ptr 的非常量成员函数，则将发生数据竞争。除非所有此类访问都是通过 std::atomic_load 和 std::atomic_store 这类函数执行的。 shared_ptr ptr, new_ptr; atomic_store(&amp;ptr, new_ptr); shared_ptr ret &#x3D; atomic_load(&amp;ptr); 引用计数是原子，线程安全 并发改变指向时不安全，可能引用计数为0提前析构，例如： 智能指针P2被线程 A1 和 A2 共享 线程 A1 执行P1&#x3D;P2，P1指向P2，但没来得及计数+1 线程 A2 执行P2&#x3D;P3，P2指向P3，此时引用计数0将资源释放了，则P1变成了悬空指针 SharedPtr实现 123456789101112131415161718192021222324252627282930313233343536template&lt;typename T&gt;class SharedPtr &#123;public: SharedPtr(T* ptr = nullptr) :_ptr(ptr), _count(new int(0))&#123; if(ptr) (*_count)++; &#125; ~SharedPtr() &#123; if (--(*_count) == 0) &#123; delete _ptr; _ptr = nullptr; delete _count; _count = nullptr; &#125; &#125; SharedPtr(const SharedPtr&amp; s) &#123; _ptr = s._ptr; _count = s._count; (*_count)++; &#125; SharedPtr&amp; operator=(const SharedPtr&amp; s)&#123; if (this != &amp;s) &#123; if (--(*_count) == 0) &#123; delete _ptr; delete _count; &#125; _ptr = s._ptr; _count = s._count; (*_count)++; &#125; return *this; &#125; T&amp; operator*() const &#123; return *_ptr;&#125; T* operator-&gt;() const &#123; return _ptr; &#125; operator bool() const &#123; return _ptr; &#125;private: T* _ptr; int* _count;&#125;; weak_ptr它指向一个由 shared_ptr 管理的对象而不影响所指对象的生命周期，它只引用不计数。weak_ptr 不保证指向的内存一定有效：如果一块内存被 shared_ptr 和 weak_ptr 同时引用，当所有shared_ptr析构了之后，内存就会被释放，通过 expired() 指向的对象是否已被销毁 想使用对象但不管理对象，并且在需要时可以返回对象的 shared_ptr 时，使用 weak_ptr 引用计数有一个问题就是互相引用形成环，这样两个指针指向的内存都无法释放，解决方法就是其中一方用 weak_ptr 的方式管理对象从而打破环 123456789101112131415161718class Node &#123; // shared_ptr&lt;Node&gt; partner_; memory leak weak_ptr&lt;Node&gt; partner_; public: friend void partnerUp(shared_ptr&lt;Node&gt;&amp; p1, shared_ptr&lt;Node&gt;&amp; p2) &#123; if (!p1 || !p2) return; p1-&gt;partner_ = p2; p2-&gt;partner_ = p1; &#125; const std::shared_ptr&lt;Person&gt; getPartner() const &#123; return partner_.lock(); &#125;&#125;;int main() &#123; auto node1 &#123; make_shared&lt;Node&gt;() &#125;; auto node2 &#123; make_shared&lt;Node&gt;() &#125;; partnerUp(node1, node2); // 循环引用 // lock() 返回其所指对象的 shared_ptr，并将计数器加1 auto node1_partner = node1-&gt;getPartner();&#125; 异常安全问题1some_function(std::unique_ptr&lt;T&gt;(new T), function_that_can_throw_exception()); 对于以上代码，C++ 没有规定编译器对函数参数的求值次序，所以有可能出现这样的次序： 调用new T分配动态内存 调用function_that_can_throw_exception()函数（此时抛异常会内存泄露） 调用unique_ptr的构造函数 解决：用 make_unique/shared 确保对象 T 的创建和 unique_ptr 一起 类型转换 static_cast：主要执⾏⾮多态的基本类型互转。基类子类间上⾏转换安全，下⾏转换不安全，得到错误指针；不能转换掉const、volitale属性 dynamic_cast：主要用于安全的下行转换，支持运行时识别指针、引用 （下行转换）须用于含虚函数的类，因为运行时转换须要知道类对象的信息，通过虚函数表得到继承关系 必须转换类指针、引⽤或 void*类型 上行转换同static_cast，下⾏转换安全，当类型不⼀致时返回nullptr const_cast：移除const或volatile属性 reinterpret_cast：从底层对数据进⾏重新解释，危险性高，依赖具体的平台，可移植性差 代码编译链接1. 预编译 处理 # 开头的预编译指令，#define、#include、#ifdef 删除注释，添加行号和文件标识，生成 .i 文件 2. 编译 经过词法分析、语法分析、语义分析、优化后，生成汇编代码 .s 文件 3. 汇编 将汇编代码转成机器码，根据汇编指令和机器指令的对照表翻译即可，生成 .o 文件 4. 链接 静态链接：把库中⽤到的函数代码直接链接进⽬标程序，程序运⾏的时候不再需要其它的库⽂件 空间浪费：如果多个程序对同一个目标文件有依赖，会存在多个副本 更新困难：库函数修改后需重新编译链接 运行速度快 动态链接：把调⽤的函数所在动态链接库和在其中的位置等信息链接进⽬标程序，程序运⾏的时候再从 DLL 中寻找相应函数代码，因此需要 DLL 的⽀持。 共享库：多个程序依赖同一个库时，只需共享一个副本，减小 更新方便：直接替换原来的目标文件即可 即使只需要一两条命令，也要附带庞大的 DLL 的支持才能运行 内存分配三种 new 操作1234567891011// operator new: 标准库函数, 类似malloc只申请一块原始的未命名的内存void* buffer = ::operator new(sizeof(string));// placement new: 在给定的内存中初始化对象（但不分配内存）buffer = new(buffer) string(&quot;123&quot;);cout &lt;&lt; *(string*)buffer &lt;&lt; endl;// equals new operatorstring* str = new string(&quot;123&quot;);cout &lt;&lt; *str &lt;&lt; endl;delete str;// operator delete: 标准库函数, 类似 free::operator delete(buffer); new &#x2F; delete 与 malloc &#x2F; free的区别 new 是运算符，malloc 是标准库函数 new 返回具体类型指针 &#x2F; 抛bad_alloc异常，malloc 返回void类型指针 &#x2F; NULL new 类型安全，malloc 不安全 new 自动计算要分配的空间大小，malloc 手工计算 new 调用 operator new 的标准库函数分配空间并调用对象的构造函数，delete 先运行析构函数再调用 operator delete 的标准库函数释放内存。 new 封装了malloc，直接free不会报错，但是这只是释放内存，而不会析构对象 malloc和free的原理malloc() 分配的是虚拟内存。如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。 malloc分配的空间包括：cookie、debugger header、(对象数量)、对象(数组)、padding、cookie brk()分配的内存小于 128 KB 时：通过 brk() 系统调用将堆顶指针向高地址移动，申请一块较大的内存块，然后划分成多个小块的内存，用一个空闲内存块的链表维护，每次申请内存时会从链表中分配一个合适大小的内存块。 调用 free 时不会立即还给操作系统，而是将内存块放回到空闲内存块链表中，等待下次复用，可能彼时这个内存块的虚拟&#x2F;物理地址的映射关系还在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数。 缺点：系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。 mmap()分配的内存大于 128 KB 时，通过 mmap() 系统调用中私有匿名映射的方式，在文件映射区分配一块内存。释放内存时会把内存归还给操作系统，内存得到真正的释放。 缺点：mmap() 每次都要执行系统调用。另外 mmap() 分配的内存释放时都会归还给操作系统，于是在第一次访问该虚拟地址的时候就会缺页中断。不仅每次都会发生运行态的切换，第一次访问虚拟地址后还会缺页中断，导致 CPU 消耗较大。 内存模型Linux 将高地址的 1GB 空间分配给内核，用户空间只剩 3GB 包括： 栈：由编译器管理分配和回收，存放局部变量和函数参数。效率很高，但是分配的内存容量有限。 堆：由new、malloc分配的内存块，由应用程序去控制释放。空间很大，但可能内存泄漏和空闲碎片。 全局&#x2F;静态存储区 (bss和data)：存放静态变量、全局变量和常量(static const)，在编译的时分配初始化为 0，整个运行期间都存在。static 可以控制变量的可见范围，全局变量不行。 常量存储区 (rodata)：存放的是字面常量和const变量，不允许修改。 代码区 (text)：存放程序的二进制代码。 内存泄漏 堆内存泄漏：没有free 或 delete 系统资源泄漏：如 SOCKET 没将基类析构函数定义为虚函数 内存对齐什么是内存对齐 计算机系统要求数据的首地址值是某个数 k（通常它为4或8）的倍数 内存对齐的原因 平台原因：有的硬件平台不支持访问任意地址上的数据，会抛出硬件异常。 性能原因：CPU是按块读取的，访问未对齐的内存需要仿存两次，而对齐的内存仅需要访问一次。 内存对齐的规则 确定对齐系数：和编译器有关，可以通过预编译命令 #pragma pack(n)，n = 1,2,4 设置。 确定对齐单位：min(对齐系数，结构体中最长数据类型长度) 确定数据的偏移量：min(成员大小，对齐单位)的整数倍，（可选）在成员之间加上填充字节。 结构体尾部填充：保证总大小为对齐单位的整数倍","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"}]},{"title":"流媒体协议","slug":"Archive/流媒体协议","date":"2022-11-01T10:00:00.000Z","updated":"2025-03-06T09:01:58.041Z","comments":true,"path":"2022/11/01/Archive/流媒体协议/","permalink":"http://example.com/2022/11/01/Archive/%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"RTMP RTMP协议详解 一篇文章搞清楚直播协议RTMP 什么是 RTMP一种应用层的实时信息传输协议，对低延时和音视频同步有良好的支持。解决多媒体数据传输流的分包和多路复用的问题 message 消息：将数据封装成消息，是 RTMP 协议中的基本数据单元 chunk 块：将消息分包成更小的块，基于TCP网络传输 RTMP 设计思想 分包：可以将大的消息数据分包成小的块通过网络来进行传输，是降低延时的关键 多路复用：音频、视频数据就能够合到一个传输流（块流）中进行同步传输，是音视频同步的关键 消息分优先级设计：优先级：控制消息 &gt; 音频消息 &gt; 视频消息，当网络传输能力受限时优先传输高优先级数据。要使优先级能够有效执行，分块也很关键：将大消息切割成小块，可以避免大的低优先级的消息（视频消息）堵塞了发送缓冲而延误高优先级的消息（音频、控制消息） 块大小协商：充分考虑流媒体服务器、带宽、客户端的情况，通过块大小协商动态的适应环境 Header压缩优化：块 Header 最大 12 字节，最小可以压缩到 1 字节，节省带宽 创建流的过程1.建立TCP连接 2.RTMP握手 客户端发送 C0 表示版本号、紧接着发送 C1 表示时间戳 服务器收到 C0 的时候，返回 S0 表明自己的版本号（版本不匹配则断开），然后直接发送时间戳 S1 客户端收到 S1 的时候，发一个知道了对方时间戳的 ACK C2，同理服务器收到 C1 的时候发 S2 3.建立RTMP连接 客户端发送connect命令，请求与一个服务应用实例建立连接 服务器接收到连接命令消息后，发送确认窗口大小协议消息，同时连接应用程序 服务器发送设置带宽协议消息到客户端 客户端处理设置带宽协议消息后，发送确认窗口大小协议消息到服务器端 服务器发送Stream Begin 服务器发送命令消息中的result，通知客户端连接的状态 4.创建RTMP流 客户端发送 createStream 命令 服务器发送命令消息中的result，通知客户端流的状态。 推流 客户端发送publish命令到服务器，请求创建绑定推流 服务端返回onStatus告知结果 客户端向服务器设置**媒体元数据 ** 服务端直接将metaData转发给订阅者，以便解码器初始化 服务端解析metaData，设置解码器 客户端向服务器推送媒体数据 拉流 客户端发送 play 命令到服务器，指定播放哪个频道 服务器发送设置块大小协议消息 服务器发送streambegin告知客户端流ID 服务器发送onStatus告知客户端成功 此后服务器发送音视频数据 RTMP Message Header 注意：消息需要分块发送。消息的类型只是消息本身格式的设定，和分块传输过程是不同的概念。应该把消息格式理解为消息的信息排列样式；把传输过程理解为物理上发送数据的方案。 RTMP 消息的头（而非 Message Header）是会被切割到 Chunk 里传输的。不过因为和 Chunk Header 内容重复，实际的实现上也可以不考虑这个（得约定好） MessageType 1B：类型 ID 1 - 6 被保留用于协议控制消息 MessageLength 3B：表示有效负载的字节数，大端格式 Timestamp 4B：包含了当前消息的 timestamp，大端格式 StreamID 3B：消息归属消息流 ID 标志位，大端格式 RTMP Chunk Basic Header：存放fmt和CSID，长度取决第一个字节的后6位 0：Header占2字节，CSID从64开始，范围 $2^8$ 1：Header占4字节，CSID从64+$2^8$开始，范围$2^{24}$ 2-63：Header占1字节，后6位本身即为CSID，范围2-63 Message Header：长度可变，取决于fmt StreamID 4B：同一个流中的消息（除了第一个），可省略 MessageType 1B：同一个消息拆分成的chunk，消息类型相同可省略 MessageLength 3B：同一个消息中chunk大小固定，可省略 TimeStamp 3B：前三个都相同且chunk由同一个Message切割而来，则时间戳相同，可省略 Extended Time Stamp：可选，TimeStamp为0xFFFFFF时采用扩展时间戳 RTP&#x2F;RTCP与RTSP流式传输包括顺序流式传输和实时流式传输。直播场景中使用两者均可，但实时流式传输的延迟应当更低。 RTP 实时传输协议RTP为IP网络上多媒体数据提供端到端的实时传输服务。为端到端的实时传输提供时间信息和流同步，但并不保证服务质量，服务质量（乱序、流量控制）由RTCP来提供 RTP被划分在传输层，它建立在UDP上。载荷按IP-UDP-RTP的结构进行封装，其中RTP头12B 整个RTP协议由两个密切相关的部分组成：RTP数据协议和RTP控制协议（即RTCP） RTCP 实时传输控制协议RTCP同样是基于UDP的，但是每一个RTCP包都只包含一些控制信息，因而会很短，可以把多个RTCP分组封装在一个UDP包中。RTCP的原理是向会话中的所有成员周期性地发送控制包，应用程序通过接收这些控制数据包，从中获取会话参与者的相关资料，以及网络状况、丢包率等反馈信息，从而控制服务质量或者诊断网络状况。但当有许多用户一起加入会话进程的时候，由于每个参与者都周期发送RTCP信息包，导致RTCP包泛滥 RTCP协议的不同数据包： SR(Sender Report)：类型200，发送端报告，用来使发送端以多播方式向所有接收端报告发送情况。发送端是指发出RTP数据报的终端，可以同时作为接收端。 RR(Receiver Report)：类型201，接收端报告，接收端是指仅接收但不发送RTP数据报的终端 SDES：类型202，源描述，用于报告和站点相关的信息。 BYE：类型203，是站点离开系统的报告，表示结束 APP：类型204，由应用程序自己定义，解决了RTCP的扩展性问题 RTSP 实时流协议RTSP是一个基于文本的多媒体播放控制协议，属于应用层。RTSP主要用来控制具有实时特性的数据的发送，但其本身并不用于传送流媒体数据，而必须依赖下层传输协议(如RTP&#x2F;RTCP)所提供的服务来完成流媒体数据的传送。RTSP负责定义具体的控制信息、操作方法、状态码，以及描述与RTP之间的交互操作。 RTSP的请求主要有DESCRIBE,SETUP,PLAY,PAUSE,TEARDOWN,OPTIONS等 RTSP控制的流媒体一般传输TS、MP4之类的格式 RTSP的工作流程 首先，客户端连接到流服务器并发送 DESCRIBE 命令 流服务器返回一个SDP描述，包括流数量、媒体类型等 客户端再分析该SDP描述，并为会话中的每一个流发送一个 SETUP 命令，告诉服务器客户端接收媒体数据的端口，流媒体连接建立完成 客户端发送 PLAY 命令，服务器就开始在UDP上传送媒体流 (RTP包)。在播放过程中客户端还可以向服务器发送命令来控制快进、快退和暂停等 最后，客户端可发送 TERADOWN 命令来结束流媒体会话 MP4 在 MP4 文件中，Chunk 是最小的基本单位，是为了优化数据的 I&#x2F;O 读取效率，媒体数据 -&gt; chunk -&gt; sample -&gt; 帧(默认1个) 5分钟入门MP4 封装格式分析MP4 Box结构 box header：box的元数据 type：4B，box类型，包括 预定义类型、自定义扩展类型 size：4B，整个box的字节数，为0时大小由8B的largesize确定，为1时表示是最后一个box box body：数据部分存储的内容跟box类型有关，有的很简单如 ftyp，有的可能嵌套了其他box比如moov Container box：嵌套其他box FullBox：扩展多了 version、flags 字段 version：1B，当前box的版本，为扩展做准备 flags：3B，标志位，含义由具体的box自己定义 Box类型ftyp (file type box)：描述文件遵从的MP4规范与版本 major_brand：最好基于哪种格式来解析文件，比如常见的 isom、mp41&#x2F;42、avc1、qt等 minor_version：提供 major_brand 的说明信息，比如版本号 compatible_brands：文件兼容的brand列表 moov (movie box)：媒体的metadata信息，有且仅有一个 mvhd：mp4文件的整体信息，比如创建时间、文件时长 trak (Track Box)：包含的轨道信息，是container box，至少包含两个box tkhd：单个 track 的信息，如track创建时间、时长，音频音量、视频宽高 mdia： mdhd (Media Header Box) hdlr (Handler Reference Box)：声明track的类型，以及对应的处理器 minf (Media Information Box)： trak 中媒体数据的所有特征信息 vmhd &#x2F; smhd stbl (Sample Table Box)：是包含媒体数据信息最多的 Box。主要包含了时间和媒体采样数据的索引表，能按照时间检索出采样数据的位置、类型（是否 I 帧）、大小、实际偏移位置 stsd (Sample Description)：音视频的编码、宽高、音量，每个sample中包含多少个帧（包含SPS 和 PPS） stco (Chunk Offset)：chunk索引表，chunk在文件中的偏移 stsc (Sample To Chunk)：包含 Sample 和 Chunk 的映射关系，即每个chunk中包含几个sample，用来找到包含 sample 的 chunk stsz (Sample Size)：每个sample的大小，AVPacket的size大小 stts (Decoding Time to Sample)：每个sample的时长（ 相邻两帧的解码间隔） stss (Sync Sample)：哪些sample是关键帧 ctts (Composition Time to Sample)： 时间补偿，用来计算出 pts，因为mp4 是按解码顺序存储，packet 按 dts 递增。通常用于B帧场景 mdat (Media Data Box)：存放实际的媒体数据，这里数据是没有结构的，依赖于moov中的信息索引 Moov和Mdat的前后 moov 在 mdat 后面：修改moov中的用户自定义信息时，不会影响 Chunk Offset，无需更新 stco ，编辑效率较高。但从网络播放 MP4 时就需较长时间，直到播放器获取到 moov 数据后才能初始化解码器并播放 moov 在 mdat 前面：则与上述情况相反，这时候从网络读取和播放 MP4 文件时，就可以较快获取到 moov 的数据并开始播放。所以对于通过网络播放 MP4 视频的场景，都建议将视频处理为 moov 前置。 Seek操作原理 sample &#x3D; 秒数 * 帧率 stsc根据sample找到chunk，以及该chunk中前面sample的数量 stco找到chunk偏移位置 stsz确定每个sample大小，求和即为字节数 FLVFLV是基于流式的文件存储结构，可以随时将音视频数据写入文件末尾，且文件头不会因文件数据的大小而变化，所以不管是在录制时，还是进行回放时，FLV 相较于 MP4 等多媒体格式都更有优势 与RTMP对比发现：FLV 文件就是由 “FLV Header + RTMP 数据” 构成的 格式FLV Header T：Type标识占1字节，其中两位表明是否包含音频或视频 Offset：Header长度，固定为9B FLV Body Pre TagSize：占4字节，表示前一个Tag大小 Tag Header：同RTMP Header TagType 1B：类型音频、视频、脚本数据 DataSize 3B：数据长度 Timestamp和扩展Timestamp 4B：数据生成时间戳 StreamID 3B：总为0 Tag Data：存放AudioHeader + AudioData 或 VideoHeader + VideoData TagData Script Tags存放FLV视频和音频的元信息（onMetadata），是第一个Tag，且仅有一个 Audio Tags在 FLV 中一般会用第一个 Audio Tag 来封装 AudioSpecificConfig。如果音频使用 AAC 编码格式，那么这个 Tag 就是 AAC 音频同步包 Video Tags在 FLV 中一般会用第一个 Video Tag 来封装 AVCDecoderConfigurationRecord。如果视频使用 AVC 编码格式，那么这个 Tag 就是 AVC 视频同步包。它记录了 AVC 解码相关的 sps 和 pps 信息，解码器在解码前要先获取的 sps 和 pps ，在做 seek 等操作引起解码器重启时，也需再传一遍 sps 和 pps AAC编码ADTS格式每一帧的ADTS的头文件都包含音频的采样率，声道，帧长度等信息 syncword ：固定 0xFFF，代表一个ADTS帧的开始 ID：MPEG版本: MPEG-4为0，MPEG-2为1 Layer：固定 0x00 protection_absent：需要CRC校验为0（header length&#x3D;9B），不需要为1（7B）， profile：表示使用哪个级别的AAC sampling_frequency_index：采样率的下标，如44.1k对应 0x4 channel_configuration：声道数，如2表示立体声双声道 aac_frame_length：ADTS帧的长度 &#x3D; (protection_absent &#x3D;&#x3D; 1 ? 7 : 9) + size(AACFrame) adts_buffer_fullness：0x7FF 说明是码率可变的码流。 number_of_raw_data_blocks_in_frame：表示ADTS帧中有 k+1个AAC原始帧 AAC首部分析网站 JPEG编码块划分：源图像中每点的 3个分量是交替出现的，先要分开存放到 3 张表中去。按8x8大小划分块，不足则填充 DCT变换：先将图像分层N*N的像素块，再针对每个像素块逐一DCT操作。编码时正向DCT变换，解码时反向 Zigzag 扫描排序：从左上角Z形扫描并保存DCT系数 量化：量化阶段需要两个 8*8 量化表，分别处理亮度和色度的频率系数，将频率系数除以量化矩阵的值之后取整，即完成了量化过程。量化阶段之后所有数据只保留了整数近似值，会有损失。在 JPEG 算法中，由于对亮度和色度的精度要求不同，分别对亮度和色度采用不同的量化表，前者细量化，后者粗量化。 DC和AC分量编码： DC进行DPCM差值编码，因为相邻DC系数值变化不大，取同一个图像分量中相邻DC的差值来进行编码 AC进行行程长度编码，因为系数中很多0，所以用一个数据对表示两个非零AC系数间的0个数 熵编码： 对得到的DC和AC系数的中间格式进行熵编码，JPEG标准规定了两种方式：Huffman编码和算术编码，JPEG基本系统规定采用Huffman编码 Huffman编码：对出现概率大的字符分配字符长度较短的二进制编码，对出现概率小的字符分配字符长度较长的二进制编码，从而使得字符的平均编码长度最短。具体Huffman编码采用查表的方式高效地完成，需要4张Huffman编码表：DC系数&amp;AC系数、亮度&amp;色度 JPEG解码 H264 &#x2F;AVC en.wikipedia.org&#x2F;wiki&#x2F;Advanced_Video_Coding H264码流结构VCL和NAL VCL：视频编码层，H264编码的核心，负责将视频数据编码压缩、切分 VCL层是对核心算法引擎，宏块及片的语法级别的定义，输出编码完的数据 SODB NAL：网络抽象层，负责将VCL的数据组织打包，解决丢包、乱序 NAL层定义片级以上的语法级别（如SPS和PS，针对网络传输），同时支持独立片解码，保证起始码唯一 分层结构 封闭式GOP：指每一个GOP都以IDR开始，各个GOP之间独立地编解码 开放式GOP：指第一个GOP中的第一个帧内编码图像是IDR，后续GOP中的第一个帧内编码图像为non-IDR图像，因此后面GOP中的帧间编码图像可以用前一个GOP中的已编码图像做参考图像 GOP值大的好处： 在码率不变的前提下，GOP值越大，P、B帧的数量会越多，画面细节更多，图像质量越高； GOP值大的局限： 场景切换时，编码器会自动强制插入一个I帧，此时实际的GOP值被缩短了 当I帧的图像质量差时会影响到后续P、B帧的质量，直到下一个GOP开始才有可能得以恢复 过多的P、B帧会影响编码效率，使编码效率降低 过长的GOP还会影响Seek操作的响应速度，解码某一个P或B帧时，需要先解码得到本GOP内的I帧及之前的N个预测帧才可以，GOP值越长，需要解码的预测帧就越多，seek响应的时间也越长。 五个层次：GOP -&gt; 图像 -&gt; Slice -&gt; 宏块 -&gt;子块 封闭式GOP：一组连续的画面，第一帧为IDR帧，一般由一张 I 帧和数张 B &#x2F; P 帧组成 片 slice：宏块的载体，限制误码的扩散和传输（常一帧图片对应一个slice） ，Slice Header中包括帧类型、GOP中解码帧的序号、预测权重、滤波 宏块 Macroblock：宏块大小通常为16×16像素，分为I、B、P宏块；编码处理的基本单元，由多个块组成 宏块中包含了宏块类型、预测类型、Coded Block Pattern 编码的块模式、Quantization Parameter 量化参数、像素的亮度和色度数据集等等信息 H264编码编码器结构一个编码器基本上都会有帧内预测、帧间预测、变换量化、熵编码以及滤波等几个部分。 预测编码是指利用相邻像素的空间或时间相关性，用已传输的像素对当前正在编码的像素进行预测，然后对预测值与真实值的差-预测误差进行编码和传输，即帧内预测，帧间预测。 变换编码是指将空间域描述的图像，经过某种变换形成变换域中的数据，改变数据分布，减少有效数据量。 编码流程 帧内预测：空间冗余利用相邻像素的相关性，通过当前像素块的左边和上边的像素进行预测，计算出每个宏块的预测模式信息，再将预测得到的全部图像数据和当前帧原数据进行对比得到残差值，进行变换量化，拆包生成NAL分发区别：帧内预测模式H264有9种；H265有35种，预测方向更细、更灵活 帧间预测：时间冗余基于当前帧与参考帧，通过运动评估（对所有宏块匹配查找）得到运动矢量，与当前帧对比得出残差值，进行变换量化，生成NAL区别： H264以16x16宏块为预测单位，也可以划分为16x8, 8x8, 8x4, 4x4等；H265对应的是64x64的CTU，CTU可以递归的分解为编码块CU，CU是视频编码和帧间预测的基本单元，大小32x32, 16x16, 8x8等，可以进一步划分为PU和TU 采用了更合理的子像素插值算法，进一步提高了运动估计和运动补偿的精度 采用了新的合并模式，可以更加高效地编码传输运动参数 变换和量化：为了压缩残差信息的统计冗余 DCT变换（离散余弦变换）：将图像分成互不重叠的图像块，将空间域的图像信号变换到频率域。变换后，左上角的低频系数集中了大量能量，而右下角的高频系数上的能量很小，有益于有损压缩的数据处理 量化：人眼对图像的低频特性很敏感（如总体亮度），而对高频细节信息不敏感，因此在传送过程中可以少传高频信息。量化过程通过对低频区的系数进行细量化，高频区的系数进行粗量化，去除了人眼不敏感的高频信息，从而降低信息传送量。因此，量化是有损压缩，是视频压缩编码中质量损伤的主要原因 区别：H265提高了编码效率 熵编码：使用新的编码来表示输入的数据，从而达到压缩的效果 效率稍低、实现较易的基于上下文的自适应可变长编码（CAVLC），常用数据块用短码表示 效率较高、实现较难的基于上下文的自适应二进制算术编码（CABAC），目的是从概率的角度再做一次压缩，编码的过程主要分为二值化，上下文建模，二进制算术编码 环路滤波视频压缩编码是有损压缩，逐块地对预测后的残差进行变换和量化，将导致重建图像时失真，出现方块效应（图像块边界上不连续）等。因此采用环路滤波的方法对重建图像进行滤波，降低重建误差 H264：去方块滤波（在 TU&#x2F;PU 块边界进行不同强度滤波，减少重构图像会出现的方块效应） H265：去方块滤波、SAO样点自适应补偿（通过补偿重构像素值，以减少振铃效应） 压缩方式1.帧内压缩（I帧，IDR帧）：得到预测模式信息+残差值 2.帧间压缩（P帧，B帧） 编码时运动估计：（通过宏块匹配）得到运动矢量+残差值 解码时运动补偿：将预测的图像与残差值相加 3.无损压缩 DCT变换、CAVLC压缩（MPEG2）、CABAC压缩（H.264） AnnexB格式AnnexB流结构 Startcode： 0x000001：单帧多slice（即单帧多个NALU）之间间隔 0x00000001：帧之间，或者SPS、PPS等之前 NALU： EBSP扩展字节序列载荷 &#x3D; RBSP插入防竞争字节0x03 （连续两个0x00字节时） RBSP原始字节序列载荷 &#x3D; SODB + RBSP尾部（补齐） SODB为原始数据比特流 &#x3D; Slice Header + Slice Data SPS和PPS 序列参数集，包括一组编码视频序列的全局参数，包含了profile、level、宽高和颜色空间等信息 图像参数集，包括一幅图像的公共参数，PPS可以引用SPS参数，也会被码流中的slice引用 一般均位于码流起始，但也可能在中间：解码器需要从中间开始解码；编码过程中改变了参数 NALU Header(8 bits) 第一位：forbidden_zero_bit 禁止位，初始为0，当网络发现NAL单元有错误时可置为1 后两位：nal_ref_idc代表 NALU 的重要性，取值范围0~3。对于重要数据（参考帧，序列集参数集或图像集）必须大于0 最后五位：nal_unit_type指的是当前 NAL 类型 1-4：I&#x2F;P&#x2F;B帧，是依据VLC的slice区分的 5：IDR帧，告诉解码器之前依赖的解码参数集合（接下来要出现的SPS\\PPS等）可以被刷新了 6：SEI补充增强信息，提供了向视频码流中加入额外信息的方法 7：SPS序列参数集，保存了一组编码视频序列(Coded Video Sequence)的全局参数 8：PPS图像参数集，保存了整体图像相关的参数 9：AU分隔符，Access Unit是一个或者多个NALU的集合，代表了一个完整的帧 RBSP尾部 RBSP尾部：大多数（非1-5）NALUSODB在最后紧跟1个比特1，再增加若干比特0补齐字节 条带RBSP尾部：NALU类型为条带（1-5）时默认仍情况1，仅当①entropy_coding_mode_flag值为1（当前采用的熵编码为CABAC）且②more_rbsp_trailing_data()返回true（RBSP中有更多数据时），添加一&#x2F;多个0x0000 AVCC格式AVCC流结构 视频开始有extradata，包含SPS、PPS和NALU前缀长度 前缀指明了NALU大小，前缀字节数1、2或4 AVCC中的NALU格式与AnnexB一致。AVCC转AnnexB时，如果检测到NALU Type &#x3D; 5关键帧，须在关键帧前面加上SPS NALU和PPS NALU即可 Extradata 前4字节无用跳过 第5个字节：前6位保留全1，后2位为NALU前缀大小，值013分别对应前缀124字节 第6个字节：前3位保留全1，后5位存放SPS NALU的个数（通常为1个）根据SPS NALU个数，循环获取SPS数据： 前2个字节为前缀，表示SPS字节数N，后N个字节为SPS的数据 获取全部SPS数据后，下个字节为PPS NALU的个数（通常为1个）根据PPS NALU个数，循环获取PPS数据： 前2个字节为前缀，表示PPS字节数N，后N个字节为PPS的数据 RTP格式RTP封装&#x3D; 12字节固定RTP包头 + 载荷（NALU） RTP包头 V：RTP协议的版本号为2 P：填充标志，置1将在包尾包含附加填充字节，它不属于有效载荷。填充的最后一个八进制包含应该忽略的八进制计数。某些加密算法需要固定大小的填充字节，或为在底层协议数据单元中携带几个RTP包 X：扩展标志，置1则在RTP报头后跟有一个扩展报头 CC：CSRC计数器，指示CSRC 标识符的个数 Ｍ：标记位（不同载荷含义不同，视频标记一帧的最后一个分片slice则1,其他0） PT：载荷类型RTP_PAYLOAD_RTSP，记录使用哪种 Codec ，receiver 端找出相应的 decoder解码出来。如H264&#x3D;96 序列号：标识 RTP 报文的序列号（初始值随机），每发送一个报文序号加 1 时间戳：反映了该报文第一个八位组的采样时刻。 接受者使用时间戳来计算延迟和抖动， 并进行同步控制 SSRC：区分是在和谁通信，两个同步信源的SSRC要相同 CSRC：每个32位，可以有0～15个。每个CSRC标识了该报文有效载荷中的所有特约信源 NALU类型最后五位：nal_unit_type指的是当前 NAL 类型 1-23：NAL单元，单个 NAL 单元包. 24：STAP-A，单一时间的组合包 25：STAP-B，单一时间的组合包 26：MTAP16，多个时间的组合包 27：MTAP24，多个时间的组合包 28：FU-A，分片的单元 29：FU-B，分片的单元 打包模式 单一NALU的RTP包（1个RTP包：1个NALU） 打包时去除000..1开始码，把其他数据封包得 RTP 包即可 组合NALU的RTP包（1个RTP包：多个NALU），需要解包时在重组，以STEP-A为例： 123[RTP Header] [78 (STAP-A头，1B)] [第一个NALU长度(2B)] [67 42 A0 1E 23 56 0E 2F ] [第二个NALU长度(2B)] [68 42 B0 12 58 6A D4 FF ... ] 分片NALU的RTP包（1个NALU：多RTP包），因NALU＞MTU H265 &#x2F;HEVC 白话H.265&#x2F;HEVC和H.264&#x2F;AVC编码结构*** HEVC（H.265）视频压缩编码格式与其原理 详细分析 HEVC&#x2F;H265编码框架原理 H265码流结构码流结构H.265&#x2F;HEVC压缩数据采用了类似H.264&#x2F;AVC的分层结构，将数据GOP层、Slice层中公用的大部分语法元素游离出来组成SPS和PPS，并增加了视频参数集VPS。 SPS 序列参数集，包括一组编码视频序列的全局参数，包含了profile、level、宽高和颜色空间等信息 PPS 图像参数集，包括一幅图像的公共参数，引用关系 slice -&gt; PPS -&gt; SPS -&gt;VPS VPS 视频参数集，包括多个子层共享的语法元素和其他不属于SPS的特定信息 分层结构 视频序列划分为GOP（开放式） GOP包含多个Slice或Tile，为了独立编解码 Slice带状，包括一个独立片段SS和若干依赖SS，SS包含多个树形编码单元CTU Tile矩形，包含整数个CTU CTU按照四叉树划分为不同类型，包括CU、PU、TU CU是进行预测、变换、量化和熵编码等处理的基本单元 PU是进行帧内&#x2F;帧间预测的基本单元 TU是进行变换和量化的基本单元 AnnexB与HVCC格式H.265的优势&#x2F;区别 H.265的编码架构和H.264相似，包含帧内预测、帧间预测、转换、量化、去区块滤波器、熵编码。但在HEVC编码架构中，整体被分为了三个基本单位，分别是编码单元CU、预测单元PU和转换单元 TU。并且对一些技术加以改进：改善码流、编码质量、算法复杂度 H.265采用了块的四叉树划分结构，采用了从64×64～8×8像素的自适应块划分，并基于这种块划分结构采用一系列自适应的预测和变换等编码技术；而H.264中每个宏块大小都是固定的16×16像素 H.265的帧内预测模式支持35种方向（H.264只支持9种），预测方向更细、更灵活 H.265的帧间预测采用了更合理的子像素插值算法，提高了运动补偿和估计的精度 H.264可以低于1Mbps的速度实现标清数字图像传送；H.265则可以实现利用1~2Mbps的速度传送720P普通高清音视频 同样的画质和同样的码率，H.265比H.264占用的存储空间要少理论50% 档次、层和级别 Profile（3种）：主要规定编码器可采用哪些编码工具或算法 H.264有四种画质级别：Baseline Profile：基本画质。支持I&#x2F;P 帧，只支持无交错和CAVLCExtended profile：进阶画质。支持I&#x2F;P&#x2F;B&#x2F;SP&#x2F;SI 帧，只支持无交错和CAVLCMain profile：主流画质。提供I&#x2F;P&#x2F;B 帧，支持无交错和交错，也支持CAVLC 和CABACHigh profile：高级画质。在main Profile 的基础上增加了8x8内部预测、自定义量化、无损视频编码 Level（13种）：根据解码端的负载和存储空间情况对关键参数加以限制，主要包括采样率、分辨率、码率的最大值、压缩率的最小值、解码图像缓存区的容量(DPB)、编码图像缓存区的容量(CPB)等 Tier（2种）：H.265新定义的，规定了每个级别的码率的高低","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[]},{"title":"FFmpeg","slug":"Archive/FFmpeg","date":"2022-10-01T10:00:00.000Z","updated":"2025-03-06T09:01:58.040Z","comments":true,"path":"2022/10/01/Archive/FFmpeg/","permalink":"http://example.com/2022/10/01/Archive/FFmpeg/","excerpt":"","text":"FFmpeg开发时间基与时间戳关联： 时间基 (time_base) 乘以时间戳 (timestamp) 即为实际时刻（单位s） 如：总时长 &#x3D; duration * av_q2d(AV_TIME_BASE_Q) 如：显示时间 &#x3D; PTS * av_q2d(stream-&gt;time_base) 时间戳： PTS 显示时间戳，DTS 解码时间戳 时间基： FFmpeg内部时间基： 用于FFmpeg内部计算，AV_TIME_BASE &#x3D; 10^6，AV_TIME_BASE_Q为其倒数 编解码器中的时间基tbc： 对应AVCodecContext，根据帧率来设定如25帧，则{num &#x3D; 1,den&#x3D;25} 容器中的时间基tbn： 对应AVStream，根据采样频率设定如 (1,90000)，是AVPacket中PTS和DTS的单位 确认输入输出流的时间基avformat_find_stream_info：获得输入流时间基avformat_write_header：根据输出文件封装格式确定输出流时间基 输入输出时间基不同，需要转换av_packet_rescale_ts() ：将 AVPacket 根据时间基重新计算时间戳PTS、DTS 时间基转换： 视频按帧进行播放，所以原始视频帧时间基为 1&#x2F;framerate。视频解码前需要处理输入 AVPacket 中各时间参数，将输入容器中的时间基转换为 1&#x2F;framerate 时间基；视频编码后再处理输出 AVPacket 中各时间参数，将 1&#x2F;framerate 时间基转换为输出容器中的时间基。 音频按采样点进行播放，所以原始音频帧时间为 1&#x2F;sample_rate。音频解码前需要处理输入 AVPacket 中各时间参数，将输入容器中的时间基转换为 1&#x2F;sample_rate 时间基；音频编码后再处理输出 AVPacket 中各时间参数，将 1&#x2F;sample_rate 时间基转换为输出容器中的时间基。如果引入音频 FIFO，从 FIFO 从读出的音频帧时间戳信息会丢失，需要使用 1&#x2F;sample_rate 时间基重新为每一个音频帧生成 pts，然后再送入编码器。1234// 解码前的时间基转换av_packet_rescale_ts(ipacket, sctx-&gt;i_stream-&gt;time_base, sctx-&gt;o_codec_ctx-&gt;time_base);// 编码后的时间基转换av_packet_rescale_ts(&amp;opacket, sctx-&gt;o_codec_ctx-&gt;time_base, sctx-&gt;o_stream-&gt;time_base); 工具函数12345678//获取音频样本大小（单个声道）av_get_bytes_per_sample()//获取音频声道数量av_get_channel_layout_nb_channels()//获取视频帧大小av_image_get_buffer_size()//计算重采样输出样本数av_rescale_rnd() 主要流程 解码过程 连接和打开视频流 avformat_network_init：初始化并启动TLS库，用来打开网络流 avformat_open_input：为AVFormatContext分配空间、打开输入媒体流、探测封装格式、读数据文件头、创建AVStream 定位视频流数据 avformat_find_stream_info：该函数内部已经做了一套完整的解码流程，获取了多媒体流的信息 准备解码器codec avcodec_find_decoder：寻找解码器 avcodec_alloc_context3：创建 AVCodecContext avcodec_parameters_to_context：内容拷贝，流的参数 avcodec_open2：打卡解码器，分配相关变量内存、检查解码器状态等。 解码 av_read_frame：取出一个完整帧，包括压缩后的流数据和附加信息 avcodec_send_packet：解码，按dts递增顺序输入 avcodec_receive_frame：从缓存或解码器内存中取出解压数据，按pts递增顺序输出 sws_scale：进行尺寸缩放和转码工作 av_packet_unref：解除引用刷新缓冲区：avcodec_send_packet传一个空packet，再解码就能拿到剩余帧数据 编码流程 打开输出文件 avformat_alloc_output_context2 avio_open 查找编码器、创建输出流 avcodec_find_encoder avformat_new_stream：设置时间基和编码参数 codecpar（宽、高） avcodec_parameters_to_context：参数拷贝到编码器上下文，还需设置时间基、格式、码率 avcodec_open2 写文件头 avformat_write_header 编码 读帧 avcodec_send_frame avcodec_receive_packet av_packet_rescale_ts：重新计算时间戳 av_interleaved_write_frame：交替写入帧 写文件尾 av_write_trailer 音频流视频流混合进输出媒体时，需要确保音频帧和视频帧按照 dts 递增的顺序交错排列，这就是交织问题 av_interleaved_write_frame() 函数会缓存一定数量的帧，将缓存的帧按照 dts 递增的顺序写入输出媒体，调用者不必关注交织问题(小范围的 dts 顺序错误问题这个函数可以修正) av_write_frame() 函数会直接将帧写入输出媒体，用户必须自行处理交织问题 转码流程 FFmpeg源码解析初始化avformat_open_input() ：分配空间、打开输入媒体流、探测封装格式、读数据文件头、创建AVStream 分配AVFormatContext、设置options init_input()：打开输入媒体流、探测封装格式 当使用自定义AVIOContext时（s-&gt;pb!&#x3D;NULL），如果指定了AVInputFormat就直接返回，否则调用av_probe_input_buffer2()推测AVInputFormat（如从内存中读取数据的时候） 如果指定了AVInputFormat就直接返回，否则根据文件路径推测AVInputFormat，调用av_probe_input_format2() read_probe、av_match_ext、av_match_name匹配得分 如果路径判断不出文件格式，则调用avio_open2()打开文件，再用av_probe_input_buffer2()推测AVInputFormat s-&gt;iformat-&gt;read_header()：读取多媒体数据文件头 avformat_new_stream()：根据视音频流创建相应的AVStream 拷贝白名单与黑名单协议、读取ID3V2参数 avformat_alloc_output_context2() ：分配空间、设默认值、根据文件名猜AVOutputFormat avformat_alloc_context() av_opt_set_defaults() 若参数指定了AVOutputFormat，则直接赋值给oformat 否则调用av_guess_format()遍历所有AVOutputFormat，计算匹配度 av_match_name()：封装格式名匹配，score加100 strcmp()：mime类型匹配，score加10 av_match_ext()：如果文件名称的后缀匹配，score加5 avio_open2() ：根据文件名找URLProtocol，再用对应协议打开（file、rtmp），初始化AVIOContext ffurl_open_whitelist()：初始化URLContext ffurl_alloc() url_find_protocol()：根据文件路径查找合适的URLProtocol url_alloc_for_protocol()：为URLProtocol创建URLContext ffurl_connect() url_open()&#x2F;url_open2()：打开URLProtocol（根据协议调用file_open()或rtmp_open()等） ffio_fdopen()：根据URLContext初始化AVIOContext avio_alloc_context() avformat_find_stream_info() ：做了一套完整的解码流程，获取了多媒体流的信息 find_decoder() avcodec_find_decoder()：获取解码器 avcodec_open2() read_frame_internal()：读取完整的一帧压缩编码的数据 try_decode_frame()：解码一些压缩编码数据 has_codec_parameters()：检查AVStream成员变量是否设置完毕 estimate_timings()：通过PTS、已知流时长或码率估算AVFormatContext及AVStream的duration avcodec_open2() 通过各种av_malloc()分配结构体 将AVDictionary选项设置到AVCodecContext 各种检查，比如检查编解码器是否处于“实验”阶段 如果是编码器，检查输入参数是否符合编码器的要求 调用AVCodec的init()初始化具体的解码器 读写帧av_parser_parse2() av_read_frame() 把文件拆分为若干个帧，每次调用返回一帧数据包，但不校验是否有效 返回的数据包被引用计数，必须使用av_packet_unref()进行释放。 如果音频是可变大小，则只包含一帧。 如果视频中存在B帧，pkt-&gt;pts可能为AV_NOPTS_VALUE，所以最好使用pkt-&gt;dts作为依赖。 avpriv_packet_list_get() av_read_frame_internal() ff_read_packet() iformat-&gt;read_packet()：调用AVInputFormat指向的read_packet()读取数据包 parse_packet() av_parser_parse2()：解析出视频一帧（音频若干帧） avformat_write_header() ：初始化复用器、检查AVStream的time_base,采样率,宽高、写入封装头 init_muxer()：初始化复用器 将AVDictionary选项设置到AVFormatContext 遍历AVFormatContext中的每个AVStream，并检查： time_base是否正确设置，否则调用avpriv_set_pts_info()进行设置 音频采样率，视频宽、高、宽高比 AVOutputFormat-&gt;write_header()：写入相应封装头 av_write_frame() &#x2F; av_interleaved_write_frame() ：检查 stream_index, codec_type, pts, dts，调用write_packets_common()写入帧，interleaved参数传1交错写入，总会调用 av_packet_unref() 解引用 write_packets_common() 检查pkt的stream_index和codec_type 检查pkt的pts和dts 调用s-&gt;oformat-&gt;check_bitstream()检查码流 调用函数二选一写数据包 write_packets_from_bsfs()：经过bitstream filter处理，如h264要处理startcode起始码 write_packet_common() 若interleaved标志位交错，调用interleave_packet()排序 s-&gt;oformat-&gt;write_packet()：校正时间戳，根据封装格式写入未&#x2F;压缩编码的数据包 av_write_trailer() 如果有AVBSFContext，最后写入bitstream filter数据包 填充空数据包 如果有AVIOContext，avio_write_marker写入marker标志 s-&gt;oformat-&gt;write_trailer()写文件尾 deinit_muxer()：释放muxer资源 释放priv_data和index_entries 编码avcodec_send_frame() ：检查编码器、frame，不对frame赋值 编码器是否打开、是否为编码器 encode_send_frame_internal()：解析音频metadata、检查frame是否有效 真正frame的赋值操作在后续ff_encode_get_frame() avcodec_receive_packet() ：检查编码器、w,h,f、取出未压缩的一帧 编码器是否打开、是否为编码器 encode_receive_packet_internal()：检测视频宽高、像素格式，判断调用二选一 receive_packet() 或encode_simple_receive_packet()-&gt;encode_simple_internal() frame为空则调用ff_encode_get_frame()取出一帧未压缩的数据 ff_thread_video_encode_frame或avctx-&gt;codec-&gt;encode2()编码 转码sws_getContext() sws_scale FFmpeg结构体分类 解协议（http,rtsp,rtmp） AVIOContext：管理输入输出数据，硬盘数据读到其buffer中再送给解码器 URLContext：对具体资源文件进行操作的上下文 URLProtocol：广义的输入文件（文件、网络数据流等），每种协议都对应一个URLProtocol 解封装（flv,avi,rmvb,mp4） AVFormatContext：存储视音视频封装格式中包含的信息 AVInputFormat、AVOutputFormat：对应一种封装格式 AVIOContext AVStream AVDictionary：元数据 解码（h264,mpeg2,aac,mp3） AVStream：存储每一个视频&#x2F;音频流信息的结构体 AVCodecContext：编解码器上下文结构体，存储音视频流的解码方式的相关数据 AVCodec：每种编解码器对应一个该结构体(如ff_h264_decoer) AVRational，宽高，声道数，采样率 profile，level 存数据 对于视频，每个结构一般是存一帧；音频可能有好几帧 AVPacket AVFrame AVPacket uint8_t* data：本身不包含压缩的帧数据，而是指向缓存空间 int size AVBufferRef *buf：对data指向的数据缓冲区引用管理 av_packet_ref缓存空间引用+1，复制packet中的其他字段，仅首次将src-&gt;data复制到buf-&gt;buffer中 av_packet_unref引用-1，变为0时释放缓存空间。 pts、dts stream_index int key_frame：是否关键帧 duration（解码后帧播放时长） AVFrameAVFrame 通常只需分配一次，然后可以多次重用，每次重用前应调用 av_frame_unref() 将 frame 复位到原始的干净可用的状态 uint8_t *data[]：原始帧存在若干plane中，对应planar、packet格式和单双声道 int linesize[]：对齐填充，可能比实际原数据大 AVBufferRef *buf[]： uint8_t **extended_data：存多声道音频 width, height nb_samples, channel_layout int format：帧格式AV_PIX_FMT_YUV420P、AV_SAMPLE_FMT_S16 int key_frame：是否关键帧 宏块类型表、运动矢量表等 FFmpeg相关文章 Tools：MediaInfo, VLC media player, wireshark, Elecard StreamEye Tools ※ FFmpeg时间戳详解 分析视频流 YUV结构详解 AVBuffer 和 AVBufferRef AVFrame几种分配堆空间的方式 AVStream中codec_tag初始化0 av_seek_frame() FFmpeg指令分解与复用1.格式转换 12## 音视频编码处理方式都是copy,不改变ffmpeg -i gfxm.mp4 -vcodec copy -acodec copy out.flv 2.抽取视频 12## -an表示不需要音频数据ffmpeg -i input_file -vcodec copy -an output_file_video 3.抽取音频 12## -vn表示不需要视频数据ffmpeg -i input_file -acodec copy -vn output_file_audio 处理原始数据1.提取YUV数据 1234## -c:v 表示对v(视频)进行c(编码), -pix_fmt 指定了视频的像素格式ffmpeg -i gfxm.mp4 -an -c:v rawvideo -pix_fmt yuv420p out.yuv #大小通过提取原始数据时产生的参数获取（在input中）ffplay out.yuv -s 864x486 2.提取PCM数据 1234## -ar采样率 -ac双声道 -f:PCM数据存储格式 s有符号 16位 le小端存储ffmpeg -i gfxm.mp4 -vn -ar 44100 -ac 2 -f s16le out.pcm## 对于PCM播放时，我们要制定ar,ac,f参数ffplay out.pcm -ac 44100 -ac 2 -f s16le 音视频裁剪1.裁剪 12## -ss开始时间 -t时间长度(单位s)ffmpeg -i gfxm.mp4 -ss 00:01:00 -t 10 out.ts 2.合并 12## 文件片段为.tsffmpeg -f concat -i input.txt out2.flv input.txt 12file &quot;out.ts&quot;file &quot;out2.ts&quot; 图片视频互转1.视频转图片 12## -r 指定转换图片频率(每秒转出几张) -f 指定转出图片格式image2ffmpeg -i out.ts -r 1 -f image2 image-%3d.jpeg 2.图片转视频 12#可以通过-r指定每秒放的帧数ffmpeg -i image-%3d.jpeg out5.mp4","categories":[{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"}],"tags":[]},{"title":"复试","slug":"GRE/复试","date":"2022-04-08T12:59:04.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"2022/04/08/GRE/复试/","permalink":"http://example.com/2022/04/08/GRE/%E5%A4%8D%E8%AF%95/","excerpt":"","text":"规划篇 面试篇英语面 Teacher_1 Student 自我介绍2min 稍微超时被打断 英文说出软工开发步骤 初中口语，漏了一个 专业面T1 Teacher_1 Student 软件工程 软件开发过程 √ 系统设计要做什么 教材里没看到，打太极2min被怼 用到什么模型 一开始跑题了，被引导后答出 数据库 数据库发展历史 sorry 数据库范式最高等级 √ 既然你知道5NF，说说定义 sorry，只学到BCNF 那说说BCNF定义 √ 数据库模型 一开始跑题了，被引导后答出 网状模型和关系模型哪个快，原因 网状，原因答错 思政 社会主义核心价值观 您能提示第一个词吗（老师们笑） 那你给毛概一个定义 √ T2 Teacher_2 C++ Student 两个200万长度的数字相加 √ C++构造函数和析构函数 √ T3 Teacher_3 项目 Student 说说做过工程量最大的项目 √ 复习篇大数据&amp;云计算Hadoop一个能够对大量数据进行分布式处理的软件框架 核心技术： HDFS：存储服务，众多存储数据片段的服务器组成 MapReduce：编程模型，基于集群的高性能并行计算 特性： 高效、高可靠、高扩展、低成本、多平台、多语言 HDFS计算机集群结构：交换机相连，包含多个计算机节点的多个机架组成 HDFS体系结构：主从结构，一个名称节点 + 若干数据节点 名称节点：管理命名空间，记录各块所在数据节点的位置 数据节点：负责数据存储和读取，自身数据保存在本地Linux系统中 HDFS缺点：大量小文件、低延迟数据访问、多用户写入文件 HDFS存储原理： 冗余数据保存：加速、可靠 数据存取策略： 存：(每个副本依次)上传的数据节点、不同机架节点、同机架节点 读：名称节点-&gt;数据节点，Api获取机架ID 数据错误与恢复：名称节点出错、数据节点、数据 HBase一个高可靠、高性能、面相列、可伸缩的分布式数据库，存储非&#x2F;半结构化的松散数据，目标处理大表 优点：实时处理、扩展性、处理非&#x2F;半结构化 特点：数据存储为未经解释的字符串、仅插删查、列存储、性能伸缩性好 功能组件： 库函数：链接到每个客户端 Master主服务器：维护HBase表分区信息、Region服务器列表 Region服务器：维护自己的Region，处理客户读写请求 Hbase三层结构：Zookeeper文件 -&gt; -ROOT-表 -&gt;.META.表 (-&gt;用户数据表) MapReduce策略：分而治之，将数据集分片由Map任务并行处理 框架：主(JobTracker) 从(TaskTracker)架构 体系结构：Client、JobTracker、TaskTracker、Task Scheduler 核心函数：Map、Reduce JAVA OOP设计模式分类 创建型：工厂方法模式、抽象工厂、单例、建造者、原型 结构型：桥接模式、组合模式 行为型：观察者、访问者模式 设计模式六大原则 开闭原则：对扩展开放，对修改关闭 里氏代换原则：任何基类可以出现的地方，子类一定可以出现 依赖倒换原则：依赖抽象而非具体 接口隔离原则：多个隔离接口好于一个 最少知道原则：实体尽量少发生作用 合成复用原则：多用合成聚合 密码学分类 对称密码算法：加密解密秘钥相同，两个运算代替与置换(重排位置) 快、短、大，密钥管理困难，安全性弱 DES、AES、IDEA 非对称秘钥算法：公钥加密，私钥解密 慢、长、少，只需保管私钥，可以长时间不变 RSA(大素数因式分解) 对密码系统四种攻击唯密文攻击、已知明文攻击、选择明文攻击、选择密文攻击 数字签名原理： 原始报文经散列算法生成报文摘要，经发送方私钥加密成数字签名，一同发给接收方 接收方同算法将原始报文生成报文摘要，再用发送方公钥解密附件里的数字签名，比对 功能：防止否认抵赖、篡改 混合加密A用对称密钥加密数据，并用B的公钥加密自己的对称密钥形成数字信封，一起传过去；B逆操作 PKI公钥基础设施是以公开密钥技术为基础，以数据的机密性、完整性和不可抵赖性为安全目的而构建的认证、授权、加密等的综合设施。 认证机构：数字证书申请签发 数字证书库：存储已签发的数字证书和公钥 密钥备份恢复系统：恢复解密密钥 证书作废系统 应用接口：应用与PKI交互 对公钥的管理：数字证书机制 VPN将物理不同地点的网络通过Internet连接成的逻辑上的虚拟子网，被特定企业拥有，只有授权用户才能使用，数据传输经过了加密认证 技术：隧道技术、加密技术和密钥管理技术、身份认证和访问控制技术 项目负载均衡把高并发的流量分摊在其后的服务器集群上； DNS轮询 CDN(内容分发网络)：发布机制同步到大量的缓存节点，并在DNS服务器上进行扩展，找到最近的缓存节点提供服务 软件负载均衡：nginx 负载均衡算法：哈希 轮询 随机 权重 SpringCloudNacos：服务注册中心，保存服务所在机器和端口号Ribbon：负载均衡，从一个服务的多台机器中选择一台OpenFeign：基于fegin的动态代理机制，根据注解和选择机器拼接Url地址，发起请求Sentinel：熔断降级，实现了不同的服务调度隔离，避免服务雪崩的问题Gateway：如果前端后端调用后台系统，统一走网关进入，由网关转发请求给对应的服务 Elasticsearch 集成ES，添加IK中文分词插件 创建文章的索引仓库，先进行ik分词，分词后的词语在ES中做类似搜索引擎的搜索，利用在索引库检索标题和内容，搜出来的文章返回给前端。 计网物理层数据链路层(PPP、HDLC、CSMA&#x2F;CD)网络层(IP、ARP&#x2F;RARP、ICMP)传输层(TCP、UDP)会话层表示层应用层(telnet、FTP、SMTP、DNS、DHCP、HTTP) 信道划分介质访问控制FDM：将多路基带信号调到不同频率载波上，再叠加形一个复合信号 TDM：信道分成若干时间片，轮流分配 （异步时分多路复用） WDM：光纤传播不同波长光信号 CDM：用一组包含互相正交的码字的码组携带多路信号，共享频率和时间、抗干扰 CSMA&#x2F;CA适用于无线局域网802.11 过程： 发送第一个数据帧且信道空闲，等待DIFS后发送 否则执行退避算法，信道空闲时倒计时 倒计时为0时发送并等待确认，无论续&#x2F;重发都要执行退避算法 预约：源站广播RTS，基站收到后广播CTS帧，许可源站并在规定时间内抑制其他站 PPP协议拨号建立专线点对点传输，面向字节串行线路，全双工 组成：LCP(建立管理数据链路) NCP(允许多种网络层协议 为网络层逻辑连接) PPP封装 只保证无差错接收，不可靠，无确认序号机制 路由算法距离向量 所有节点定期将路由表发送给相邻节点(目的地、代价)，无则添加，近则更新 路由信息协议(RIP)：最多15跳，规模小；慢收敛；掩码必须同 链路状态 原理：每个节点有完全的网络拓扑信息，主动测试邻接节点状态，定期泛洪法向所有路由器发送信息(相邻的所有路由器链路状态) 优点：各节点使用相同原始状态数据独立计算路径，不依赖中间节点、规模伸展性 开放最短路径优先(OSPF)：收敛快；变化时才发；灵活设置不同代价 CIDR在变长子码基础上，消除ABC类网络划分的IP地址划分方法 将网络前缀都相同的连续IP地址组成CIDR地址块，构成超网，网络前缀长度灵活，减少路由器之间路由选择信息交换 组播一次发送单个分组到达同一个组地址的多个主机 过程：主机通过IGMP协议加入组播组；通知本地网络路由器关于要接收发送给某个组播组的分组的愿望；通过扩展路由器选择转发 特点：最大努力交付，无差错报文，仅能目的地址，硬件地址映射不唯一需IP层过滤 IGMP：使路由器知道组播成员信息 主机向组播地址发送IGMP报文，路由器接收后将组成员关系转发给其他组路由器 路由器定期探寻本局域网主机，若无响应则不转发给其他 移动IP满足移动节点以固定IP实现不同网段间漫游 功能实体：移动节点、本地代理、外部代理 过程： 本地时依旧TCP&#x2F;IP 移到外地网络后，移动节点向本地代理注册当前位置 此后本地代理将收到的信息通过隧道送到转交地址并复原交付 回到本地网时，向本地代理注销转交地址 路由器一种具有多个输入输出端口的专用计算机，连接异构网络并完成路由转发 过程：源目的主机在同一网络，直接交付；否则按转发表给下一个路由 功能： 路由选择：根据协议构造路由表，和相邻路由器交换信息并更新维护 分组转发：根据转发表选择输出端口 TCP可靠传输：序号 + 超时 + 重传 流量控制：滑动窗口 &#x3D; 拥塞窗口 + 发送窗口 拥塞控制：慢开始、拥塞避免、快重传、快恢复 FTP采用CS模式使得用户远程访问服务器文件，在异构网络任意计算机间传送文件 两个TCP连接： 控制21：始终打开，监听连接&#x2F;传送请求 数据20： HTTP规定了浏览器服务器请求响应的格式规则，面相事务应用层协议 过程： 服务器进程不断监听 建立TCP连接，浏览器发送http请求报文 服务器通过http响应报文返回web信息 浏览器解释页面，TCP释放 编译原理编译程序的五个阶段 词法分析：正则式和有限自动机，生成记号流 语法分析：上下文无关文法，分析是否符合语言语法结构，生成语法树 语义分析和中间代码产生：四元式、逆波兰式，分析语义并收集符号属性 代码优化 目标代码生成：绝对、可重定位、汇编指令代码 概念编译前端：与源语言有关，三个分析、中间代码产生、中间代码优化、符号表建立 编译后端：与目标机有关，目标代码生成、错误处理、机器代码优化、符号表访问 正则表达式：特定运算符、对象按特定规则构成的表达式，描述词法规则 有限自动机：描述输入串被识别的过程，用状态图描述(一起始多接收)，输出为接收&#x2F;拒绝，构造词法分析程序 文法0型：图灵机 1型：上下文有关文法，线性界限自动机 2型：上下文无关文法，非确定下推自动机 3型：正则文法，有限自动机 语法分析自上而下： 递归下降 LL：从文法开始符号出发自上而下地为输入串建立语法树 需先消除左递归(转右递归)、避免回溯(提取公共左因子？) FIRST：候选 α 可以推导出的串的第一个终结符 FOLLOW：判断能不能将非终结符推导为 ε 自下而上： LR：一种移进规约的自底向上分析法，不断规约句柄，本质规范规约 构造复杂执行快，及时准确发现错 Action：对于当前输入符号，移进规约接收出错 Goto：面对某符号时，新的栈顶状态 软件工程软件生存周期从开发软件概念起，软件使用以后，直到失去使用价值消亡为止的过程 软件定义、软件开发、软件维护 可行性分析、需求分析、软件设计、编码、软件测试、软件维护 软件开发的模型瀑布模型 各阶段组织模式如瀑布逐级下落，完成上一阶段才能下一阶段，前阶段输出&#x3D;后阶段输入 特点：阶段性、线性不可回溯、开发不灵活有风险 开发过程：计划 - 需求分析 - 设计 - 编码 - 测试 - 运行和维护 快速原型模型 快速建立反映客户主要需求的系统，让用户试用并提出意见，从而书写规格说明文档 特点：能够实现线性开发，满足客户需求 增量模型 模块化，分批完成这些增量组件(分析设计编码测试)，将整个产品分批次提交给用户 特点：用户及时了解、开发顺序灵活 螺旋模型 结合瀑布、快速原型模型，将风险分析扩展到各阶段 统一软件开发过程模型 (Rational Unified Process)是一个基于UML的面向对象开发模型。解决了螺旋模型可操作性问题，是一种重量级过程，适用于大型团体开发大型项目 。 特征：迭代增量开发、用例驱动、软件体系结构为中心 敏捷模型 轻量级软件工程方法，更强调变化的必然性，通过沟通及合理机制有效响应变化 避免了传统开发过程复杂、文档繁琐，强调过程简洁、成员交流、用户反馈 极限编程(XP)：敏捷模型的典型应用，强调用户需求和团队工作，适用于需求模糊易改变、人数&lt;10、开发地点集中。项目计划阶段：建立简洁的用户故事；设计体系架构时：采用CRC卡促进共同努力；测试方面：开发人员向用户证明代码正确而非用户找 需求分析 业务需求：客户对系统、产品高层次的目标要求 用户需求：用户使用产品必须完成的任务 功能需求：开发人员必须实现的软件功能，以便用户完成任务 非功能性需求：系统展现给用户的行为和执行的操作，产品须遵循的标准和约束 结构化分析面向数据流的需求分析方法，基于分解抽象建立系统逻辑模型 E-R图：数据模型，实体+联系+属性 数据流图：数据流联系的功能组合，建立逻辑模型 数据字典：数据流图中各个图元的具体内容 状态转换图：行为模型 UML用例图：包含(提取共同行为)、扩展(增强行为)、泛化(一般特殊) 类图：关联、依赖(引发改变)、泛化(父类子类)、实现(类和接口) 软件测试原则：考虑不同用户、不同人员参与测试(杀虫剂效应)，开发测试组分开，尽早测试，回归测试 黑盒：已知功能设计规格，测试每个实现的功能是否符合要求。在接口处，不考虑内部逻辑 不正确、遗漏功能？ 正确输入输出？ 性能？ 初始化、终止性错误？ 白盒：已知产品内部工作过程，测试证明每种内部操作是否符合设计规格要求。对程序逻辑路径测试 对所有执行路径测试一遍 逻辑判定用真假测试一遍 循环边界执行循环体 数据库基本概念1. 触发器特殊的存储过程，通过事件触发执行。可以强化约束，维护数据完整性、一致性。 2. 存储过程预编译的SQL语句，允许模块化设计，创建一次调用多次。通过命令对象、外部程序调用 优点：预编译效率高、重复使用减少开发量、权限控制安全、从数据库中直接调用减少网络通讯 缺点：移植性差 3. 视图基于SQL语句的结果集的可视化的表。视图就像一个真实的表，包含行和列，字段是来自真实的表中的字段，可以向视图添加SQL语句&#x2F;数据。 视图是虚表,它在存储时只存储视图的定义,而没有存储对应的数据 视图只在刚刚打开的一瞬间,通过定义从基表中搜集数据,并展现给用户 优点： 简化操作：对复杂聚合函数直接创建视图 安全性：虚拟的数据集合，且用户不能随意更改 合并分离的数据：如将分公司数据合并一个表格里 缺点：性能差（转化基本表查询）、修改限制 4. 游标一种数据访问机制。对查询的结果集进行查询，将其看成结果集的指针，可以根据需要来回滚动，浏览需要的数据 表的连接方式内连接：用比较运算符比较要连接的列的值的连接，不匹配的行不会被显示 左&#x2F;右外连接：以一种表为基表，基表的所有行列都会显示，外表如果不匹配则列值都为NULL 全外连接：所有表的行列都会显示，条件不匹配的为NULL 自然连接：特殊的等值连接，它要求比较的分量是相同属性组，并在结果中去掉重复的属性列 交叉连接：不带WHERE 子句，返回被连接的两表所有行的笛卡尔积 三级模式和两级映像外模式：也称用户模式或者子模式,是用户与数据库的接口。数据库的设计者把程序员用的上的接口给出来，程序员不需要关心数据库的结构，这就是外模式（视图） 概念模式：也称模式。是数据的逻辑结构和特征的描述，是所有用户的公共数据视图（SQL建表语句建出来的东西） 内模式：也称存储模式。是数据物理结构和存储方式的描述，是数据在数据库内部的组织方式。 外模式&#x2F;模式映像：定义之间的对应关系，保证数据逻辑独立性，如修改表结构无需更改外模式(应用程序) 模式&#x2F;内模式映像：定义逻辑&#x2F;存储结构对应关系(唯一)，物理独立性。 数据库模型种类层次模型：1:n，树形结构表示实体间的联系 网状模型：m:n，用指针来确定网状连接关系 关系模型：用表格结构表达实体集，用外键表示实体间联系 优点：严格的数学概念基础；结构简单清晰，易懂易用；存取路径对用户透明，数据独立&#x2F;安全性好，简化数据库开发工作 缺点：查询效率不如非关系数据模型 数据库恢复实现方式建立冗余数据： 数据转储：静态、动态、海量、增量 登记日志文件 各类故障恢复策略事务故障：事务未完成利用日志文件撤销：反向扫描，作逆修改 系统故障：①未完成事务的更新写入DS ②已提交事务更新还在缓冲区撤销未完成，重做已完成：正向扫描撤销&#x2F;重做队列，反向撤销，正向重做 介质故障：硬盘数据破坏重装数据库，重做已完成事务 并发控制技术封锁：事务操作前，申请加锁，释放前其他事务不能更新①写锁：不能后加锁，不能读写②读锁：只能后加读锁，只能读 时间戳：每个事务一个唯一时间戳，按顺序提交给DBMS 死锁问题死锁预防：一次封锁法(降并发度、难确定)，顺序封锁法(动态变化，难确定) 死锁诊断与接触：超时法(误判、不及时)，等待图法(类比资源分配图有环则锁，撤销代价最小的事务及锁，并恢复该事务数据) 封锁协议 一级：修改前加X锁，事务结束释放——防止丢失修改 二级：读前加S锁，读后释放——防止读脏数据 三级：读前加S锁，事务结束释放——防止不可重复读 非关系型数据库特点 不需预定义模式(数据模式&amp;表结构) 无共享架构：划分后存在各本地服务器，无需网络传输，高性能 弹性可扩展：动态增删节点，无需停机 需要分区：分散在多个节点，提高并行性，防止单点失效 异步复制：基于日志，尽快写入一节点，不保证一致性 BASE模型：BA基本可用，S软状态(可一段时间异步)，E最终一致性 非规范化技术适当降低关系模式范式，提高数据库效率，可适当数据冗余 优点：减少查询时连接、减少外键索引数量 缺点：数据冗余、影响数据库完整性、增加存储空间占用 计组 OS系统调用提供了用户程序和操作系统之间的接口，实现两者通信，并取得OS服务 处理步骤: 用户态转为系统态，然后由硬件和内核程序进行系统调用的一般性处理,即首先保护被中断进程的 CPU 环境,将处理机状态字 PSW、程序计数器 PC、系统调用号、用户栈指针以及通用寄存器内容等压入堆栈;再然后将用户定义的参数传送到指定的地址保存起来 分析系统调用类型,转入相应的系统调用处理子程序 子程序执行完后，恢复被中断的 CPU 现场,然后返回被中断进程 硬中断和软中断软中断是程序运行时其他程序对它的中断;硬中断是设备对它的中断 软中断发生的时间由程序控制；而硬中断随机 硬中断的中断号由中断控制器提供的；软中断由指令直接给出 管程定义：一组数据以及定义在数据上的操作组成的软件模块，这组操作能初始化&#x2F;修改管程数据并同步进程 组成：共享结构数据说明、一组操作过程、初始化 特性：一次一个程序执行、通过管程序访问内部数据 虚拟存储器是计算机系统内存管理的一种技术,虚拟存储器将主存或辅存的地址空间统一编址,形成一个庞大的地址空间,在这个空间内,用户可以自由编程,二不必在乎实际的主存容量和程序在主存中实际的存放位置。 优点：可以弥补物理内存大小的不足;一定程度的提高反映速度;减少对物理内存的读取从而保护内存延长内存使用寿命 缺点：占用一定的物理硬盘空间;加大了对硬盘的读写;设置不得当会影响整机稳定性与 速度。 存储器地址选择方式线选法：低位地址线直接连到芯片，实现片内选址；高位直接输出片选信号，地址空间不连续、重叠； 译码法：低位同，高位译码器输出信号，增加电路复杂； 与外设信息交换的问题接口电路解决： 速度：锁存器 和 缓冲器 信号电平：电平转换电路 信号格式： 时序不匹配：时序控制电路 I&#x2F;O寻址方式存储器映像寻址：统一编址，访存指令可访问；占用内存空间； I&#x2F;O独立编址：不占内存，程序可读性好；设立IO读取指令，并区分两种 提高访存速度措施高速主存、双端口存储器、单体多字、多体并行 Open打开文件的过程若已打开：进程文件打开表为a分配表项，指向系统打开表；向PCB分配fd文件描述符 未打开：读入文件目录，获取FCB并将文件读入内存；系统打开表分配表项，指向FCB，后同1 程序装入方式 源代码 编译 成目标模块 目标模块与库函数 链接 成装入模块 通过装入程序 装入 内存 绝对装入：编译时知道内存物理地址，只能单道程序 静态重定位：在装入时一次完成，逻辑地址+内存的起始地址&#x3D;物理地址 动态重定位：装入内存的是相对地址，程序执行时依靠硬件地址变换机构得出","categories":[{"name":"考研","slug":"考研","permalink":"http://example.com/categories/%E8%80%83%E7%A0%94/"}],"tags":[]},{"title":"英语作文","slug":"GRE/英语","date":"2021-12-26T12:59:04.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"2021/12/26/GRE/英语/","permalink":"http://example.com/2021/12/26/GRE/%E8%8B%B1%E8%AF%AD/","excerpt":"","text":"大作文(图表)第一段动态图 What is clearly presented in the above line chart is that dramatic changes have taken place in purpose of mobile reading among students at a certain college from … to … . Based upon the data given above, we can conclude that the proportion of … has gained momentum substantially from A to B, a rise&#x2F;decline of 50 million, whereas the statistics of … have continued its downward trend slightly&#x2F;significantly from C to D. In the meanwhile, the … remains steady. 静态图 What is clearly presented in the above table is the statistics of … in a certain city&#x2F;group. Based upon the data given above, we can conclude that the proportion of … is the highest accounting for 60% among all the four categories. On the contrary, the statistics of … and other factors take up A and B respectively&#x2F; for only a small proportion. 补充描述 增长率 at the year-on-year growth rate of 50% 倍数 be twice &#x2F;three times as high as &#x2F; the ratio of A to B is 3:2 极值 the figures reached the peak&#x2F;bottom in … 接近 there is no obvious gap between …&#x2F; narrowed over the 25-year period 反超 the … showed an upward trend, overtaking that of … in 1980. 第二段As a matter of fact, what the author tries to show us is more than statistics. The table leads us to find out what causes the differences. Several primary causes that contribute to the above-mentioned phenomenon could be summarized as follows. 第三段预测 Taking into account what has been argued, we can come to the conclusion that whatever causes it, this established tendency of the majority of students taking jobs will continue in the forthcoming years unless current conditions go through enormous changes. The government and individuals should collaborate as much as possible to improve people’s standard of living and make the current social system more sociable. Only with joint effort, can these changes be made most use of. 利弊 XXX seems to be a double-edged sword. On the one hand, it enables more people to live a better life, but on the other hand, it is conceivable that its acceleration will put an extra stress on city resources. Given the gravity of the situation, we should figure out ways to alleviate the problem. It is advisable to launch a public awareness campaign which highlights the dangers of … When used properly, its benefits far outweigh its disadvantages. We must seek ways to reduce its disadvantages to a minimum so that it better serves humanity. 万能原因环境背景经济 On the basis of latest survey by the Chinese academy of science, with the quickening pace of modern life and the fierce competition of society, people’s values have changed gradually, an increasing amount of people aged 40 to 50 chose to … in order to adapt to the rapid development of society. XXX is no longer as essential it used to be. 媒体 The mass media such as radio, television, and the Internet, might have appropriately trumped the benefits of a higher education. 政府 The changes are enhanced and promoted by the superior policy of the government in the infrastructure field. That is to say, it is the enforcement of pertinent laws and regulations that make this surprising trend come into being. 发展 The development of the job market on the whole cannot keep pace with the expansion of college graduates, which has obliged a large number of students to to get better prepared for their careers. 科技 Advancements in science and technology have offered a technical foundation for the rapid development of the Chinese automobile industry by providing a material basis and technical means. 主观意愿目标 People generally have shifted their life goals from achieving the ultimate success to a relatively easy and comfortable life and therefore are inclined to … 思想 With the social ideology becoming more open and inclusive, the public are more willing to publicize their individuality and have higher demand for …. 进步 It is a well-established fact that people have made extraordinary progress in pursuit of spiritual life. Undoubtedly, they will secure a bright future and better life. 解压 People, who have to juggle academic work, romantic relationships and a busy social calendar, are particularly susceptible to tremendous pressure. By XXX they can successfully manage and reduce stress. 渴望 It is not uncommon to find that aspire to enhance their overall competitiveness. Therefore, XXX can gain great popularity among them. This development is believed to be in the interest of both individuals and society as a whole. 带来的好处关系 In a bid to develop interpersonal relationship and enjoy comfortable life, people in mounting numbers prefer service and environment to other factors. 学识 XXX increases one’s knowledge, widens one’s horizons and enhances mutual understanding. &#x2F;Through XXX, we Chinese have expanded our scope of knowledge, and we have come to know the world better and have been learning how to develop our country better. 能力 XXX can boost people’s development of interpersonal relationships. Awareness of cooperation, dependability, responsibility and punctuality are cultivated and fostered as people … 负面现象意识 General public lacks the basic awareness about the significance&#x2F;danger of …… 法规 Laws may not have been strictly enforced to warn people not to do. 利益 Driven by short-term profits, XXX, as a result, leading to our ecology in grave danger. 小作文(应用)邀请信On behalf of the Student Union, I am writing this letter to cordially invite you to attend the … located at (place) on (date) 12345678You are sincerely invited to participate in this important event as our judge/keynote speaker/distinguished guest. As you are one of the outstanding experts in ... all over the world, I believe the students will not only be able to learn from you, but to be inspired by you as well. The conference will be held for about xxx hours, including lectures/ seminars/ tea break/ discussion.The event mainly consists of the following parts. First of all, we will do sth, and could you please be kind to deliver a speech about sth for about ... minutes. After that, we will do sth. In the end, we will do sth.Firstly, it is organized with the primary objective to allow participants to expand their understanding about ... and it will start off at 9:00 am next Monday in the school hall. Besides, the event will be recorded and uploaded online, so you will be able to access it from the Internet if necessary. Your participation is necessary to achieve this aim. We will surely look forward to your gracious presence that day. If you have any concerns regarding this, please do not hesitate to contact us. 推荐信介绍人 I am pleased to recommend XXX for the position of … 12345XXX is one of the most pleasant persons you&#x27;ll ever meet or work with./ The characteristic that is most commendable in XXX is...First and foremost, XXX displays such traits as maturity and seriousness, which are unusual in most of his peers. In addition, XXX is an easy-going and dedicated team member who can constantly look out for others who are in need of assistance. For all of these reasons, I think XXX will make a fine addition to your team&#x2F;program. 介绍物 In reply to your request for recommending sth of quality, I am privileged to introduce… 123Firstly, XXX won applause from people with a discerning eye, ever since it was publicly discussed on social media. Moreover, XXX is able to create a comprehensive and unforgettable experience for everyone, which makes it stand out from the others. I give it my highest recommendation without reservation. I hope that you will have… and I would be pleased to answer any additional questions you may have. 建议信个人 As one of your closest friends, it is my pleasure to put forward some suggestions with regard to… 12345678First of all, you should always retain a flexible mind when you are receiving advice and insight from those who have rich experience. Besides, you should take active steps to deal with your problem, since everything will become meaningless if you sit back and wait for solutions.In the second place, a solid foundation is to be lied in order to avoid detours.Moreover, be persistent. xxx is not a task that can be accomplished within a short time. Only with a lot of sustained efforts can we improve our xxx skills.Besides, in spite of all those burdens，various extracurricular activities such as sports meets, speech contests and social gatherings will still provide ample opportunities to make friends. All in all, although there is a lot of pressure, the time you spend on our campus will be worthwhile and enhance your whole life. I hope you will find the above-mentioned useful. I am looking forward to witness a favorable improvement as soon as possible. 机构 As a resident who has been living in this city, I am writing this letter to provide some suggestions that I think are useful to improve the quality &#x2F;service. 12345678Recently, xxx can be characterized by the ... However, compared with before, xxx.These are some important points that I wanted to mention. Firstly, not only should the XX work out some rules, but more importantly, they should guarantee the effective implementation of these rules. Besides, it is advisable to cultivate the public awareness of ... More activities should be organized to ensure a sound atmosphere providing the major impetus.I deem that it is alse necessary to enhance the ...Only when xxx becomes more convenient and comfortable, can citizens xxx and the problem be solved. Hope you take these suggestions positively and improve your services as soon as possible. 倡议信As most of you know, ….&#x2F; These days, the Students’ Union is doing sth. and this open letter is for the purpose of advocating all the students on campus to … 1Compared with the past years, we enjoy a higher quailty of life but ... This phenomenon is particularly worth concerning and it is advisable for us to reverse this trend. Thus, everyone is supposed to take actions to ..., such as doing sth. As students of this university, we need to show our … to … by donating money to assit in a speedy recovery. Please consider our suggestions and we are looking forward to your actions and participation! 申请信① From the… website I learned about your need for a… I am very interested in this position, andbelieve that my education and employment background are appropriate for the position. ② As a college student about to graduate, I am writing to apply for the … position in your company&#x2F;admission to your university majoring in … ③ Moved by the noble cause of xxx Project and encouraged by what has been achieved so far, I would like to contribute my bit to the project by offering … 123456The key strengths that I possess for success in this position include ...With my... background, my training in ... and my work experience, I believe I could make a valuable contribution to... I believe my combination of... experience and... training is an excellent match for the position.My experience also includes... Thank you for taking time from your busy schedule to read this letter, and I will appreciate it if …， I am looking forward to your favorable reply. 道歉信① Please accept this letter as my formal apology for what happened on（location&#x2F;event&#x2F;issue.）It was not my intention to cause any damage or inconvenience. In retrospect, I believe the situation resulted from…② I would like to thank you for arranging to meet with me. Unfortunately, I have recently been diagnosed with a serious ear infection which will require surgery on the same day as our interview. I am so sorry to say thar I will therefore not be able to … 1234Do you mind if I postpone ... to another day later in the week? Please let me know which time is most convenient for you.I take full responsibility for this unpleasant result and do truly hope that you can stand in my place and forgive me in this matter. I will exercise caution in the future to prevent a similar mistake from happening a second time. I sincerely thank you for hearing me out. Again, I apologize for any inconvenience this may cause you. 祝贺信I am very happy today to hear the news that… Hereby I am writing this letter to you to congratulate you on this achievement. 123This only could be achieved by your painstaking efforts and talent. You really deserve...I&#x27;m so proud of you for setting your sights high, and making every effort to achieve that goal. Many congratulations on your achievement and best wishes for future growth as well. 感谢信① On behalf of..， I express heartfelt thanks for all you do.② I am writing to express my gratitude for your time and consideration in your endeavors. Your perspective and encouragement mean a great deal to me. 12345We appreciate your unfailing attention to detail and several participants commented on how well the event was organized.You showed up in good time to help me, which made such an enormous contribution to my current accomplishments. If there had not been your very generous input, it would have been tremendously difficult for me to attempt to do this.You left a deep impression upon me. Indeed, the program is one of the most wonderful memories in my life. If I can be of any service to you in the future, please don’t hesitate to contact me. 投诉信I’m writing to file a complaint about the service I received during my November 15 visit to your store. I am disappointed because—— ① It did not function the way it was supposed to and therefore, resulted in a great deal of interruptions to my life. Besides, I have been trying to negotiate with one of your staff members, but no agreement has been reached because of his indifference.② The service was not performed correctly &#x2F;I was billed the wrong amount &#x2F;something was not disclosed clearly or was misrepresented.③ It was the frequent breakdowns and problems that led me to make inadequate preparation for GRE.④ It was the guide’s rude attitude that caused us to enjoy no comfort in the trip. 123To resolve the problem, I would appreciate your money refunded/ charge card credit/ repair/ exchange. I expect you to provide a new one for replacement or ,at least, to follow the warranty policy by repairing it. If no satisfaction can be gained by these means, I will have to demand a refund.Enclosed are originals of my records include receipts guarantees/warranties/canceled checks/contracts and any other documents I believe you will take this matter into serious consideration and give a satisfactory reply as soon as possible. At the same time, I sincerely hope that you will review … If detailed information is required, please contact me at the above address or by phone at 111. 通知&#x2F;告示① Your attention, please… It is announced that… &#x2F; Owing to… we beg to inform you that…A and B will be invited to be the guests of honor.② All individuals are hereby informed that legislation regarding… has been approved. 12345678910参与活动You can be involved in a variety of activities, including (taste some special local delicacies, visit local attractions/Mount Tai) These activities are high beneficial in multiple regards. It is organized to facilitate high school students&#x27; academic learning and more importantly cultivate their cooperation ability and practical skills through activities including but not limited to reading salon and business-starting competition.I am sure we&#x27;ll share so ju8me unforgettable time together.招募志愿者We are now searching for volunteers for the coming event. They are required to help organize activities and cope with daily affairs during the summer camp.He or she are supposed to have nice appearance and temperament, and should be good at communication and cooperation. Having relevant experience is perferred. If you are interested in this activity, please feel free to contact us via xxx@163.com. The deadline is…Come and join us now！","categories":[{"name":"考研","slug":"考研","permalink":"http://example.com/categories/%E8%80%83%E7%A0%94/"}],"tags":[]},{"title":"高数十八讲","slug":"GRE/高数","date":"2021-12-26T12:59:04.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"2021/12/26/GRE/高数/","permalink":"http://example.com/2021/12/26/GRE/%E9%AB%98%E6%95%B0/","excerpt":"","text":"函数极限与连续 数列极限 一元微分学概念 一元微分学几何 一元微分学证明 一元积分学概念 一元积分学计算 一元积分学证明 多元微分学 二重积分 微分方程 无穷级数 多元积分学预备知识 多元函数积分学","categories":[{"name":"考研","slug":"考研","permalink":"http://example.com/categories/%E8%80%83%E7%A0%94/"}],"tags":[]},{"title":"408计网","slug":"GRE/计网","date":"2021-12-26T12:59:04.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"2021/12/26/GRE/计网/","permalink":"http://example.com/2021/12/26/GRE/%E8%AE%A1%E7%BD%91/","excerpt":"","text":"体系结构 物理层 数据链路层 网络层 传输层 应用层","categories":[{"name":"考研","slug":"考研","permalink":"http://example.com/categories/%E8%80%83%E7%A0%94/"}],"tags":[]},{"title":"政治知识点","slug":"GRE/政治","date":"2021-12-26T12:59:04.000Z","updated":"2025-03-06T09:01:58.042Z","comments":true,"path":"2021/12/26/GRE/政治/","permalink":"http://example.com/2021/12/26/GRE/%E6%94%BF%E6%B2%BB/","excerpt":"","text":"时政会议文件国际服贸会：数字服务共同构建人与自然生命共同体：共同有别的责任原则中央人才工作会议：世界重要人才中心和创新高地博鳌峰会《同舟共济，命运与共》：世界大变局世界经济论坛20：全球力量世界经济论坛21：世界复兴世界经济论坛”达沃斯议程”：把握中关村论坛：智慧 健康 碳中和联合国人权问题：殖民主义气候变化：人与自然命运共同体共克时艰：全球发展命运共同体新冠肺炎：人类卫生健康共同体生物多样：地球生命共同体冬奥会：一起向未来阿富汗问题联合峰会：原则”阿人主导阿人所有”中国共产党和国际政党会议：为人民谋幸福：政党的责任《反外国制裁法》：反击西方、维护利益、推进法制《加强网络文明建设》：社会精神文明、社会矛盾、建设网络强国 经济社会绿色转型源头：资源利用总抓手：实现减污降碳协同增效关键：产业结构调整 新时代民族工作主题：共同团结奋斗、共同繁荣发展主线：共同体意识出发落脚点：伟大复兴重要任务：共同奋斗 人类高质量发展新征程引领：生态文明建设驱动：绿色转型中心：人民福祉基础：国际法 高标准市场体系基础：法规体系重难点：机制改革重要任务：提升市场环境质量 横琴粤澳合作初心：促进产业多元化丰富一国两制 √探索沿海和内地开放新模式 x 四个伟大梦想 斗争 事业 工程(最) 联合国宪章宗旨：促进合作原则：尊重平等呼吁义务：多边主义 爱国统一战线涉及政策：民族 宗教 政党包括：社会主义XX者 建设社会主义文化强国包含：坚持社会效益首位、社会经济效益统一讲好中国故事：树立中国形象、提高文化软实力的重要战略任务 载人航天三步走1.载人飞船2.攻克空间站技术，短期有人照料（2017实现）3.建立空间站，长期有人照料（2021全面进入空间站阶段） 神十三号：径向对接，关键技术验证、收官之战神十二号：空间站首飞、首进，首自快接，全面迈入空间站，进入实验室研制阶段天宫二号：航天员中期驻留天问一号：火星首探嫦娥四号：探测器软着陆嫦娥工程：深空探测零突破 全过程民主统一：过程与成果、程序与实质、直接和间接、人民和国家是全链条、全方位、全覆盖民主是最广泛、最真实、最管用的社会主义民主是否民主关键：是否人民当家做主包括：投票权、口头承诺兑现、法规、权利运行是否民主 香港选举制度核心：委员会重构和赋权 北大：最早传播马克思上海：各地共产主义联络中心 改革开放：伟大觉醒、伟大革命、决定前途关键一招 第一阶段：20-35基本实现现代化第二阶段：35-50实现现代化强国 政治建设首要：党中央权威与统一领导党的领导首要：建立不忘初心、牢记使命制度 讲好中国故事：对外互联网战场主动权：唱主旋律、壮大主流舆论 民族融合 x 民族团结 √依照宪法基本法——港澳√ 台湾X 意识形态决定文化前进方向一切工作的生命线-思政工作党的生命线-群众路线 十八大：全面小康底线任务和标志性指标、脱贫攻坚十九大：全面小康三大攻坚战：防范化解重大风险、精准脱贫、污染防治 第一个农民协会：浙江萧山县 中华人名共和国成立：彻底结束了极少剥削者统治广大人民 党史学习：党史、新中国史、改革开放史、社会主义发展史 减贫道路鲜明特征：开发式扶贫关键法宝：精准扶贫 深圳示范、浦东引领、浙江富裕、中关村科技园、海南窗口 资源环境利用归根：生产和消费模式问题生态环境问题归根：发展方式和生活方式 健全宏观经济治理体系战略导向：国家发展规划 宪法制定、实施均与人民有关（区分立法&amp;制定）法律适用主体只能是司法机关 开放型经济体系：互多安对外开放格局：大宽深 马原政治经济学：劳动二重性经济学说：剩余价值理论 知识性认识：以”真”的认识为目的价值评价：以”善美”的认识为目的，评价有对错之分 金融寡头资本形成：融 资 人控制：政策咨询 参与制 个人联合 产业资本连续循环：流通过程+生产过程、货币&amp;生产&amp;商品资本循环统一商品生产过程：劳动+价值形成资本主义生产过程：劳动+价值增值 社会基本矛盾决定其他矛盾社会主要矛盾在社会发展中主导作用 现代化经济体系重要基础：乡村振兴战略支撑：创新驱动发展 统一战线主题：大团结 大联合 加强党作风建设核心问题：党与人民血肉联系 合作共赢新型国际关系：维护联合国宪章 马恩论述社会发展规律包括：阐明无产阶级使命和革命斗争策略、提出资本过渡社会主义理论 主要矛盾的主要方面决定事物性质矛盾特殊性决定事物不同的性质 货币转资本前提：劳动力成为商品资本家能雇佣工人前提：资本主义生产资料所有制 利润是资本的盈利，是剩余价值的转化方式 人工智能可以将意识活动从人脑中部分分离出来，延伸意识器官功能 著作资本论：剩余价值学说，工人阶级圣经神圣家族：马恩第一次合作，批判黑格尔唯心主义、论述历史唯物主义共产党宣言：马克思主义诞生哥达纲领批判：晚年著作，与《法兰西内战》丰富了科社思想前提(转向共产主义)：德法年鉴 社会再生产生产生产资料部门：保证本部类对消耗补偿、两部类扩规模后生产资料需求生产消费资料部门：满足两部类的消费、满足扩规模后消费资料的需求 资本循环三阶段&amp;作用购买阶段-货币资本：生产资料、剩余价值准备生产阶段-生产资本：生产剩余价值售卖阶段-商品资本：实现价值和剩余价值 无产阶级政治力量登上法国第一次：里昂工人起义英国：宪章运动德国：西里西亚纺织工人巴黎公社：全面选举、撤换制，取消高薪(非第一国际发动) 社会主义民主与资本主义民主相同：法律平等、服从多数社会主义：无产阶级、原则实践一致 资本主义所有制变化法人资本崛起、国家资本发挥作用 拜物教必然原因劳动量只有以价值量形式才能计算比较劳动等同性只有以同质的价值形式才能在交换中体现出来社会关系被物关系掩盖 马克思主义特征革命性：批判精神和鲜明的无产阶级立场，是人民、实践、发展性集中体现人民性：立场，最鲜明的品格实践性：区别于其他理论的显著特征强大生命力根源：实践为基础的科学革命性统一 唯物辩证法本质：批判、革命现存都应当灭亡、从暂时性方面理解既成的形式、对事物的肯定理解中包含否定 马克思与唯心认识论的区别认识是主体对客体的反映、社会实践是认识的基础、经验有客观来源 实践特点主观见于客观的物质活动、沟通主客观的“桥梁”、直接现实性 价值尺度于真理尺度成功的实践都是价值、真理尺度的统一脱离了价值尺度，真理就缺失了主体意义真理尺度与价值尺度的统一是具体的历史的价值尺度必须以真理为前提 社会形态关于社会运动的具体形式、发展阶段和不同质态的范畴社会形态 &#x3D; 经济基础+上层建筑 &#x3D; 经济形态+政治形态+意识形态 生产方式 &#x3D; 生产力+生产关系生产方式是社会存在发展的基础决定力量，是物质性的集中体现生产力是社会发展的最终决定力量 (物质力量)生产关系是决定其他关系的基本关系 (经济关系)，其中生产资料所有制关系最基本 社会存在 (社会物质生活条件)包括物质生产方式、自然地理环境和人口因素生产关系是社会关系，属于社会存在，但非所有社会关系(物质关系和思想关系)都是社会存在 上层建筑观念上层建筑(社会意识形态)：政治法律思想，道德，艺术，宗教，哲学政治上层建筑：国家制度，政权机构，政党，军队，警察，法庭，监狱等 具体劳动使用价值，转移生产资料价值 —&gt; 使用价值(社会财富)源泉抽象劳动价值实体，再创造劳动力商品的价值 —&gt; 价值源泉 资本主义经济危机本质特征：生产相对过剩可能性：货币的流通、支付手段根本原因：资本主义的基本矛盾 资本主义生产过程：劳动过程、价值增殖过程资本主义再生产过程：物质资料再生产、资本主义生产关系再生产 资本积累规模取决于垫付资本、剥削工人、劳动生产率、所用所费资本差额 (预付-损耗) 资本技术构成：生产资料和劳动力的比例资本价值构成：不变资本与可变资本的比例资本有机构成：由资本的技术构成决定并且反映技术构成变化的资本价值构成 经济全球化根本推动力：科技和生产力发展组织形式：跨国公司体制保障：经济体制变革壮大条件：金融自由化和创新 国际水平分工前提：资本、技术、管理核心：跨国组织标志：生产体系 法人资本所有制：基于资本雇侧劳动的垄断资本集体所有制国家资本所有制：生产资料由国家占有并服务于垄断资本的所有制 资本主义政治制度变化政治多元化趋势、法制加强建设、改良政党影响扩大 列宁提出长期探索、发展生产力、多种经济成分并存、利用资本主义发展社会主义 可能性可能性&amp;不可能性、现实&amp;抽象可能性、好&amp;坏可能性 从抽象到具体是辩证思维过程(非实践)，逻辑起点是抽象，终点是具体，各种形式的逻辑中介 政治经济学的枢纽：劳动二重性经济理论的基石：剩余价值 能动反映的基本特点：摹写 反映 能动 创造 绝对真理和相对真理是客观真理的两种属性(非表述方式) 劳动是人的存在方式，非物质财富唯一源泉 社会意识的相对独立性包括历史继承性 阶级是经济实体，历史范畴，经济范畴，根据生产资料占有关系划分阶级 资本家追求超额剩余价值 (因)——&gt;获得相对剩余价值 (果） 马恩在唯物史观+剩余价值的 (理论基础) 上阐述了无产阶级革命+无产阶级政党 (内容) 中特新发展理念&#x2F;一带一路目标：高标准 可持续 惠民生 共产党成立后早期活动建党问题讨论、共青团、宣传马克思 最新关于党的说法百年奋斗结论：走自己的路党的灵魂旗帜：马克思主义政治优势：密切联系群众根本成就：中特优良传统、鲜明特色、政治优势：思想政治工作(是一切工作的生命线)历经千锤百炼朝气蓬勃：党要管党、从严治党 新时代党的建设总要求根本方针：党要管党，全面从严治党主线：加强长期执政能力建设、先进性、纯洁性着力点：调动积极性、主动性、创造性统领：党的政治建设根基：坚定理想信念宗旨长远&#x2F;根本之策：制度建设基础性建设：思想——首要任务：坚定理想信念根本性建设：政治——首要任务：保证全党服从中央、中央权威、统一领导 农业改造方针：积稳（积极领导 稳步前进）原则：字典国（自愿互利 典型示范 国家帮助） 法治建设法治国家-目标、法治政府-重点、法治社会-基础法治政府是全面依法治国的主体工程 新发展理念根和魂：为人民谋幸福、为民族谋复兴从宗旨、问题、忧患把握新发展理念、注重共同富裕 新发展格局基点：扩大内需关键：经济循环畅通无阻主线：供给侧改革本质特征：高水平自立自强 无产阶级领导权条件：率领斗争、给以物质福利关键：建立工农基础统一战线根本保证：党建坚实支柱：军队&#x2F;革命武装 外交原则：世界和平工作布局：关键-大国、首要-周边 一带一路原则：共商共建共享目标：可持续惠民生理念：和平合作 开放包容 互学互鉴 互利共赢 人类命运共同体：繁荣 包容 安全 和平 美丽 协调：健康发展绿色：永续发展 推动高质量发展是主题扩大内需是战略基点坚持供给侧结构性改革是战略方向也是主线实现高水平自立自强是最本质特征 社会主义本质前提：坚持公有制和按劳分配党的基本路线：坚持四项基本原则、改革开放 乡村振兴战略关键：加快发展乡村产业主线：农村供给侧改革底线：国家粮食安全总目标：农村农业现代化总方针：坚持农村农业优先发展总要求：产业兴旺、生态宜居、乡风文明、治理有效、生活富裕制度保障：城乡融合三农工作总抓手：全面实施乡村振兴 人民健康是社会主义现代化标志幸福生活指标民族昌盛国家富强标志 全面深化改革出发点落脚点：促进社会公平正义、增进人民福祉总目标：完善中特，推进治理能力现代化根本目的：解放发展生产力，社会公平，惠及全民 党的领导为何中特理论逻辑、历史逻辑、实践逻辑 党的成立”不”新之处反帝反封建纲领——二大开启革命新纪元——南昌、秋收、广州有了新道路——三大起义失败才探索农村道路有了新革命任务——始终反帝反封建 创新引领经济高质量发展的根本之策引领新常态的根本之策引领发展第一动力 社会主义初级阶段基本路线基本途径：一个中心、两个基本点奋斗目标：建成社会主义现代化国家立足点：自力更生、艰苦创业 建设世界一流军队基本方略：依法治军、从严治军立军之本：政治建军灵魂：听党指挥重要途径：军民融合式核心根本：打胜仗宗旨品格特色：作风优良目标：建成听、能、作的世界一流 作出正确抉择根本前提：人民至上化危为机根本方法：科学决策促进发展大局根本支撑：科技自立自强 文明发展道路内容：生产发展，生活富裕，生态良好 共享发展理念渐进共享，全民共享，共建共享，全面共享 政协——民主政治的特有形式和独特优势主轴：中特工作主线：两个一百年”奋斗目标”中心环节：思想政治引领、广泛凝聚共识两大主题：团结和民主基本精神：合作…本质属性：团结… 实现伟大复兴提供条件新民主主义革命：社会条件(结束半殖民地半封建社会)社会主义革命建设：政治制度改革开放现代化建设：活力体制、物质保证新时代中特：三个更为 列宁论述执政党建设重要性、思想文化建设、国家政权建设和发扬社会主义民主、“根据经验谈论社会主义” 生态环境直接影响文明更替，是人类文明趋势，最普惠民生福祉，就是保护生产力，用最严格严密法制保护，共谋全球 毛泽东思想发展过程提出思想：第一次国内革命战争时期 《中国社会各阶级的分析》——分清敌友《湖南农民运动考察报告》《国民革命与农民运动》——农民问题是国民革命中心 初步形成：中国革命新道路（农村包围城市，武装夺取政权） 《中国的红色政权为什么能够存在？》《井冈山的斗争》——工农武装割据思想《星星之火，可以燎原》——中国革命只能走资本主义不同路《反对本本主义》——辩证唯物主义思想、即理论联系实际 趋于成熟：新民主主义革命理论的系统阐述 《实践论》《矛盾论》《论持久战》《共产党人发刊词》《新民主主义论》《中国革命和中国共产党》——认清近代中国是半殖民地半封建，新民主&#x3D;反帝反封建 正式确立：党的七大《论联合政府》 丰富发展：解放战争时期和中华人民共和国成立后 《在晋绥干部会议上的讲话》——打击官僚资本主义，强调新民主主义革命既是总路线又是总政策《论十大关系》——“苏积”，社会主义建设道路开始标志，第一大关系：重 轻 农业 （工业化道路：农 轻 重）《论人民民主专政》《关于正确处理人民内部矛盾的问题》——区别于苏的工业道路，首提社会主义社会基本矛盾理论，处理人民矛盾是政治生活主题：着眼点——调动一切、团结一切、党注意力转到社会主义建设 新民主主义革命道路首次提出：《中国革命与中国共产党》最终确定：《战争与战略问题》完整表述：《晋绥革命干部》 思想哲学：《实践论、矛盾论》政治路线：《论反日策略》军事路线：《革命战争与战略》 邓小平理论十一届三中：提出改革开放，改革开放后提出“必须坚持四项基本原则”，初步提出什么&#x2F;怎样社会主义十一届六中：首次”社会初级阶段”提法，评价毛泽东即毛泽东思想十二大：提出建设中特（主题形成）十三大：社会主义初级阶段的理论，基本路线”一中心、两基本点”（轮廓形成）南方谈话：发展就是硬道理、社会主义本质、计划市场都是手段（成熟）十四大：社会主义市场经济改革目标，高度评价&#x2F;确立邓小平理论的指导地位十五大：入党章，指出”公有制为主体…”基本制度，依法治国基本方略 新民主主义的经济纲领1、没收封建地主阶级的土地归农民所有。（是新民主主义革命的主要内容）2、没收官僚资产阶级的垄断资本归新民主主义国家所有。（是新民主主义革命的题中应有之义）3、保护民族工商业（是新民主主义经济纲领中极具特色的一项内容） 农村包围、武装夺政道路根本：处理好土地革命、武装斗争、农村根据地建设土地革命：基本内容；武装斗争：主要形式，是强有力保证；农村革命根据地：战略阵地，是依托 新民主主义社会经济成分国营经济（工人阶级）个体经济（农+小资）：十字路口私人资本主义（民资）：要改造合作社经济、国家资本主义经济：要过渡 衡量社会活力和谐有序：自由平等公正法制衡量社会性质标准：生产关系性质衡量社会进步：生产力 平安，温饱后第一要求就业，最大的民生公共安全，最基本民生收入分配，民生之源、直接方式社保，民生之依，兜底 发展中国家崛起标志：万隆会议 独立自主是中华民族精神之魂创新是国家民族发展进步动力 坚持党的领导：由党的性质决定√ 由中特x 增强四个自信坚实基础：党百年奋斗成就 马克思主义同中国第二次结合的任务：社会主义建设走自己的路 开放型经济：以一带一路重点&#x2F;关键 军民融合深度发展格局：全多高对外开放格局：全多宽 社会主义核心价值观：先进、人民(核心)、真实 社会主义先进文化建设以社会主义核心价值观为引领 思修人生目的决定人生道路 道德支撑滋养法律法律促进保障道德 民族精神：民族生存发展的精神支柱，民族精神独立性的保证时代精神：民族生存发展的精神支柱，引领新时代的根源 理想人格：明先富（明于庶物、先天下之忧、富贵不能淫）仁爱：立人或带”仁爱”（己立而立人）理想：天下、苍生、万民、志士仁人理想人格：君子、圣人、真、新民 时代新人的根本要求想领便当：理想、本领(源泉)、担当(砝码) 宪法基本原则党的领导、人民主权、尊保人权、社会主义法治、民主集中制 理想：超时代，表现为目标、动力、境界源于现实、超越现实：推动美好生活局大力量 信念：多执，一旦形成就不会轻易改变 道德起源：前提：劳动客观条件：社会关系主观条件(认识前提)：意识 道德本质：特殊意识形态，是一种实践精神(知行合一) 道德功能调节：行为中，指导纠正、协调社会关系认识：行为前，反映社会关系规范：行为后，善恶观指引、规范品德还有导向、激励 道德建设目标：培育时代新人；内容：树立理想、弘扬价值观、构建中国精神 革命道德灵魂：实现共产主义奋斗贯穿红线：为人民服务革命利益首位，树立社会新风、新型人际关系，修身自律、保持节操 社会主义道德核心：为人民服务原则：集体主义 集体主义道德要求最高：无私奉献、一心为公最基本：顾全大局、热爱祖国、诚实劳动 职业道德：爱岗敬业——基本诚实守信——公民道德建设重点办事公道、服务群众奉献社会——最高 个人品德：勤 明 宽 奉 法律 本质特征：科学先进性、人民性、阶级性、党和人民意志 立法原则：公平、公正、公开执法原则：合法、合理、信赖保护、效率司法原则：一律平等、以事实为依据、司法机关公正行使司法权 社会法：调整劳动关系、社保福利和特殊权益保障，遵循公平和谐、国家适度干预原则 中特法制体系内容前提：法律规范体系重点：法律实施体系保障：法制监督体系依托：法制保障体系本质要求与重点内容：完善党内法规体系 全面依法治国基本要求&#x2F;前提：有法可依、有法必依、执法必严、违法必究方向：党的领导、人民中心、中特法治道路关键：党依法执政、政府依法执政总抓手：中特法制体系基本格局&#x2F;法治建设方针：科学立法、严格执法、公正司法、全民守法 社会主义法治道路根本保证：党的领导力量源泉：人民社会主义法律基本属性：平等依法治国&amp;以德治国：性质、目标、作用一致，其余区别 社会主义法制建设的基本路线&#x2F;经验：党的领导、人民当家做主、依法治国坚持党领导立法、保证执法、支持司法、带头守法，依法治国与依法执政统一坚持人民在全面依法治国中的主体地位坚持法治为了人民、依靠人民、造福人民、保护人民 法治思维1.法律至上：普遍适用、优先适用、不可违抗2.权力制约：权利法定、有权有责、用权监督、违法追究3.公平正义：”拳击规救” 权力公平：权力主体、享有权利、权利保护和救济机会公平：起点、发展、代际规则公平：法律规则、法律内容、法律保护救济公平：司法、行政、社会救济 4.人权保障 前提基础：宪法（治国安邦总章程）重要条件：立法关键环节：行政最后防线：司法 5.正当程序：合法性、中立性、参与性、公开性、时限性 人身权利：生命健康权(原始基本)、人身自由权(行动前提)、尊严、住宅、通信权 中华传统美德：注重整体利益、强调责任奉献根本要求：公义胜私欲 爱国主义教育鲜明主题：实现复兴中国梦着力点落脚点：维护祖国统一和民族团结爱国教育的主阵地：思想政治理论课基本内容：广泛开展史教育、大力弘扬民族时代精神 家庭联产承包责任制包产到户，土地集体所有，积极性和优越性结合（三权分置从2014） 民族区域自治制度：与国外、历史、宗教无关 爱国主义：历史、具体、现实、有阶级性、随发展变化本质：坚持爱国 爱党 爱社会主义高度统一 史纲三三制：抗日民族统一战线政权、一切赞民政权、革命阶级联合的民主专政党员：工农中间派：民资、开明绅士(不包括地方实力派)非党左派进步：小资 中共二大采取群众路线，建立民主联合战线第一次提出统一战线思想、反帝纲领、《中国共产党宣言》、《中国共产党章程》 瓦窑堡会议：抗日战线，批判左倾关门主义，《论反日》强调党战线领导作用，”人民共和国”代替 《反对本本主义》—— 没调查没发言权、中国革命的胜利靠中国同志了解国情《关于调查人口和土地状况的通知》—— 不做正确的调查同样没有发言权“第二次全国工农兵代表大会”—— 关心群众生活，注意工作方法“ 洛川会议：抗救十纲，”成为全民族抗战”，全国军事总动员，反对片面抗战，强调无产阶级领导权敌后全面抗战方针：抗日游击战争，建立敌后根据地国统区全面抗战方针：放手发动群众，争取抗日民主 新经济政策：列宁建设社会主义思想重大变化，正在探索社会主义，采取国家资本主义发展生产 抗日根据地建设首要任务：政权建设 秋收起义：2个工农（工农革命军+工农武装）南昌起义：2个开端（创建人民军队+土地革命）井冈山革命根据地：工农武装割据 第二次统一战线区别：背景复杂、国共政权与军队合作、无正式固定的组织形式与纲领 第一次政协与重庆政协相同：多党派、确认和平建国方针不同：共产党领导地位、新民主主义性质 解放战争战略防御：46-47战略进攻：47三路大军，中国革命转折点，蒋灭亡转折点，帝国主义统治灭亡转折点战略决战：48三大战役 近代中国现代化民主化阻碍严重障碍：封建地主——民主方向总根源：帝国主义——独立方向 边疆危机：南西新台，英法俄日（云南西藏-英，广西-法，新疆-俄，台湾-日） 条约《南京》《虎门》《望厦》《黄埔》：英美法破坏主权《马关》：租港割台、洋务运动失败《辛丑》：完全半殖民地半封建社会英国侵占香港：《南京》《北京》《展拓香港界址》收回台澎文件：《开罗宣言》《波茨坦》《日本投降书》《中日联合声明》 维新派与守旧派变法？兴民权？设议院，君主立宪。废八股？改科举和兴西学 革命派和改良派革命推翻？推翻帝制实行共和？革命派认为”兴民权改民主”是唯一出路。社会革命？革命派认为必须平均地权实现土地国有，同时进行政治、社会革命才能避免贫富不均 《临时约法》——第一部资产阶级民主宪法。国民：主权、平等、自由分设行政、司法、立法机关 三民主义：没有反帝、反封不彻底新三民主义：明确反帝，平等民权，平均地权、节制资本相同点：都是民族资产阶级纲领 土地法《兴国土地法》：将“没收一切土地改为“没收一切公共土地及地主阶级的土地”土地革命时期：限制富农，耕者有其田抗日战争时期：减租减息，削弱富农，无耕者有其田解放战争时期：废除封建剥削制度，一般不变动富农土地，耕者有其田新中国成立：保存富农经济 新文化运动的局限资产阶级民主主义不能提供思想改造国民性置于优先地位没有马克思主义的批判精神 八七会议清算陈独秀右倾机会主义枪杆子政权，军事斗争重心，确定土地革命和武装反抗方针整顿改编自己的队伍，纠正过去严重的错误，而找着新的道路任务 党对人民军队的绝对领导制度发端：南昌起义奠基：三湾改编（确立”支部建在连上”）定型：古田会议（确立思想建党政治建军，绝对服从共产党领导）区别于旧军队的政治特质、根本优势 延安整风主观——整顿学风(重要)——教条主义宗派——整顿党风党八股——整顿文风 关于整风运动的指示主观、宗派、官僚，全党范围确立了实事求是 建立新中国的筹备①七届二中全会（西柏坡）夺取全国胜利的方针：天津式、北平式、绥远式工作重心的转移：由乡村转移到城两个转变：农业国转工业国，新民主主义转社会主义社会②《论人民民主专政》为新中国鉴定了理论基础和政治基础，人民民主专政的基础是工、农、小资联盟，主要是工农经验集中到一点就是工阶级（经过共产党）领导的工农联盟为基础的人民民主专政 八大经济：反保守反冒进，综合平稳政治：社会主义法制，有法可依&#x2F;必依党建：健全党内民主集中制、发展党内民主根本任务：保护发展生产力提出三个主体(国家经济、国家市场、计划生产)、三个补充 五一口号：开政协，召集人大，成立联合政府 国家资本主义具体形式：加工订货、统购包销、经销代销（初级形式）公私合营（高级形式）不包括：统购统销 土地革命时期—— 工农民主专政抗日战争时期一一 一切赞成抗日又赞成民主的人们的政权解放战争时期—— 各个革命阶级的联合专政新中国成立初期—— 人民民主专政 军事和组织问题—— 遵义会议政治和路线问题—— 瓦窑堡会议战略和战术问题——《中国革命战争的战略问题》思想和作风问题—— 延安整风，《矛盾论》《实践论》 ①1935 一二九运动，中华民族的觉醒，抗日新高潮。口号：反对华北自治、打倒日本帝国主义、停止内战，一致对外②1935 八一宣言：《为抗日告同胞书》：停止内战，一致抗日④1936《停战议和》：逼蒋抗日⑤1945 口号：民主和平团结⑥1947 口号：打倒蒋介石 49年：共同纲领四面八方（公私兼顾、劳资两利、城乡互助、内外交流）56年：三大改造完毕双反（既反保守又反冒进，在综合平衡中稳步前进）大跃进后：调整巩固十六大：速度质量统一 毛思活的灵魂：实事求是、群众路线、独立自主战胜敌人法宝：实事求是、群众路线三大法宝：党的建设、武装斗争、统一战线中共七大：三作风一一自我批评、与人民群众联系、理论联系实际七届二中：两务必一一谦虚谨慎艰苦奋斗七届三中：不要四面出击、三年内经济好转 辛亥革命前：保路风潮辛亥革命后：二次革命，护国运动，护法运动（标志结束） “五反”打击不法资本家：初步改变私营企业性质1956三大改造完成：巩固公有制主体地位","categories":[{"name":"考研","slug":"考研","permalink":"http://example.com/categories/%E8%80%83%E7%A0%94/"}],"tags":[]},{"title":"Financing","slug":"Other/Financing","date":"2020-07-20T15:42:37.000Z","updated":"2025-03-06T09:01:58.038Z","comments":true,"path":"2020/07/20/Other/Financing/","permalink":"http://example.com/2020/07/20/Other/Financing/","excerpt":"","text":"基金种类 货币型：投资于货币市场上短期有价证券，银行存款、央行票据——余额宝 债权型：投资于国债、企业债，市场低迷仍有稳定收益 混合型：可同时投资股票、债权和货币基金 股票型：基金80%投股市 主动型：基金经理选取投资组合，但约7成收益率低于中证500，费率较高如1.9% 被动型：即指数基金，投资指数成分股，试图复制指数表现，费率约0.7% 大盘指数每年两次调整编制，剔除垃圾股，跟随国家发展趋势稳升 指数基金分类 宽基指数基金：如沪深300，平稳代表股市平均收益 行业指数基金：集中跟踪某行业，波动大收益高，如消费、医疗、科技长期增长，例中证白酒但周期性强的行业指数基金会暴跌暴涨，如银行、券商、地产、煤炭、钢铁，例中证煤炭 对比指数基金 VS 主动型 在有效市场中（理想的无摩擦）指数基金强，管理费用低，调仓换股成本低，如美国的“弱势有效”，然而相比之下A股市场变幻莫测 牛市指数涨的更高，因为持仓全是股票（垃圾股都会涨），而主动型有仓位限制，要预留现金应对赎回；熊市指数一败涂地，更考验公司的基本面，如茅台比垃圾股赚钱 定投 VS 集中投 本金少只能定投 定投资金使用效率慢，很久才全入市，有可能都投在了半山腰 主流指数1. A股市场 指数 概念 上证50指数 上交所市值前50大公司 深证100指数 深交所市值前100大公司 沪深300指数 上交所和深交所前300大公司 中证500指数 上交所和深交所前500中型公司（排除沪深300） 创业板指数 小型公司，创业板在深交所下 2. 港股市场 指数 概念 恒生指数 港交所最大50家公司 H股指数 含40只最大的H股和10家不在内地注册的公司 3. 美股市场 指数 概念 标普500指数 纽交所和纳斯达克交易所的500公司 纳斯达克100指数 纳斯达克上市的最大100公司 基金公司易方达、博时、华夏、广发、南方、汇添富、富国、中证、嘉实、招商 基金后缀 ETF联接基金：通过场外交易（基金APP），投资场内（证券交易所）的ETF基金 LOF基金：可在基金APP也可用股票账户买卖，两处价格常不一样 分级基金：母份额拆成AB子份额，A债权B炒股，子份额很复杂，小白勿入 增强、价值、等权重：加入基金经理主动管理，不一定更好 后缀ABC：A买基金时收申购费，B赎回时根据持有时间收费（越久越少），C略 何时买入 交易日15点前买入算当天，即“T日“ 确定估值指数 市值：股票价格 * 股份数量，反映公允价值（当前交易价格） 净资产：资产总额 - 负债，遵循历史成本计量原则（资产的历史值） 市盈率PE：市值&#x2F;净利润，多久把投资的前赚回来，PE变高减少定投 市净率PB：市值&#x2F;净资产，当前市值相对公司本身资产的溢价程度 盈利收益率：PE倒数，反映买下一家公司，其一年的盈利能带来的收益率 大于10%：开始定投 小于6.4%：分批卖出，因为债权平均收益率6.4%，相同情况没必要选风险更大的指数 股息率：分红&#x2F;市值 确定哪只基金 靠谱的基金公司、跟踪误差小、费率低、成立三年以上、基金规模大（减少清盘风险） 几只基金相关度低 夏普比率：无风险收益率与风险的比值，应不小于2.5 最大回撤率：产品净值走到最低点时的收益率回撤幅度的最大值，不高于15% 何时卖出高估值、目标止盈 债基纯债基金短期：6-12月，风险小，相当于增强版货币基金 中长期：1-2年 混合债基一级债基：主要投资债券，但可申购新股&#x2F;债 二级债基：仓位股票20%以内，债券80%以上，收益主要源于债券，股票锦上添花 偏债混合基金类似二级债基，但股票仓位20～40%之间 四大保险1.重疾险被保险人一旦确诊或者达到合同约定的理赔标准，保险公司按约定赔付保额，与是否发生医疗费用无关，是给付型的。重疾险存在的价值在于收入补偿和康复费用，例如得了癌症的人大部分要接受放化疗等长期的规范治疗，治疗和康复周期一般要1年或更久，这期间无法上班导致家庭收入损失就可以用重疾险来覆盖。重疾险的保额要做足，通常是一到两年的年收入，保额低不足以覆盖家庭收入损失。 2.医疗险先看病后报销，理赔时需要提供发票，用药清单等，是凭票报销型。众所周知现在很多进口药物，医疗器材，特效药等社保是不能报销的，需要患者自费，那这时医疗险扣除约定的免赔额后是可以报销的，通常我们讲医疗险理解为社保的补充，社保报销完剩下的部分还能通过商业医疗险来覆盖。 3.定期寿险对一个家庭经济支柱尤为重要，顾名思义是保障到一定年龄的不是保障终身，比如保到70岁；是抵御身故，全残这类极端风险带来的家庭经济损失。定寿保费低，保额高，杠杆率高，一旦在保障期间内发生极端风险保险公司会赔付一笔钱用于还房贷，抚养孩子，赡养老人等帮助被保险人完成未尽到的家庭责任和义务。30岁男，买100万保额，保费大概一千多，多数人都能承受的起。 4.意外险保障的是外来的，突发的，非本意的，非疾病导致的被保险人的就诊住院等的医疗行为。小到猫抓狗咬，小磕小碰，大到跌倒摔伤、意外事故等都可以保。全年龄段的人都应该配好意外险。建议购买一年起消费型的，一年一两百块，保费极低杠杆率极高，不要买只保身故全残的返还型意外险。 5.终身寿险属于寿险的一种，虽然也保障身故或全残，但其用于储蓄规划资金的属性居多。可以用来资金增值，财富传承，避税避债，储蓄教育金，规划养老等；又因其资产绝对安全，取用灵活，强制储蓄等的功能被越来越多的人认可。 总结：前四种属于保障类险种，用来保人。第五种终身寿险，用来保钱。 理财险 复利今年产生的利息可以放入下一年的本金生息；单利不能。 年金险和增额终身寿险收益是确定的，写进条款里。万能险可以保本，但收益不确定，不过会有保底的最低收益。投连险可能会有高收益，也可能连基本保费都亏掉。 年金险 1、收益明确，但不高 何时领钱、领多少钱都会写在合同上，保险公司一定可以给到。 但收益不高，即使持有十几二十年也很难达到4%。 2、灵活性差 买了年金险，只有到了规定时间才能领到钱（想有收益至少持有10年以上）。 如果提前取钱即退保，可能会有大亏损，交十万可能只退回六七万。 3、分红型年金险不要碰 万能险万能险就是保险界的“余额宝”。闲钱可以随时投入这个万能账户，每个月都会按最新的结算利率来计算收益，可以一直复利生息。 1、收益是一个未知数 结算利率看似高，但保底利率比较低。 2、相对灵活，但也会有各种限制 相对于年金险，万能险随时可取，灵活得多，然而： 钱投进万能险时会扣1-3%手续费，几年后才返还； 前几年取钱也会扣1-5%手续费； 每年限制取出钱的数额，要几年才能取完 3、捆绑销售 绝大部分万能险都会和年金险捆绑销售，这样以来年金险**每年返还的钱如果不领取，就会自动进入万能账户生息。**就好比你公司（保险公司）发工资给你，你不用，都放进余额宝了（万能账户）。年金险本来收益很明确的，但是捆绑上万能险后，年金险的收益就要看万能险的结算利率是高还是低，变得不清不楚了。 增额终身寿保额可以逐渐增大的终身寿险。适合小有资产，想给孩子留一笔钱，或者想要一个安全、灵活的投资渠道。 投连险高风险与高收益并存，由保险公司投资股票、债券等，有亏损可能。 五险一金1.职工社保（五险一金） 五险（强制缴纳，试用期）一金：养老、医疗、生育、失业、工伤，公积金 缴费基数最低为当地平均工资的60%（问HR缴费基数），最高为当地平均工资的300%，导致养老金、生育补贴减少 社保断缴的第二个月一般医保会失效，重新缴费后还需要计算等待期 2.城乡居民社会保险 （养老、医疗）：一年交一次 小孩出生3个月内可以去街道或者社保中心办理少儿医保，可以报销宝宝出生当天起的住院费用 3.生育险：生育前缴满9-18个月，生育的一定期限内申请，固定价格报销或按照比例报销 生育津贴：生孩子期间不能工作的收入补偿 (单位职工月日均缴费工资 * 假期天数） 奖励产假由单位发放基本工资 经常要求基本工资和生育津贴二选一 4.失业险：按照最低工资标准的一定比例领取失业金，最少缴满一年，最长可以领取24个月，领取期间若社保断缴，也可以享受医保报销的待遇，主动离职无法领取 5.工伤险：做工伤鉴定 6.养老保险金 若出现停缴、断缴，时间依旧可以累加不会清零 支付宝-养老金计算器 7.住房公积金 按照缴费基数的5%-12%来缴纳，个人企业各出一半，相当于可以双倍提取 申请公积金贷款（北京上限120w）部分城市可以和父母、配偶共同申请公积金贷款 （家庭公积金贷款）贷款利率低，利率3.25%（商业险高于5%，贷款300w多还80w） 公积金提现条件：购房租房、丧失劳动能力、离职异地 8.衡量退休前后生活水平差异：养老金替代率-退休后拿钱相当于退休前拿钱的百分比 公务员高于90%，职工约50% 养老金体系养老保险三大支柱第一支柱（政府）：基本养老保险年轻时按月缴纳一定的费用，退休后参保人能按月一直领养老金，身故后亲属还能领取丧葬补助和抚恤金。 城镇职工养老保险：企业在职职工，缴纳金额由企业（&lt;20%）和个人（8%）共同承担，具有国家强制性 城镇灵活就业养老保险：各类自由职业者或者个体户，可以选择这一类 城乡居民养老保险：对应没有工作，或想自行购买的居民，个人承担 我国养老保险分为两个账户 个人账户：账户里面的钱都是自己交的钱，交得多退休后领得也多，可以理解成强制储蓄； 统筹账户：企业交的钱会进入国家养老统筹基金，由国家统一调配。居民养老保险没有统筹账户，所有缴费都进入个人账户里面。 第一支柱的主体是现收现付制，是年轻劳动人口向退休老人的横向转移支付。伴随老年抚养比不断攀升，财政支出的压力会越来越大。 在企业职工养老保险的收入结余中，80%来自保费缴纳，15%来自财政补贴。当支出远远大于收入时，就意味着国家的补贴会越来越多。根据社科院的研究预测，第一支柱养老金结余差不多在2035年左右就会被耗尽。 交多少？企业为员工缴纳一部分，而个人缴纳其余的8%。这里指缴费基数的8%，缴费基数与当地平均工资挂钩，规定了缴费上下限（北京为6326~33891） 交几年？至少15年。企业交的部分会被划入国家养老统筹基金里，如未满15年则只能领取个人账户中自己交的部分养老金。这时可以：①补缴 ②转城乡居民基本养老保险（大打折扣） 领多少？企业职工： 职工基本养老金 &#x3D; 个人账户养老金 + 基础养老金 个人账户养老金 &#x3D; 退休时个人账户存储额 ÷ 计发月数（一般男139，女195） 基础养老金 &#x3D;当地上年度月平均工资 x (1 + 本人平均缴费工资指数）÷ 2 × 缴费年限 × 1% 注：平均缴费工资指数，公务员事业单位按最高标准交如1.5，而企业可能按最低标准交如0.6 体制职工：此前，按照退休前岗位工资和薪级工资之和的一定比例计发。工作满35年、30年和20年的，分别按90%、85%、80%计发。 第二支柱（企业）：企业年金制度企业&#x2F;事业单位和个人共同缴费，交给投资机构打理，退休&#x2F;工作满年限后可以一次性&#x2F;按月领取。缴费多少领多少，还有利息， 企业年金：目前只有一些国有银行、外企、移动联通、BAT 等才有，由企业自主建立，企业缴费不超过8%。企业缴纳的部分可能因为工作年限不达标而“作废”，但个人账户上的钱换了工作也不会消失。 职业年金：机关事业单位建立的补充养老保险制度，由单位8%和员工4%共同缴纳，所缴纳的费用全部进入职工的职业年金个人账户中； 建立企业年金需要花费大量的资金，所以只有效益好企业以及机关事业单位才有这种福利，仅只占城镇就业人口的6%。原因是为员工缴纳社保已经带来了很多压力，而设立企业年金计划虽然可以享受税收优惠政策，但是额度很低，对企业的激励效果非常有限。 第三支柱（个人）：商业养老保险 美联储加息定义是一个结果，经由美联储（美国的中央银行）提高利率，减少市场流动性 过程 美联储购买政府国债，积累后向市场甩卖（缩表），回收市场资金，同时提高对外拆借利息 联邦银行可投资放贷的资金减少，不愿外借，导致同业拆借利率**（联邦基金利率）提高**，即加息 加息后银行间借钱成本高了，为吸引人们把钱存到银行，存款利息增加 银行获得钱成本变高了，减少贷款，通货膨胀缓解 影响对货币加息 -&gt; 美国储户存款利息增加 -&gt; 国际资金涌入美国 -&gt; 美元升值 对黄金加息 -&gt; 美联储银行存款增加，市场过剩投资减少 -&gt; 投资美元增加、黄金减少 -&gt; 黄金降值 对股市银行利率上涨 -&gt; 人们愿意存银行，股票买少卖多 -&gt; 股价下降 资金外流，人民币贬值 -&gt; 进口原材料成本升高 -&gt; 公司利润减少（除出口型企业）","categories":[{"name":"Other","slug":"Other","permalink":"http://example.com/categories/Other/"}],"tags":[]}],"categories":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/categories/Storage/"},{"name":"OS","slug":"OS","permalink":"http://example.com/categories/OS/"},{"name":"Other","slug":"Other","permalink":"http://example.com/categories/Other/"},{"name":"Software","slug":"Software","permalink":"http://example.com/categories/Software/"},{"name":"CPP","slug":"CPP","permalink":"http://example.com/categories/CPP/"},{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/categories/Distribution/"},{"name":"八股","slug":"八股","permalink":"http://example.com/categories/%E5%85%AB%E8%82%A1/"},{"name":"考研","slug":"考研","permalink":"http://example.com/categories/%E8%80%83%E7%A0%94/"}],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://example.com/tags/Storage/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Other","slug":"Other","permalink":"http://example.com/tags/Other/"},{"name":"CPP","slug":"CPP","permalink":"http://example.com/tags/CPP/"},{"name":"Distribution","slug":"Distribution","permalink":"http://example.com/tags/Distribution/"},{"name":"八股","slug":"八股","permalink":"http://example.com/tags/%E5%85%AB%E8%82%A1/"},{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"},{"name":"Git","slug":"Git","permalink":"http://example.com/tags/Git/"}]}